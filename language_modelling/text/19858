{{See also|Timeline of artificial intelligence}}

The '''history of artificial intelligence''' began in [[ancient history|antiquity]], with myths, stories and rumors of artificial beings endowed with intelligence or consciousness by master craftsmen; as [[Pamela McCorduck]] writes, AI began with "an ancient wish to forge the gods."{{sfn|McCorduck|2004}}

The seeds of modern AI were planted by classical philosophers who attempted to describe the process of human thinking as the mechanical manipulation of symbols. This work culminated in the invention of the [[computer|programmable digital computer]] in the 1940s, a machine based on the abstract essence of mathematical reasoning. This device and the ideas behind it inspired a handful of scientists to begin seriously discussing the possibility of building an electronic brain.

The field of [[artificial intelligence]] research was founded at a conference on the campus of [[Dartmouth College]] in the summer of 1956. Those who attended would become the leaders of AI research for decades. Many of them predicted that a machine as intelligent as a human being would exist in no more than a generation and they were given millions of dollars to make this vision come true. Eventually it became obvious that they had grossly underestimated the difficulty of the project. In 1973, in response to the criticism of [[Sir James Lighthill]] and ongoing pressure from congress, the [[DARPA|U.S.]] and [[British Government]]s stopped funding undirected research into artificial intelligence. Seven years later, a visionary initiative by the [[Japanese Government]] inspired governments and industry to provide AI with billions of dollars, but by the late 80s the investors became disillusioned and withdrew funding again. This cycle of boom and bust, of "[[AI winter]]s" and summers, continues to haunt the field. Undaunted, there are those who make extraordinary predictions even now.<ref>For example {{Harvtxt|Kurzweil|2005}} argues that machines with [[strong AI|human level intelligence]] will exist by 2029.</ref>

Progress in AI has continued, despite the rise and fall of its reputation in the eyes of government bureaucrats and venture capitalists. Problems that had begun to seem impossible in 1970 have been solved and the solutions are now used in successful commercial products. However, no machine has been built with a [[strong AI|human level of intelligence]], contrary to the optimistic predictions of the first generation of AI researchers. "We can only see a short distance ahead," admitted [[Alan Turing]], in a famous 1950 paper that catalyzed the modern search for machines that think. "But," he added, "we can see much that must be done."<ref name="TuringQuote">{{Harvnb|Turing|1950|p=460}}</ref>
{{History of computing}}

== Precursors ==
{{Harvtxt|McCorduck|2004}} writes "[[artificial intelligence]] in one form or another is an idea that has pervaded Western intellectual history, a dream in urgent need of being realized," expressed in humanity's myths, legends, stories, speculation and clockwork [[automaton]]s.<ref>{{Harvnb|McCorduck|2004|pp=5<U+2013>35}}</ref>

=== AI in myth, fiction and speculation ===
{{Main|Artificial intelligence in fiction}}
Mechanical men and artificial beings appear in [[Greek myth]]s, such as the golden robots of [[Hephaestus]] and [[Pygmalion (mythology)|Pygmalion's]] [[Galatea (mythology)|Galatea]].<ref>
{{Harvnb|McCorduck|2004|p=5}},
{{Harvnb|Russell|Norvig|2003|p=939}}
</ref>
In the Middle Ages, there were rumors of secret mystical or [[alchemy|alchemical]] means of placing mind into matter, such as [[J<U+0101>bir ibn Hayy<U+0101>n]]'s ''[[Takwin]]'', [[Paracelsus]]' [[homunculus]] and [[Judah Loew|Rabbi Judah Loew]]'s [[Golem]].<ref>
{{Harvnb|McCorduck|2004|pp=15<U+2013>16}},
{{Harvnb|Buchanan|2005|p=50}} ([[Judah Loew]]'s [[Golem]]),
{{Harvnb|McCorduck|2004|pp=13<U+2013>14}} (Paracelsus),
{{Harvnb|O'Connor|1994}} (Geber's ''Takwin'')
</ref>
By the 19th century, ideas about artificial men and thinking machines were developed in fiction, as in [[Mary Shelley]]'s ''[[Frankenstein]]''  or  [[Karel <U+010C>apek]]'s ''[[R.U.R. (Rossum's Universal Robots)]]'',<ref>
{{Harvnb|McCorduck|2004|pp=17<U+2013>25}}
</ref>
and speculation, such as [[Samuel Butler (novelist)|Samuel Butler]]'s "[[Darwin among the Machines]]."<ref>
{{Harvnb|Butler|1863}}
</ref>
AI has continued to be an important element of [[science fiction]] into the present.

=== Automatons ===
{{Main|Automaton}}
[[Image:Al-jazari robots.jpg|thumb|right|250px|[[Al-Jazari]]'s programmable automata (1206 CE)]]
Realistic humanoid [[automaton]]s were built by craftsman from every civilization, including [[King Mu of Zhou#Automaton|Yan Shi]],<ref>
{{Harvnb|Needham|1986|p=53}}
</ref>
[[Hero of Alexandria]],<ref>
{{Harvnb|McCorduck|2004|p=6}}
</ref>
[[Al-Jazari]]<ref>
{{Harvnb|Nick|2005}}
</ref>
and [[Wolfgang von Kempelen]].<ref>
{{Harvnb|McCorduck|2004|p=17}} and see also {{Harvnb|Levitt|2000}}
</ref>
The oldest known [[automaton]]s were the [[cult image|sacred statues]] of [[ancient Egypt]] and [[ancient Greece|Greece]]. The faithful believed that craftsman had imbued these figures with very real minds, capable of wisdom and emotion<U+2014>[[Hermes Trismegistus]] wrote that "by discovering the true nature of the gods, man has been able to reproduce it."<ref>
Quoted in {{Harvnb|McCorduck|2004|p=8}}. {{Harvnb|Crevier|1993|p=1}} and {{Harvnb|McCorduck|2004|pp=6<U+2013>9}} discusses sacred statues.
</ref><ref>Other important [[automaton]]s were built by [[Haroun al-Rashid]] {{Harv|McCorduck|2004|p=10}}, [[Jacques de Vaucanson]] {{Harv|McCorduck|2004|p=16}} and [[Leonardo Torres y Quevedo]] {{Harv|McCorduck|2004|pp=59<U+2013>62}}</ref>

===Formal reasoning===
Artificial intelligence is based on the assumption that the process of human thought can be mechanized. The study of mechanical<U+2014>or "formal"<U+2014>reasoning has a long history. [[Chinese Philosophy|Chinese]], [[Indian Philosophy|Indian]] and [[Greek Philosophy|Greek]] philosophers all developed structured methods of formal deduction in the first millennium BCE. Their ideas were developed over the centuries by philosophers such as  [[Aristotle]] (who gave a formal analysis of the [[syllogism]]),  [[Euclid]] (whose ''[[Euclid's Elements|Elements]]'' was a model of formal reasoning), {{Unicode|[[Muhammad ibn Musa al-Khwarizmi|al-Khw<U+0101>rizm<U+012B>]]}} (who developed [[algebra]] and gave his name to "[[algorithm]]") and European [[Scholasticism|scholastic]] philosophers such as [[William of Ockham]] and [[Duns Scotus]].<ref name="Berlinski 2000">
{{Harvnb|Berlinski|2000}}
</ref>

Majorcan philosopher [[Ramon Llull]] (1232<U+2013>1315) developed  several ''logical machines'' devoted to the production of knowledge by logical means;<ref>Cfr. Carreras Artau, Tom<U+00E1>s y Joaqu<U+00ED>n. ''Historia de la filosof<U+00ED>a espa<U+00F1>ola. Filosof<U+00ED>a cristiana de los siglos XIII al XV''. Madrid, 1939, Volume I</ref> Llull described his machines as mechanical entities that could combine basic and undeniable truths by simple logical operations, produced by the machine by mechanical meanings, in such ways as to produce all the possible knowledge.<ref>Bonner, Anthonny, ''The Art and Logic of Ram<U+00F3>n Llull: A User's Guide'', Brill, 2007.</ref> Llull's work had a great influence on [[Gottfried Leibniz]], who redeveloped his ideas.<ref>Anthony Bonner (ed.), Doctor Illuminatus. A Ramon Llull Reader (Princeton University 1985). Vid. "Llull's Influence: The History of Lullism" at 57-71</ref>

[[Image:Gottfried Wilhelm von Leibniz.jpg||left|thumb|150px|[[Gottfried Leibniz]], who speculated that human reason could be reduced to mechanical calculation]]
In the 17th century, [[Gottfried Leibniz|Leibniz]], [[Thomas Hobbes]] and [[Ren<U+00E9> Descartes]] explored the possibility that all rational thought could be made as systematic as algebra or geometry.<ref>
17th century mechanism and AI:
* {{Harvnb|McCorduck|2004|pp=37<U+2013>46}}
* {{Harvnb|Russell|Norvig|2003|p=6}}
* {{Harvnb|Haugeland|1986|loc=chpt. 2}}
* {{Harvnb|Buchanan|2005|p=53}}
</ref>
[[Hobbes]] famously wrote in [[Leviathan (book)|''Leviathan'']]: "reason is nothing but reckoning".<ref>
Hobbes and AI:
* {{Harvnb|McCorduck|2004|p=42}}
* {{Harvnb|Hobbes|1651|loc=chapter 5}}
</ref>
[[Gottfried Leibniz|Leibniz]] envisioned a universal language of reasoning (his ''[[characteristica universalis]]'') which would reduce argumentation to calculation, so that "there would be no more need of disputation between two philosophers than between two accountants. For it would suffice to take their pencils in hand, down to their slates, and to say each other (with a friend as witness, if they liked): ''Let us calculate''."<ref>
Leibniz and AI:
* {{Harvnb|McCorduck|2004|p=41}}
* {{Harvnb|Russell|Norvig|2003|p=6}}
* {{Harvnb|Berlinski|2000|p=12}}
* {{Harvnb|Buchanan|2005|p=53}}
</ref>
These philosophers had begun to articulate the [[physical symbol system]] hypothesis that would become the guiding faith of AI research.

In the 20th century, the study of [[mathematical logic]] provided the essential breakthrough that made artificial intelligence seem plausible. The foundations had been set by such works as [[George Boole|Boole]]'s ''[[The Laws of Thought]]'' and [[Frege]]'s ''[[Begriffsschrift]]''. Building on [[Frege]]'s system, [[Bertrand Russell|Russell]] and [[Alfred North Whitehead|Whitehead]] presented a formal treatment of the foundations of mathematics in their masterpiece, the ''[[Principia Mathematica]]'' in 1913. Inspired by [[Bertrand Russell|Russell]]'s success, [[Hilbert's program|David Hilbert]] challenged mathematicians of the 1920s and 30s to answer this fundamental question: "can all of mathematical reasoning be formalized?"<ref name="Berlinski 2000"/>
His question was answered by [[Kurt G<U+00F6>del|G<U+00F6>del]]'s [[G<U+00F6>del's incompleteness theorems|incompleteness proof]], [[Alan Turing|Turing]]'s [[Turing machine|machine]] and [[Alonzo Church|Church]]'s [[Lambda calculus]].<ref name="Berlinski 2000"/><ref>
The [[Lambda calculus]] was especially important to AI, since it was an inspiration for [[Lisp programming language|Lisp]] (the most important programming language used in AI). {{Harv|Crevier|1993|pp=190&nbsp;196,61}}
</ref>
Their answer was surprising in two ways. First, they proved that there were, in fact, limits to what mathematical logic could accomplish.

[[Image:Classic shot of the ENIAC.jpg|right|thumbnail|250px|thumb|The ENIAC, at the Moore School of Electrical Engineering.]]
But second (and more important for AI) their work suggested that, within these limits, ''any'' form of mathematical reasoning could be mechanized. The [[Church-Turing thesis]] implied that a mechanical device, shuffling symbols as simple as 0 and 1, could imitate any conceivable process of mathematical deduction. The key insight was the [[Turing machine]]<U+2014>a simple theoretical construct that captured the essence of abstract symbol manipulation. This invention would inspire a handful of scientists to begin discussing the possibility of thinking machines.<ref name="Berlinski 2000"/><ref>
The [[Turing machine]]:
{{Harvnb|McCorduck|2004|pp=63<U+2013>64}},
{{Harvnb|Crevier|1993|pp=22<U+2013>24}},
{{Harvnb|Russell|Norvig|2003|p=8}} and see
{{Harvnb|Turing|1936}}</ref>

===Computer science===
:{{Main|history of computer hardware|history of computer science}}

Calculating machines were built in antiquity and improved throughout history by many mathematicians, including (once again) philosopher [[Gottfried Leibniz#Information technology|Gottfried Leibniz]]. In the early 19th century, [[Charles Babbage]] designed a programmable computer (the [[Analytical Engine]]), although it was never built. [[Ada Lovelace]] speculated that the machine "might compose elaborate and scientific pieces of music of any degree of complexity or extent".<ref name="Menabrea1843">Menabrea 1843</ref> (She is often credited as the first programmer because of [[Ada Byron's notes on the analytical engine|a set of notes]] she wrote that completely detail a method for calculating [[Bernoulli numbers]] with the Engine.)

The first modern computers were the massive code breaking machines of the [[Second World War]] (such as [[Z3 (computer)|Z3]], [[ENIAC]] and [[Colossus computer|Colossus]]).<ref>
{{Harvnb|McCorduck|2004|pp=61<U+2013>62, 64<U+2013>66}}, {{Harvnb|Russell|Norvig|2003|pp=14<U+2013>15}}</ref> The latter two of these machines were based on the theoretical foundation laid by  [[Alan Turing]] and developed by [[John Von Neumann]].<ref>
Von Neumann: {{Harvtxt|McCorduck|2004|pp=76<U+2013>80}}</ref>

==The birth of artificial intelligence 1943<U+2212>1956==
[[Image:BRL61-IBM 702.jpg|thumb|420px|The IBM 702: a computer used by the first generation of AI researchers.]]
''A note on the sections in this article''.<ref>
The starting and ending dates of the sections in this article are adopted from {{Harvnb|Crevier|1993}} and {{Harvnb|Russell|Norvig|2003|p=16<U+2212>27}}. Themes, trends and projects are treated in the period that the most important work was done.</ref>

In the 1940s and 50s, a handful of scientists from a variety of fields (mathematics, psychology, engineering, economics and political science) began to discuss the possibility of creating an artificial brain. The field of [[artificial intelligence]] research was founded as an academic discipline in 1956.

===Cybernetics and early neural networks===<!-- This section is linked to from [[Artificial intelligence]] -->
The earliest research into thinking machines was inspired by a confluence of ideas that became prevalent in the late 30s, 40s and early 50s. Recent research in [[neurology]] had shown that the brain was an electrical network of [[neuron]]s that fired in all-or-nothing pulses. [[Norbert Wiener]]'s [[cybernetic]]s described control and stability in electrical networks. [[Claude Shannon]]'s [[information theory]] described digital signals (i.e., all-or-nothing signals). [[Alan Turing]]'s [[theory of computation]] showed any form computation could be described digitally. The close relationship between these ideas suggested that it might be possible to construct an [[electronic brain]].<ref>
{{Harvnb|McCorduck|2004|pp=51<U+2013>57, 80<U+2013>107}},
{{Harvnb|Crevier|1993|pp=27<U+2013>32}},
{{Harvnb|Russell|Norvig|2003|pp=15, 940}},
{{Harvnb|Moravec|1988|p=3}},
{{Harvnb|Cordeschi|2002|Chap. 5}}.
</ref>

Examples of work in this vein includes robots such as [[W. Grey Walter]]'s [[Turtle (robot)|turtles]] and the [[Johns Hopkins Beast]]. These machines did not use computers, digital electronics or symbolic reasoning; they were controlled entirely by analog circuitry.<ref>
{{Harvnb|McCorduck|2004|p=98}}, {{Harvnb|Crevier|1993|pp=27<U+2212>28}}, {{Harvnb|Russell|Norvig|2003|pp=15, 940}}, {{Harvnb|Moravec|1988|p=3}}, {{Harvnb|Cordeschi|2002|Chap. 5}}.</ref>

[[Walter Pitts]] and [[Warren Sturgis McCulloch|Warren McCulloch]] analyzed networks of idealized artificial [[neurons]] and showed how they might perform simple logical functions. They were the first to describe what later researchers would call a [[neural network]].<ref>
{{Harvnb|McCorduck|2004|pp=51<U+2013>57, 88<U+2013>94}}, {{Harvnb|Crevier|1993|p=30}}, {{Harvnb|Russell|Norvig|2003|p=15<U+2212>16}}, {{Harvnb|Cordeschi|2002|Chap. 5}} and see also {{Harvnb|Pitts|McCullough|1943}}</ref> One of the students inspired by [[Walter Pitts|Pitts]] and [[Warren Sturgis McCulloch|McCulloch]] was a young [[Marvin Minsky]], then a 24 year old graduate student. In 1951 (with Dean Edmonds) he built the first neural net machine, the [[SNARC]].<ref>
{{Harvnb|McCorduck|2004|p=102}}, {{Harvnb|Crevier|1993|pp=34<U+2212>35}} and {{Harvnb|Russell|Norvig|2003|p=17}}</ref>
[[Marvin Minsky|Minsky]] was to become one of the most important leaders and innovators in AI for the next 50 years.

===Game AI===
In 1951, using the [[Ferranti Mark 1]] machine of the [[University of Manchester]], [[Christopher Strachey]] wrote a checkers program and Dietrich Prinz wrote one for chess.<ref>See [http://www.alanturing.net/turing_archive/pages/Reference%20Articles/BriefHistofComp.html "A Brief History of Computing"] at AlanTuring.net.</ref> [[Arthur Samuel]]'s checkers program, developed in the middle 50s and early 60s, eventually achieved sufficient skill to challenge a respectable amateur.<ref>Schaeffer, Jonathan. ''One Jump Ahead:: Challenging Human Supremacy in Checkers'', 1997,2009, Springer, ISBN 978-0-387-76575-4. Chapter 6.</ref> [[Game AI]] would continue to be used as a measure of progress in AI throughout its history.

===Turing's test===
In 1950 [[Alan Turing]] published a [[Computing machinery and intelligence|landmark paper]] in which he speculated about the possibility of creating machines with true intelligence.<ref>
{{Harvnb|McCorduck|2004|pp=70<U+2212>72}},
{{Harvnb|Crevier|1993|p=22<U+2212>25}},
{{Harvnb|Russell|Norvig|2003|pp=2<U+2212>3 and 948}},
{{Harvnb|Haugeland|1985|pp=6<U+2212>9}},
{{Harvnb|Cordeschi|2002|pp=170<U+2013>176}}.
See also
{{Harvnb|Turing|1950}}
</ref>
He noted that "intelligence" is difficult to define and devised his famous [[Turing Test]]. If a machine could carry on a conversation (over a [[teleprinter]]) that was indistinguishable from a conversation with a human being, then the machine could be called "intelligent." This simplified version of the problem allowed Turing to argue convincingly that a "thinking machine" was at least ''plausible'' and the paper answered all the most common objections to the proposition.<ref>{{Harvtxt|Norvig|Russell|2003|p=948}} claim that Turing answered all the major objections to AI that have been offered in the years since the paper appeared.</ref> The [[Turing Test]] was the first serious proposal in the [[philosophy of artificial intelligence]].

===Symbolic reasoning and the Logic Theorist===
When access to [[digital computer]]s became possible in the middle fifties, a few scientists instinctively recognized that a machine that could manipulate numbers could also manipulate symbols and that the manipulation of symbols could well be the essence of human thought. This was a new approach to creating thinking machines.<ref>{{Harvnb|McCorduck|2004|pp=137<U+2013>170}}, {{Harvnb|Crevier|pp=44<U+2013>47}}</ref>

In 1955, [[Allen Newell]] and (future Nobel Laureate) [[Herbert Simon]] created the "[[Logic Theorist]]" (with help from [[Cliff Shaw|J. C. Shaw]]). The program would eventually prove 38 of the first 52 theorems in [[Bertrand Russell|Russell]] and [[Alfred North Whitehead|Whitehead's]] ''[[Principia Mathematica]]'', and find new and more elegant proofs for some.<ref>
{{Harvnb|McCorduck|2004|pp=123<U+2013>125}}, {{Harvnb|Crevier|1993|pp=44<U+2212>46}} and {{Harvnb|Russell|Norvig|2003|p=17}}</ref>
Simon said that they had "solved the venerable [[mind/body problem]], explaining how a system composed of matter can have the properties of mind."<ref>
Quoted in {{Harvnb|Crevier|1993|p=46}} and {{Harvnb|Russell|Norvig|2003|p=17}}</ref>
(This was an early statement of the philosophical position [[John Searle]] would later call "[[Chinese Room#Strong AI|Strong AI]]": that machines can contain minds just as human bodies do.)<ref>
{{Harvnb|Russell|Norvig|2003|p=947,952}}</ref>

===Dartmouth Conference 1956: the birth of AI===
The [[Dartmouth Conference]] of 1956<ref>
{{Harvnb|McCorduck|2004|pp=111<U+2013>136}},
{{Harvnb|Crevier|1993|pp=49<U+2013>51}} and
{{Harvnb|Russell|Norvig|p=17}}
</ref>
was organized by [[Marvin Minsky]], [[John McCarthy (computer scientist)|John McCarthy]] and two senior scientists: [[Claude Shannon]] and [[Nathaniel Rochester (computer scientist)|Nathan Rochester]] of [[IBM]]. The proposal for the conference included this assertion: "every aspect of learning or any other feature of intelligence can be so precisely described that a machine can be made to simulate it".<ref>
See {{Harvnb|McCarthy|Minsky|Rochester|Shannon|1955}}. Also see {{Harvnb|Crevier|1993|p=48}} where [[Daniel Crevier|Crevier]] states "[the proposal] later became known as the 'physical symbol systems hypothesis'". The [[physical symbol system]] hypothesis was articulated and named by [[Allen Newell|Newell]] and [[Herbert Simon|Simon]] in their paper on [[General Problem Solver|GPS]]. {{Harv|Newell|Simon|1963}} It includes a more specific definition of a "machine" as an agent that manipulates symbols. See the [[philosophy of artificial intelligence]].</ref>
The participants included [[Ray Solomonoff]], [[Oliver Selfridge]], [[Trenchard More]], [[Arthur Samuel]], [[Allen Newell]] and [[Herbert Simon]], all of whom would create important programs during the first decades of AI research.<ref>
{{Harvtxt|McCorduck|2004|pp=129<U+2013>130}} discusses how the Dartmouth conference alumni dominated the first two decades of AI research, calling them the "invisible college".</ref>
At the conference Newell and Simon debuted the "[[Logic Theorist]]" and McCarthy persuaded the attendees to accept "Artificial Intelligence" as the name of the field.<ref>
"I won't swear and I hadn't seen it before," McCarthy told [[Pamela McCorduck]] in 1979. {{Harv|McCorduck|2004|p=114}} However, [[John McCarthy (computer scientist)|McCarthy]] also stated unequivocally "I came up with the term" in a [[CNET]] interview. {{Harv|Skillings|2006}}</ref>
The 1956 Dartmouth conference was the moment that AI gained its name, its mission, its first success and its major players, and is widely considered the birth of AI.<ref>
{{Harvtxt|Crevier|1993|pp=49}}  writes "the conference is generally recognized as the official birthdate of the new science."</ref>

==The golden years 1956<U+2212>1974==
The years after the Dartmouth conference were an era of discovery, of sprinting across new ground. The programs that were developed during this time were, to most people, simply "astonishing":<ref>Russell and Norvig write "it was astonishing whenever a computer did anything remotely clever." {{Harvnb|Russell|Norvig|2003|p=18}}</ref> computers were solving algebra word problems, proving theorems in geometry and learning to speak English. Few at the time would have believed that such "intelligent" behavior by machines was possible at all.<ref>{{Harvnb|Crevier|1993|pp=52<U+2212>107}}, {{Harvnb|Moravec|1988|p=9}} and {{Harvnb|Russell|Norvig|2003|p=18<U+2212>21}}</ref> Researchers expressed an intense optimism in private and in print, predicting that a fully intelligent machine would be built in less than 20 years.<ref>{{Harvnb|McCorduck|2004|p=218}}, {{Harvnb|Crevier|1993|pp=108<U+2212>109}} and {{Harvnb|Russell|Norvig|2003|p=21}}</ref> Government agencies like [[DARPA|ARPA]] poured money into the new field.<ref>{{Harvnb|Crevier|1993|pp=52<U+2212>107}}, {{Harvnb|Moravec|1988|p=9}}</ref>

===The work===
There were many successful programs and new directions in the late 50s and 1960s. Among the most influential were these:

====Reasoning as search====
Many early AI programs used the same basic [[algorithm]]. To achieve some goal (like winning a game or proving a theorem), they proceeded step by step towards it (by making a move or a deduction) as if searching through a maze, [[backtracking]] whenever they reached a dead end. This paradigm was called "[[reasoning as search]]".<ref>Means-ends analysis, reasoning as search: {{Harvnb|McCorduck|2004|pp=247<U+2013>248}}. {{Harvnb|Russell|Norvig|2003|pp=59<U+2212>61}}</ref>

The principal difficulty was that, for many problems, the number of possible paths through the "maze" was simply astronomical (a situation known as a "[[combinatorial explosion]]"). Researchers would reduce the search space by using [[heuristics]] or "rules of thumb" that would eliminate those paths that were unlikely to lead to a solution.<ref>Heuristic: {{Harvnb|McCorduck|2004|p=246}}, {{Harvnb|Russell|Norvig|2003|pp=21<U+2212>22}}</ref>

[[Allen Newell|Newell]] and [[Herbert Simon|Simon]] tried to capture a general version of this algorithm in a program called the "[[General Problem Solver]]".<ref>GPS: {{Harvnb|McCorduck|2004|pp=245<U+2013>250}}, {{Harvnb|Crevier|1993|p=GPS?}}, {{Harvnb|Russell|Norvig|2003|p=GPS?}}</ref> Other "searching" programs were able to accomplish impressive tasks like solving problems in geometry and algebra, such as [[Herbert Gelernter]]'s [[Geometry theorem prover|Geometry Theorem Prover]] (1958) and [[Symbolic automatic integrator|SAINT]], written by [[Marvin Minsky|Minsky's]] student [[James Slagle]] (1961).<ref>{{Harvnb|Crevier|1993|pp=51<U+2212>58,65<U+2212>66}} and {{Harvnb|Russell|Norvig|2003|pp=18<U+2212>19}}</ref> Other programs searched through goals and subgoals to plan actions, like the [[STRIPS]] system developed at [[Stanford]] to control the behavior of their robot [[Shakey the Robot|Shakey]].<ref>{{Harvnb|McCorduck|2004|pp=268<U+2013>271}}, {{Harvnb|Crevier|1993|pp=95<U+2212>96}}, {{Harvnb|Moravec|1988|pp=14<U+2212>15}}</ref>

[[Image:Semantic Net.svg|thumb|250px|An example of a semantic network]]

====Natural language====
An important goal of AI research is to allow computers to communicate in [[natural language processing|natural languages]] like English. An early success was [[Daniel Bobrow]]'s program [[STUDENT (computer program)|STUDENT]], which could solve high school algebra word problems.<ref>{{Harvnb|McCorduck|2004|p=286}}, {{Harvnb|Crevier|1993|pp=76<U+2212>79}}, {{Harvnb|Russell|Norvig|2003|p=19}}</ref>

A [[semantic net]] represents concepts (e.g. "house","door") as nodes and relations among concepts (e.g. "has-a") as links between the nodes. The first AI program to use a semantic net was written by [[Ross Quillian]]<ref>{{Harvnb|Crevier|1993|pp=79<U+2212>83}}</ref> and the most successful (and controversial) version was [[Roger Schank]]'s [[Conceptual dependency theory]].<ref>{{Harvnb|Crevier|1993|pp=164<U+2212>172}}</ref>

[[Joseph Weizenbaum]]'s [[ELIZA]] could carry out conversations that were so realistic that users occasionally were fooled into thinking they were communicating with a human being and not a program. But in fact, ELIZA had no idea what she was talking about. She simply gave a [[canned response]] or repeated back what was said to her, rephrasing her response with a few grammar rules. ELIZA was the first [[chatterbot]].<ref>{{Harvnb|McCorduck|2004|pp=291<U+2013>296}}, {{Harvnb|Crevier|1993|pp=134<U+2212>139}}</ref>

====Micro-worlds====
In the late 60s, [[Marvin Minsky]] and [[Seymour Papert]] of the [[MIT]] AI Laboratory proposed that AI research should focus on artificially simple situations known as micro-worlds. They pointed out that in successful sciences like physics, basic principles were often best understood using simplified models like frictionless planes or perfectly rigid bodies. Much of the research focused on a "[[blocks world]]," which consists of colored blocks of various shapes and sizes arrayed on a flat surface.<ref>{{Harvnb|McCorduck|2004|pp=299<U+2013>305}}, {{Harvnb|Crevier|1993|pp=83<U+2212>102}}, {{Harvnb|Russell|Norvig|2003|p=19}} and {{Harvnb|Copeland|2000}}</ref>

This paradigm led to innovative work in [[machine vision]] by [[Gerald Sussman]] (who led the team), [[Adolfo Guzman]], [[David Waltz]] (who invented "[[constraint propagation]]"), and especially [[Patrick Winston]]. At the same time, [[Marvin Minsky|Minsky]] and [[Seymour Papert|Papert]] built a robot arm that could stack blocks, bringing the blocks world to life. The crowning achievement of the micro-world program was [[Terry Winograd]]'s [[SHRDLU]]. It could communicate in ordinary English sentences, plan operations and execute them.<ref>{{Harvnb|McCorduck|2004|pp=300<U+2013>305}}, {{Harvnb|Crevier|1993|pp=84<U+2212>102}}, {{Harvnb|Russell|Norvig|2003|p=19}}</ref>

===The optimism===
The first generation of AI researchers made these predictions about their work:
* 1958, [[H. A. Simon]] and [[Allen Newell]]: "within ten years a digital computer will be the world's chess champion" and "within ten years a digital computer will discover and prove an important new mathematical theorem."<ref>{{Harvnb|Simon|Newell|1958|p=7<U+2212>8}} quoted in {{Harvnb|Crevier|1993|p=108}}. See also {{Harvnb|Russell|Norvig|2003|p=21}}</ref>
* 1965, [[H. A. Simon]]: "machines will be capable, within twenty years, of doing any work a man can do."<ref>{{Harvnb|Simon|1965|p=96}} quoted in {{Harvnb|Crevier|1993|p=109}}</ref>
* 1967, [[Marvin Minsky]]: "Within a generation ... the problem of creating 'artificial intelligence' will substantially be solved."<ref>{{Harvnb|Minsky|1967|p=2}} quoted in {{Harvnb|Crevier|1993|p=109}}</ref>
* 1970, [[Marvin Minsky]] (in [[Life magazine|''Life'' Magazine]]): "In from three to eight years we will have a machine with the general intelligence of an average human being."<ref>Minsky strongly believes he was misquoted. See {{Harvnb|McCorduck|2004|pp=272<U+2013>274}}, {{Harvnb|Crevier|1993|p=96}} and {{Harvnb|Darrach|1970}}.</ref>

===The money===
In June 1963 [[MIT]] received a $2.2 million grant from the newly created Advanced Research Projects Agency (later known as [[DARPA]]). The money was used to fund [[project MAC]] which subsumed the "AI Group" founded by [[Marvin Minsky|Minsky]] and [[John McCarthy (computer scientist)|McCarthy]] five years earlier. [[DARPA|ARPA]] continued to provide three million dollars a year until the 70s.<ref>{{Harvnb|Crevier|1993|pp=64<U+2212>65}}</ref>
[[DARPA|ARPA]] made similar grants to [[Allen Newell|Newell]] and [[Herbert Simon|Simon's]] program at [[Carnegie Mellon University|CMU]] and to the [[Stanford Artificial Intelligence Laboratory|Stanford AI Project]] (founded by [[John McCarthy (computer scientist)|John McCarthy]] in 1963).<ref>{{Harvnb|Crevier|1993|p=94}}</ref> Another important AI laboratory was established at [[Edinburgh University]] by [[Donald Michie]] in 1965.<ref>{{Harvnb|Howe|1994}}</ref>
These four institutions would continue to be the main centers of AI research (and funding) in academia for many years.<ref>{{Harvnb|McCorduck|2004|p=131}}, {{Harvnb|Crevier|1993|p=51}}. McCorduck also notes that funding was mostly under the direction of alumni of the [[Dartmouth conference]] of 1956.</ref>

The money was proffered with few strings attached: [[J. C. R. Licklider]], then the director of [[DARPA|ARPA]], believed that his organization should "fund people, not projects!" and allowed researchers to pursue whatever directions might interest them.<ref>{{Harvnb|Crevier|1993|p=65}}</ref> This created a freewheeling atmosphere at [[MIT]] that gave birth to the [[Hacker (programmer subculture)|hacker]] culture,<ref>{{Harvnb|Crevier|1993|pp=68<U+2212>71}} and {{Harvnb|Turkle|1984}}</ref> but this "hands off" approach would not last.

==The first AI winter 1974<U+2212>1980==
In the 70s, AI was subject to critiques and financial setbacks. AI researchers had failed to appreciate the difficulty of the problems they faced. Their tremendous optimism had raised expectations impossibly high, and when the promised results failed to materialize, funding for AI disappeared.<ref>{{Harvnb|Crevier|1993|pp=100<U+2212>144}} and {{Harvnb|Russell|Norvig|2003|pp=21<U+2212>22}}</ref> At the same time, the field of [[connectionism]] (or [[neural nets]]) was shut down almost completely for 10 years by [[Marvin Minsky]]'s devastating criticism of [[perceptrons]].<ref name="Perceptrons">
{{Harvnb|McCorduck|2004|pp=104<U+2212>107}},
{{Harvnb|Crevier|1993|pp=102<U+2212>105}},
{{Harvnb|Russell|Norvig|2003|p=22}}</ref>
Despite the difficulties with public perception of AI in the late 70s, new ideas were explored in [[logic programming]], [[commonsense reasoning]] and many other areas.<ref>{{Harvnb|Crevier| 1993|pp=163<U+2212>196}}</ref>

===The problems===
In the early seventies, the capabilities of AI programs were limited. Even the most impressive could only handle trivial versions of the problems they were supposed to solve; all the programs were, in some sense, "toys".<ref>{{Harvnb|Crevier|1993|p=146}}</ref> AI researchers had begun to run into several fundamental limits that could not be overcome in the 1970s. Although some of these limits would be conquered in later decades, others still stymie the field to this day.<ref>{{Harvnb|Russell|Norvig|2003|pp=20<U+2212>21}}</ref>
* '''Limited computer power''': There was not enough memory or processing speed to accomplish anything truly useful. For example, [[Ross Quillian]]'s successful work on natural language was demonstrated with a vocabulary of only ''twenty'' words, because that was all that would fit in memory.<ref>{{Harvnb|Crevier|1993|pp=146<U+2212>148}}, see also {{Harvnb|Buchanan|2005|p=56}}: "Early programs were necessarily limited in scope by the size and speed of memory"</ref> [[Hans Moravec]] argued in 1976 that computers were still millions of times too weak to exhibit intelligence. He suggested an analogy: artificial intelligence requires computer power in the same way that aircraft require power. Below a certain threshold, it's impossible, but, as power [[Moore's law|increases]], eventually it could become easy.<ref>{{Harvnb|Moravec|1976}}. [[John McCarthy (computer scientist)|McCarthy]] has always disagreed with Moravec, back to their early days together at [[Stanford Artificial Intelligence Laboratory|SAIL]]. He states "I would say that 50 years ago, the machine capability was much too small, but by 30 years ago, machine capability wasn't the real problem." in a [[CNET]] interview. {{Harv|Skillings|2006}}</ref> With regard to computer vision, Moravec estimated that simply matching the edge and motion detection capabilities of human retina in real time would require a general-purpose computer capable of 10<sup>9</sup> operations/second (1000 MIPS).<ref>{{Citation|title=ROBOT: Mere Machine to Transcendent Mind|author=Hans Moravec}}</ref> As of 2011, practical computer vision applications require 10,000 to 1,000,000 MIPS. By comparison, the fastest supercomputer in 1976, [[Cray-1]] (retailing at $5 million to $8 million), was only capable of around 80 to 130 MIPS, and a typical desktop computer at the time achieved less than 1 MIPS.

* '''[[Intractability (complexity)|Intractability]] and the [[combinatorial explosion]]'''. In 1972 [[Richard Karp]] (building on [[Stephen Cook]]'s 1971 [[Cook's theorem|theorem]]) showed there are [[Karp's 21 NP-complete problems|many problems]] that can probably only be solved in [[exponential time]] (in the size of the inputs). Finding optimal solutions to these problems requires unimaginable amounts of computer time except when the problems are trivial. This almost certainly meant that many of the "toy" solutions used by AI would probably never scale up into useful systems.<ref>{{Harvnb|Russell|Norvig|2003|pp=9,21<U+2212>22}} and {{Harvnb|Lighthill|1973}}</ref>
* '''[[Commonsense knowledge]] and [[commonsense reasoning|reasoning]]'''. Many important artificial intelligence applications like [[computer vision|vision]] or [[natural language]] require simply enormous amounts of information about the world: the program needs to have some idea of what it might be looking at or what it is talking about. This requires that the program know most of the same things about the world that a child does. Researchers soon discovered that this was a truly ''vast'' amount of information. No one in 1970 could build a database so large and no one knew how a program might learn so much information.<ref>{{Harvnb|McCorduck|2004|pp=300 & 421}}, {{Harvnb|Crevier|1993|pp=113<U+2212>114}}, {{Harvnb|Moravec|1988|p=13}}, {{Harvnb|Lenat|1989}} (Introduction) and {{Harvnb|Russell|Norvig|2003|p=21}}</ref>
* '''[[Moravec's paradox]]''': Proving theorems and solving geometry problems is comparatively easy for computers, but a supposedly simple task like recognizing a face or crossing a room without bumping into anything is extremely difficult. This helps explain why research into [[machine vision|vision]] and [[robotics]] had made so little progress by the middle 1970s.<ref>{{Harvnb|McCorduck|2004|p=456}}, {{Harvnb|Moravec|1988|pp=15<U+2212>16}}</ref>
* '''The [[frame problem|frame]] and [[qualification problem]]s'''. AI researchers (like [[John McCarthy (computer scientist)|John McCarthy]]) who used [[logic]] discovered that they could not represent ordinary deductions that involved [[automated planning and scheduling|planning]] or default reasoning without making changes to the structure of logic itself. They developed new logics (like [[non-monotonic logic]]s and [[modal logic]]s) to try to solve the problems.<ref>{{Harvnb|McCarthy|Hayes|1969}}, {{Harvnb|Crevier|1993|pp=117<U+2212>119}}</ref>

===The end of funding===
{{See also|AI Winter}}

The agencies which funded AI research (such as the [[British government]], [[DARPA]] and [[United States National Research Council|NRC]]) became frustrated with the lack of progress and eventually cut off almost all funding for undirected research into AI. The pattern began as early as 1966 when the [[ALPAC]] report appeared criticizing machine translation efforts. After spending 20 million dollars, the [[United States National Research Council|NRC]] ended all support.<ref>
{{Harvnb|McCorduck|2004|pp=280<U+2013>281}}, {{Harvnb|Crevier|1993|p=110}}, {{Harvnb|Russell|Norvig|2003|p=21}} and {{Harvnb|NRC|1999}} under "Success in Speech Recognition".
</ref>
In 1973, the [[Lighthill report]] on the state of AI research in England criticized the utter failure of AI to achieve its "grandiose objectives" and led to the dismantling of AI research in that country.<ref>
{{Harvnb|Crevier|1993|p=117}}, {{Harvnb|Russell|Norvig|2003|p=22}}, {{Harvnb|Howe|1994}} and see also {{Harvnb|Lighthill|1973}}.
</ref>
(The report specifically mentioned the [[combinatorial explosion]] problem as a reason for AI's failings.)<ref>
{{Harvnb|Russell|Norvig|2003|p=22}}, {{Harvnb|Lighthill|1973}},  [[John McCarthy (computer scientist)|John McCarthy]] wrote in response that "the combinatorial explosion problem has been recognized in AI from the beginning" in [http://www-formal.stanford.edu/jmc/reviews/lighthill/lighthill.html Review of Lighthill report]
</ref>
[[DARPA]] was deeply disappointed with researchers working on the [[speech recognition|Speech Understanding Research]] program at [[Carnegie Mellon University|CMU]] and canceled an annual grant of three million dollars.<ref>
{{Harvnb|Crevier|1993|pp=115<U+2212>116}} (on whom this account is based). Other views include {{Harvnb|McCorduck|2004|pp=306<U+2013>313}} and {{Harvnb|NRC|1999}} under "Success in Speech Recognition".
</ref>
By 1974, funding for AI projects was hard to find.

[[Hans Moravec]] blamed the crisis on the unrealistic predictions of his colleagues. "Many researchers were caught up in a web of increasing exaggeration."<ref>
{{Harvnb|Crevier|1993|p=115}}. Moravec explains, "Their initial promises to DARPA had been much too optimistic. Of course, what they delivered stopped considerably short of that. But they felt they couldn't in their next proposal promise less than in the first one, so they promised more."
</ref>
However, there was another issue: since the passage of the [[Mansfield Amendment]] in 1969, [[DARPA]] had been under increasing pressure to fund "mission-oriented direct research, rather than basic undirected research". Funding for the creative, freewheeling exploration that had gone on in the 60s would not come from [[DARPA]]. Instead, the money was directed at specific projects with clear objectives, such as autonomous tanks and battle management systems.<ref>
{{Harvnb|NRC|1999}} under "Shift to Applied Research Increases Investment." While the autonomous tank was a failure, the battle management system (called "[[Dynamic Analysis and Replanning Tool|DART]]") proved to be enormously successful, saving billions in the first [[Gulf War]], repaying the investment and justifying the [[DARPA]]'s pragmatic policy, at least as far as [[DARPA]] was concerned.
</ref>

===Critiques from across campus===
{{See also|Philosophy of artificial intelligence}}

Several philosophers had strong objections to the claims being made by AI researchers. One of the earliest was [[John Lucas (philosopher)|John Lucas]], who argued that [[Kurt G<U+00F6>del|G<U+00F6>del's]] [[G<U+00F6>del's incompleteness theorem|incompleteness theorem]] showed that a [[formal system]] (such as a computer program) could never see the truth of certain statements, while a human being could.<ref>Lucas and Penrose' critique of AI: {{Harvnb|Crevier 1993|p=22}}, {{Harvnb|Russell|Norvig|2003|pp=949<U+2212>950}}, {{Harvnb|Hofstadter|1980|pp=471<U+2212>477}} and see {{Harvnb|Lucas|1961}}</ref> [[Hubert Dreyfus]] ridiculed the broken promises of the 60s and critiqued the assumptions of AI, arguing that human reasoning actually involved very little "symbol processing" and a great deal of [[embodied cognition|embodied]], [[instinct]]ive, unconscious "[[ready-to-hand|know how]]".<ref>"Know-how" is Dreyfus' term. (Dreyfus makes a distinction between "knowing how" and "knowing that", a modern version of [[Heidegger]]'s distinction of [[ready-to-hand]] and [[present-at-hand]].) {{Harv|Dreyfus|Dreyfus|1986}}</ref><ref>[[Dreyfus' critique of artificial intelligence]]: {{Harvnb|McCorduck|2004|pp=211<U+2212>239}}, {{Harvnb|Crevier|1993|pp=120<U+2212>132}}, {{Harvnb|Russell|Norvig|2003|pp=950<U+2212>952}} and see {{Harvnb|Dreyfus|1965}}, {{Harvnb|Dreyfus|1972}}, {{Harvnb|Dreyfus|Dreyfus|1986}}</ref> [[John Searle]]'s [[Chinese Room]] argument, presented in 1980, attempted to show that a program could not be said to "understand" the symbols that it uses (a quality called "[[intentionality]]"). If the symbols have no meaning for the machine, Searle argued, then the machine can not be described as "thinking".<ref>Searle's critique of AI: {{Harvnb|McCorduck|2004|pp=443<U+2212>445}}, {{Harvnb|Crevier|1993|pp=269<U+2212>271}}, {{Harvnb|Russell|Norvig|2004|pp=958<U+2212>960}} and see {{Harvnb|Searle|1980}}</ref>

These critiques were not taken seriously by AI researchers, often because they seemed so far off the point. Problems like [[intractability (complexity)|intractability]] and [[Commonsense reasoning|commonsense knowledge]] seemed much more immediate and serious. It was unclear what difference "[[ready-to-hand|know how]]" or "[[intentionality]]" made to an actual [[computer program]]. [[Marvin Minsky|Minsky]] said of Dreyfus and Searle "they misunderstand, and should be ignored."<ref>Quoted in {{Harvnb|Crevier|1993|p=143}}</ref> Dreyfus, who taught at [[MIT]], was given a cold shoulder: he later said that AI researchers "dared not be seen having lunch with me."<ref>Quoted in {{Harvnb|Crevier|1993|p=122}}</ref> [[Joseph Weizenbaum]], the author of [[ELIZA]], felt his colleagues' treatment of [[Hubert Dreyfus|Dreyfus]] was unprofessional and childish. Although he was an outspoken critic of Dreyfus' positions, he "deliberately made it plain that theirs was not the way to treat a human being."<ref>"I became the only member of the AI community to be seen eating lunch with Dreyfus. And I deliberately made it plain that theirs was not the way to treat a human being." [[Joseph Weizenbaum]], quoted in {{Harvnb|Crevier|1993|p=123}}.</ref>

Weizenbaum began to have serious ethical doubts about AI when [[Kenneth Colby]] wrote [[ELIZA|DOCTOR]], a [[chatterbot]] therapist. Weizenbaum was disturbed that Colby saw his mindless program as a serious therapeutic tool. A feud began, and the situation was not helped when Colby did not credit Weizenbaum for his contribution to the program. In 1976, [[Joseph Weizenbaum|Weizenbaum]] published ''[[Computer Power and Human Reason]]'' which argued that the misuse of artificial intelligence has the potential to devalue human life.<ref>Weizenbaum's critique of AI: {{Harvnb|McCorduck|2004|pp=356<U+2212>373}}, {{Harvnb|Crevier|1993|pp=132<U+2212>144}}, {{Harvnb|Russell|Norvig|2003|p=961}} and see {{Harvnb|Weizenbaum|1976}}</ref>

===Perceptrons and the dark age of connectionism===
A [[perceptron]] was a form of [[neural network]] introduced in 1958 by [[Frank Rosenblatt]], who had been a schoolmate of [[Marvin Minsky]] at the [[Bronx High School of Science]]. Like most AI researchers, he was optimistic about their power, predicting that "perceptron may eventually be able to learn, make decisions, and translate languages." An active research program into the paradigm was carried out throughout the 60s but came to a sudden halt with the publication of [[Marvin Minsky|Minsky]] and [[Seymour Papert|Papert's]] 1969 book ''[[Perceptrons (book)|Perceptrons]]''. It suggested that there were severe limitations to what perceptrons could do and that [[Frank Rosenblatt]]'s predictions had been grossly exaggerated. The effect of the book was devastating: virtually no research at all was done in [[connectionism]] for 10 years. Eventually, a new generation of researchers would revive the field and thereafter it would become a vital and useful part of artificial intelligence. [[Frank Rosenblatt|Rosenblatt]] would not live to see this, as he died in a boating accident shortly after the book was published.<ref name="Perceptrons"/>

===The neats: logic, Prolog and expert systems===
Logic was introduced into AI research as early as 1958, by [[John McCarthy (computer scientist)|John McCarthy]] in his [[Advice Taker]] proposal.<ref>
{{Harvnb|McCorduck|2004|p=51}}, {{Harvnb|Russell|Norvig|2003|pp=19, 23}}
</ref>
In 1963, [[J. Alan Robinson]] had discovered a simple method to implement deduction on computers, the [[resolution (logic)|resolution]] and [[unification (computing)|unification]] algorithm. However, straightforward implementations, like those attempted by McCarthy and his students in the late 60s, were especially intractable: the programs required astronomical numbers of steps to prove simple theorems.<ref>
{{Harvnb|McCorduck|2004|p=51}}, {{Harvnb|Crevier|1993|pp=190<U+2212>192}}</ref> A more fruitful approach to logic was developed in the 70s by [[Robert Kowalski]] at the [[University of Edinburgh]], and soon this led to the collaboration with French researchers [[Alain Colmerauer]] and [[Phillipe Roussel]] who created the successful logic programming language [[Prolog]].<ref>
{{Harvnb|Crevier|1993|pp=193<U+2212>196}}</ref>
Prolog uses a subset of logic ([[Horn clause]]s, closely related to "rules" and "[[production system|production rules]]") that permit tractable computation. Rules would continue to be influential, providing a foundation for [[Edward Feigenbaum]]'s [[expert systems]] and the continuing work by [[Allen Newell]] and [[Herbert Simon]] that would lead to [[Soar (cognitive architecture)|Soar]] and their [[Unified Theory of Cognition|unified theories of cognition]].<ref>{{Harvnb|Crevier|1993|pp=145<U+2212>149,258<U+2212>63}}</ref>

Critics of the logical approach noted, as [[Hubert Dreyfus|Dreyfus]] had, that human beings rarely used logic when they solved problems. Experiments by psychologists like [[Peter Cathcart Wason|Peter Wason]], [[Eleanor Rosch]], [[Amos Tversky]], [[Daniel Kahneman]] and others provided proof.<ref>
{{Harvtxt|Wason|1966}} showed that people do poorly on completely abstract problems, but if the problem is restated to allowed the use of intuitive [[social intelligence]], performance dramatically improves. (See [[Wason selection task]]) {{Harvtxt|Tversky|Slovic|Kahnemann|1982}} have shown that people are terrible at elementary problems that involve uncertain reasoning. (See [[list of cognitive biases]] for several examples). [[Eleanor Rosch]]'s work is described in {{Harvnb|Lakoff|1987}}
</ref>
McCarthy responded that what people do is irrelevant. He argued that what is really needed are machines that can solve problems<U+2014>not machines that think as people do.<ref>
An early example of [[John McCarthy (computer scientist)|McCathy's]] position was in the journal [[Science (journal)|Science]] where he said "This is AI, so we don't care if it's psychologically real" {{Harv|Kolata|1982}}, and he recently reiterated his position at the [[AI@50]] conference where he said "Artificial intelligence is not, by definition, simulation of human intelligence" {{Harv|Maker|2006}}.</ref>

===The scruffies: frames and scripts===
Among the critics of [[John McCarthy (computer scientist)|McCarthy's]] approach were his colleagues across the country at [[MIT]]. [[Marvin Minsky]], [[Seymour Papert]] and [[Roger Schank]] were trying to solve problems like "story understanding" and "object recognition" that ''required'' a machine to think like a person. In order to use ordinary concepts like "chair" or "restaurant" they had to make all the same illogical assumptions that people normally made. Unfortunately, imprecise concepts like these are hard to represent in logic. [[Gerald Sussman]] observed that "using precise language to describe essentially imprecise concepts doesn't make them any more precise."<ref>{{Harvnb|Crevier|1993|pp=175}}</ref> [[Roger Schank|Schank]] described their "anti-logic" approaches as "[[Neats vs. scruffies|scruffy]]", as opposed to the "[[Neats vs. scruffies|neat]]" paradigms used by [[John McCarthy (computer scientist)|McCarthy]], [[Robert Kowalski|Kowalski]], [[Edward Feigenbaum|Feigenbaum]], [[Allen Newell|Newell]] and [[Herbert Simon|Simon]].<ref>Neat vs. scruffy: {{Harvnb|McCorduck|2004|pp=421<U+2013>424}} (who picks up the state of the debate in 1984). {{Harvnb|Crevier|1993|pp=168}} (who documents Schank's original use of the term). Another aspect of the conflict was called "the procedural/declarative distinction" but did not prove to be influential in later AI research.</ref>

In 1975, in a seminal paper, [[Marvin Minsky|Minsky]] noted that many of his fellow "scruffy" researchers were using the same kind of tool: a framework that captures all our [[commonsense knowledge|common sense assumptions]] about something. For example, if we use the concept of a bird, there is a constellation of facts that immediately come to mind: we might assume that it flies, eats worms and so on. We know these facts are not always true and that deductions using these facts will not be "logical", but these structured sets of assumptions are part of the ''context'' of everything we say and think. He called these structures "[[Frame (Artificial intelligence)|frames]]". [[Roger Schank|Schank]] used a version of frames he called "[[Scripts (artificial intelligence)|scripts]]" to successfully answer questions about short stories in English.<ref>{{Harvnb|McCorduck|2004|pp=305<U+2013>306}}, {{Harvnb|Crevier|1993|pp=170<U+2212>173, 246}} and {{Harvnb|Russell|Norvig|2003|p=24}}. Minsky's frame paper: {{Harvnb|Minsky|1974}}.</ref> Many years later [[object-oriented programming]] would adopt the essential idea of "[[inheritance (computer science)|inheritance]]" from AI research on frames.

==Boom 1980<U+2013>1987==
In the 1980s a form of AI program called "[[expert system]]s" was adopted by corporations around the world and [[knowledge representation|knowledge]] became the focus of mainstream AI research. In those same years, the Japanese government aggressively funded AI with its [[fifth generation computer]] project. Another encouraging event in the early 1980s was the revival of [[connectionism]] in the work of [[John Hopfield]] and [[David Rumelhart]]. Once again, AI had achieved success.

===The rise of expert systems===
An [[expert system]] is a program that answers questions or solves problems about a specific domain of knowledge, using logical [[production system|rules]] that are derived from the knowledge of experts. The earliest examples were developed by [[Edward Feigenbaum]] and his students. [[Dendral]], begun in 1965, identified compounds from spectrometer readings. [[MYCIN]], developed in 1972, diagnosed infectious blood diseases. They demonstrated the feasibility of the approach.<ref>{{Harvnb|McCorduck|2004|pp=327<U+2013>335}} ([[Dendral]]), {{Harvnb|Crevier|1993|pp=148<U+2212>159}}, {{Harvnb|Russell|Norvig|2003|pp=22<U+2212>23}}</ref>

Expert systems restricted themselves to a small domain of specific knowledge (thus avoiding the [[commonsense knowledge]] problem) and their simple design made it relatively easy for programs to be built and then modified once they were in place. All in all, the programs proved to be ''useful'': something that AI had not been able to achieve up to this point.<ref>{{harvnb|Crevier|1993|pp=158<U+2212>159}} and {{Harvnb|Russell|Norvig|2003|p=23<U+2212>24}}</ref>

In 1980, an expert system called [[XCON]] was completed at [[Carnegie Mellon University|CMU]] for the [[Digital Equipment Corporation]]. It was an enormous success: it was saving the company 40 million dollars annually by 1986.<ref>{{Harvnb|Crevier|1993|p=198}}</ref> Corporations around the world began to develop and deploy expert systems and by 1985 they were spending over a billion dollars on AI, most of it to in-house AI departments. An industry grew up to support them, including hardware companies like [[Symbolics]] and [[Lisp Machines]] and software companies such as [[IntelliCorp (Software)|IntelliCorp]] and [[Cleverpath AION Business Rules Expert|Aion]].<ref>{{Harvnb|McCorduck|2004|pp=434<U+2013>435}}, {{Harvnb|Crevier|1993|pp=161<U+2212>162,197<U+2212>203}} and {{Harvnb|Russell|Norvig|2003|p=24}}</ref>

===The knowledge revolution===
The power of expert systems came from the expert knowledge they contained. They were part of a new direction in AI research that had been gaining ground throughout the 70s. "AI researchers were beginning to suspect<U+2014>reluctantly, for it violated the scientific canon of parsimony<U+2014>that intelligence might very well be based on the ability to use large amounts of diverse knowledge in different ways,"<ref>{{Harvnb|McCorduck|2004|p=299}}</ref> writes [[Pamela McCorduck]]. "[T]he great lesson from the 1970s was that intelligent behavior depended very much on dealing with knowledge, sometimes quite detailed knowledge, of a domain where a given task lay".<ref>{{Harvnb|McCorduck|2004|pp=421}}</ref> [[Knowledge based system]]s and [[knowledge engineering]] became a major focus of AI research in the 1980s.<ref>Knowledge revolution: {{Harvnb|McCorduck|2004|pp=266<U+2013>276, 298<U+2013>300, 314, 421}}, {{Harvnb|Russell|Norvig|pp=22<U+2013>23}}</ref>

The 1980s also saw the birth of [[Cyc]], the first attempt to attack the [[commonsense reasoning|commonsense knowledge problem]] directly, by creating a massive database that would contain all the mundane facts that the average person knows. [[Douglas Lenat]], who started and led the project, argued that there is no shortcut <U+2015> the only way for machines to know the meaning of human concepts is to teach them, one concept at a time, by hand. The project was not expected to be completed for many decades.<ref>Cyc: {{Harvnb|McCorduck|2004|p=489}}, {{Harvnb|Crevier|1993|pp=239<U+2212>243}}, {{Harvnb|Russell|Norvig|2003|p=363<U+2212>365}} and {{Harvnb|Lenat|Guha|1989}}</ref>

===The money returns: the fifth generation project===
In 1981, the [[Ministry of International Trade and Industry|Japanese Ministry of International Trade and Industry]] set aside $850 million dollars for the [[Fifth generation computer]] project. Their objectives were to write programs and build machines that could carry on conversations, translate languages, interpret pictures, and reason like human beings.<ref>{{Harvnb|McCorduck|2004|pp=436<U+2013>441}}, {{Harvnb|Crevier|1993|pp=211}}, {{Harvnb|Russell|Norvig|2003|p=24}} and see also {{Harvnb|Feigenbaum|McCorduck|1983}}</ref> Much to the chagrin of [[neats vs. scruffies|scruffies]], they chose [[Prolog]] as the primary computer language for the project.<ref>{{harvnb|Crevier|1993|pp=195}}</ref>

Other countries responded with new programs of their own. The UK began the <U+20A4>350 million [[Alvey]] project. A consortium of American companies formed the [[Microelectronics and Computer Technology Corporation]] (or "MCC") to fund large scale projects in AI and information technology.<ref>{{harvnb|Crevier|1993|pp=240}}.</ref><ref name = "Norvig 25" /> [[DARPA]] responded as well, founding the [[Strategic Computing Initiative]] and tripling its investment in AI between 1984 and 1988.<ref>{{Harvnb|McCorduck|2004|pp=426<U+2013>432}}, {{Harvnb|NRC|1999}} under "Shift to Applied Research Increases Investment"</ref>
[[Image:Hopfield-net.png|thumb|left|A Hopfield net with four nodes.]]

===The revival of connectionism===
In 1982, physicist [[John Hopfield]] was able to prove that a form of neural network (now called a "[[Hopfield net]]") could learn and process information in a completely new way. Around the same time, [[David Rumelhart]] popularized a new method for training neural networks called "[[backpropagation]]" (discovered years earlier by [[Paul Werbos]]). These two discoveries revived the field of [[connectionism]] which had been largely abandoned since 1970.<ref name = "Norvig 25">{{Harvnb|Russell|Norvig|2003|p=25}}</ref><ref>{{harvnb|Crevier|1993|pp=214<U+2212>215}}.</ref>

The new field was unified and inspired by the appearance of ''Parallel Distributed Processing'' in 1986<U+2014>a two volume collection of papers edited by [[David Rumelhart|Rumelhart]] and psychologist [[James McClelland (psychologist)|James McClelland]]. Neural networks would become commercially successful in the 1990s, when they began to be used as the engines driving programs like [[optical character recognition]] and [[speech recognition]].<ref name = "Norvig 25" /><ref>{{harvnb|Crevier|1993|pp=215<U+2212>216}}.</ref>

==Bust: the second AI winter 1987<U+2212>1993==
The business community's fascination with AI rose and fell in the 80s in the classic pattern of an [[economic bubble]]. The collapse was in the ''perception'' of AI by government agencies and investors <U+2014> the field continued to make advances despite the criticism. [[Rodney Brooks]] and [[Hans Moravec]], researchers from the related field of [[robotics]], argued for an entirely new approach to artificial intelligence.

===AI winter===
The term "[[AI winter]]" was coined by researchers who had survived the funding cuts of 1974 when they became concerned that enthusiasm for expert systems had spiraled out of control and that disappointment would certainly follow.<ref>{{Harvnb|Crevier|1993|pp=203}}. [[AI winter]] was first used as the title of a seminar on the subject for the [[Association for the Advancement of Artificial Intelligence]].</ref> Their fears were well founded: in the late 80s and early 90s, AI suffered a series of financial setbacks.

The first indication of a change in weather was the sudden collapse of the market for specialized AI hardware in 1987. Desktop computers from [[Apple Computer|Apple]] and [[IBM]] had been steadily gaining speed and power and in 1987 they became more powerful than the more expensive [[Lisp machines]] made by [[Symbolics]] and others. There was no longer a good reason to buy them. An entire industry worth half a billion dollars was demolished overnight.<ref>{{Harvnb|McCorduck|2004|p=435}}, {{Harvnb|Crevier|1993|pp=209<U+2212>210}}</ref>

Eventually the earliest successful expert systems, such as [[XCON]], proved too expensive to maintain. They were difficult to update, they could not learn, they were "[[brittle (software)|brittle]]" (i.e., they could make grotesque mistakes when given unusual inputs), and they fell prey to problems (such as the [[qualification problem]]) that had been identified years earlier. Expert systems proved useful, but only in a few special contexts.<ref>{{Harvnb|McCorduck|2004|p=435}} (who cites institutional reasons for their ultimate failure), {{Harvnb|Crevier|1993|pp=204<U+2212>208}} (who cites the difficulty of truth maintenance, i.e., learning and updating), {{Harvnb|Lenat|Guha|1989|loc=Introduction}} (who emphasizes the brittleness and the inability to handle excessive qualification.)</ref>

In the late 80s, the [[Strategic Computing Initiative]] cut funding to AI "deeply and brutally." New leadership at [[DARPA]] had decided that AI was not "the next wave" and directed funds towards projects that seemed more likely to produce immediate results.<ref>{{Harvnb|McCorduck|2004|pp=430<U+2013>431}}</ref>

By 1991, the impressive list of goals penned in 1981 for Japan's [[fifth generation computer|Fifth Generation Project]] had not been met. Indeed, some of them, like "carry on a casual conversation" had not been met by 2010.<ref name="FifthGenEnd">{{Harvnb|McCorduck|2004|p=441}}, {{Harvnb|Crevier|1993|p=212}}. McCorduck writes "Two and a half decades later, we can see that the Japanese didn't quite meet all of those ambitious goals."</ref> As with other AI projects, expectations had run much higher than what was actually possible.<ref name="FifthGenEnd"/>

===The importance of having a body: Nouvelle AI and embodied reason===
{{Main|Nouvelle AI|behavior-based AI|situated|embodied cognitive science}}

In the late 80s, several researchers advocated a completely new approach to artificial intelligence, based on robotics.<ref>{{Harvnb|McCorduck|2004|pp=454<U+2013>462}}</ref> They believed that, to show real intelligence, a machine needs to have a ''body'' <U+2014> it needs to perceive, move, survive and deal with the world. They argued that these sensorimotor skills are essential to higher level skills like [[commonsense reasoning]] and that abstract reasoning was actually the ''least'' interesting or important human skill (see [[Moravec's paradox]]). They advocated building intelligence "from the bottom up."<ref>
{{Harvtxt|Moravec|1988|p=20}} writes: "I am confident that this bottom-up route to artificial intelligence will one date meet the traditional top-down route more than half way, ready to provide the real world competence and the commonsense knowledge that has been so frustratingly elusive in reasoning programs. Fully intelligent machines will result when the metaphorical [[golden spike]] is driven uniting the two efforts."
</ref>

The approach revived ideas from [[cybernetic]]s and [[control theory]] that had been unpopular since the sixties. Another precursor was [[David Marr (neuroscientist)|David Marr]], who had come to [[MIT]] in the late 70s from a successful background in theoretical neuroscience to lead the group studying [[computer vision|vision]]. He rejected all symbolic approaches (''both'' [[John McCarthy (computer scientist)|McCarthy's]] logic and [[Marvin Minsky|Minsky]]'s frames), arguing that AI needed to understand the physical machinery of vision from the bottom up before any symbolic processing took place. (Marr's work would be cut short by leukemia in 1980.)<ref>{{Harvnb|Crevier|1993|pp=183<U+2212>190}}.</ref>

In a 1990 paper [http://people.csail.mit.edu/brooks/papers/elephants.pdf Elephants Don't Play Chess], robotics researcher [[Rodney Brooks]] took direct aim at the [[physical symbol system|physical symbol system hypothesis]], arguing that symbols are not always necessary since "the world is its own best model. It is always exactly up to date. It always has every detail there is to be known. The trick is to sense it appropriately and often enough."<ref>{{Harvnb|Brooks 1990|p=3}}</ref> In the 80s and 90s, many [[cognitive science|cognitive scientists]] also rejected the symbol processing model of the mind and argued that the body was essential for reasoning, a theory called the [[embodied mind]] thesis.<ref>See, for example, {{Harvnb|Lakoff|Turner|1999}}</ref>

==AI 1993<U+2212>present==
The field of AI, now more than a half a century old, finally achieved some of its oldest goals. It began to be used successfully throughout the technology industry, although somewhat behind the scenes. Some of the success was due to increasing computer power and some was achieved by focusing on specific isolated problems and pursuing them with the highest standards of scientific accountability. Still, the reputation of AI, in the business world at least, was less than pristine. Inside the field there was little agreement on the reasons for AI's failure to fulfill the dream of human level intelligence that had captured the imagination of the world in the 1960s. Together, all these factors helped to fragment AI into competing subfields focused on particular problems or approaches, sometimes even under new names that disguised the tarnished pedigree of "artificial intelligence".<ref>{{Harvtxt|McCorduck|2004|p=424}} discusses the fragmentation and the abandonment of AI's original goals.</ref> AI was both more cautious and more successful than it had ever been.
<!--  Commented out: [[Image:p11 kasparov breakout.jpg|thumb|right|280px|[[Garry Kasparov]] playing against [[IBM Deep Blue|Deep Blue]], the first machine to win a chess match against a reigning world champion.]] -->
===Milestones and Moore's Law===
On 11 May 1997, [[IBM Deep Blue|Deep Blue]] became the first computer chess-playing system to beat a reigning world chess champion, [[Garry Kasparov]].<ref>{{Harvnb|McCorduck|2004|pp=480<U+2013>483}}</ref> In 2005, a Stanford robot won the [[DARPA Grand Challenge]] by driving autonomously for 131 miles along an unrehearsed desert trail.<ref>[http://www.darpa.mil/grandchallenge/ DARPA Grand Challenge -- home page]</ref>. Two years later, a team from CMU won the [[DARPA Urban Challenge]] by autonomously navigating 55 miles in an Urban environment while adhering to traffic hazards and all traffic laws<ref>[http://archive.darpa.mil/grandchallenge/]</ref>.  In February 2011, in a [[Jeopardy!]] [[quiz show]] exhibition match, [[IBM]]'s [[question answering system]], [[Watson (artificial intelligence software)|Watson]], defeated the two greatest Jeopardy! champions, [[Brad Rutter]] and [[Ken Jennings]], by a significant margin.<ref>{{cite news| url=http://www.nytimes.com/2011/02/17/science/17jeopardy-watson.html | work=The New York Times | first=John | last=Markoff | title=On <U+2018>Jeopardy!' Watson Win Is All but Trivial | date=16 February 2011}}</ref>

These successes were not due to some revolutionary new paradigm, but mostly on the tedious application of engineering skill and on the tremendous power of computers today.<ref>
{{Harvnb|Kurzweil|2005|p=274}} writes that the improvement in computer chess, "according to common wisdom, is governed only by the brute force expansion of computer hardware."</ref> In fact, [[IBM Deep Blue|Deep Blue's]] computer was 10 million times faster than the [[Ferranti Mark 1]] that [[Christopher Strachey]] taught to play chess in 1951.<ref>Cycle time of [[Ferranti Mark 1]] was 1.2&nbsp;milliseconds, which is arguably equivalent to about 833&nbsp;[[flops]]. [[IBM Deep Blue|Deep Blue]] ran at 11.38&nbsp;[[gigaflops]] (and this does not even take into account Deep Blue's special-purpose hardware for chess). ''Very'' approximately, these differ by a factor of 10^7.</ref> This dramatic increase is measured by [[Moore's law]], which predicts that the speed and memory capacity of computers doubles every two years. The fundamental problem of "raw computer power" was slowly being overcome.

===Intelligent agents===
A new paradigm called "[[intelligent agent]]s" became widely accepted during the 90s.<ref>{{Harvnb|McCorduck|2004|pp=471<U+2013>478}}, {{Harvnb|Russell|Norvig|2003|p=55}}, where they write: "The whole-agent view is now widely accepted in the field". The [[intelligent agent]] paradigm is discussed in major AI textbooks, such as: {{Harvnb|Russell|Norvig|2003|pp=32<U+2212>58, 968<U+2212>972}}, {{Harvnb|Poole|Mackworth|Goebel|1998|pp=7<U+2212>21}}, {{Harvnb|Luger|Stubblefield|2004|pp=235<U+2212>240}}</ref> Although earlier researchers had proposed modular "divide and conquer" approaches to AI,<ref>[[Carl Hewitt]]'s [[Actor model]] anticipated the modern definition of intelligent agents. {{Harv|Hewitt|Bishop|Steiger|1973}} Both John Doyle {{Harv|Doyle|1983}} and [[Marvin Minsky]]'s popular classic ''[[The Society of Mind]]'' {{Harv|Minsky|1986}} used the word "agent". Other "modular" proposals included [[Rodney Brooks|Rodney Brook's]] [[subsumption architecture]], [[object-oriented programming]] and others.</ref> the [[intelligent agent]] did not reach its modern form until [[Judea Pearl]], [[Allen Newell]] and others brought concepts from [[decision theory]] and [[economics]] into the study of AI.<ref name="R27">{{Harvnb|Russell|Norvig|2003|pp=27, 55}}</ref> When the [[economics|economist's]] definition of a [[rational agent]] was married to [[computer science]]'s definition of an [[object-oriented programming|object]] or [[module (programming)|module]], the [[intelligent agent]] paradigm was complete.

An [[intelligent agent]] is a system that perceives its environment and takes actions which maximize its chances of success. The simplest intelligent agents are programs that solve specific problems. The most complicated intelligent agents known are rational, thinking human beings. The [[intelligent agent|intelligent agent paradigm]] defines AI research as "the study of intelligent agents". This is a generalization of some earlier definitions of AI: it goes beyond studying human intelligence; it studies all kinds of intelligence.<ref>This is how the most widely accepted textbooks of the 21st century define artificial intelligence. See {{Harvnb|Russell|Norvig|2003|p=32}} and {{Harvnb|Poole|Mackworth|Goebel|1998|p=1}}</ref>

The paradigm gave researchers license to study isolated problems and find solutions that were both verifiable and useful. It provided a common language to describe problems and share their solutions with each other, and with other fields that also used concepts of abstract agents, like [[economics]] and [[control theory]]. It was hoped that a complete [[agent architecture]] (like [[Allen Newell|Newell's]] [[Soar (cognitive architecture)|SOAR]]) would one day allow researchers to build more versatile and intelligent systems out of interacting [[intelligent agents]].<ref name="R27"/><ref>{{Harvnb|McCorduck|2004|p=478}}</ref>

==="Victory of the neats"===
AI researchers began to develop and use sophisticated mathematical tools more than they ever had in the past.<ref>{{Harvnb|McCorduck|2004|pp=486<U+2013>487}}, {{Harvnb|Russell|Norvig|2003|pp=25<U+2013>26}}</ref> There was a widespread realization that many of the problems that AI needed to solve were already being worked on by researchers in fields like [[mathematics]], [[economics]] or [[operations research]]. The shared mathematical language allowed both a higher level of collaboration with more established and successful fields and the achievement of results which were measurable and provable; AI had become a more rigorous "scientific" discipline. {{Harvtxt|Russell|Norvig|2003}} describe this as nothing less than a "revolution" and "the victory of the [[neats and scruffies|neats]]".<ref name="RN25">{{Harvnb|Russell|Norvig|2003|p=25<U+2212>26}}</ref><ref>{{Harvtxt|McCorduck|2004|p=487}}: "As I write, AI enjoys a Neat hegemony."</ref>

[[Judea Pearl]]'s highly influential 1988 book<ref>{{Harvnb|Pearl|1988}}</ref> brought [[probability]] and [[decision theory]] into AI. Among the many new tools in use were [[Bayesian networks]], [[hidden Markov models]], [[information theory]], [[stochastic modeling]] and classical [[optimization (mathematics)|optimization]]. Precise mathematical descriptions were also developed for "[[computational intelligence]]" paradigms like [[neural networks]] and [[evolutionary algorithm]]s.<ref name="RN25"/>

=== AI behind the scenes ===

Algorithms originally developed by AI researchers began to appear as parts of larger systems. AI had solved a lot of very difficult problems<ref>
See {{See section|Applications of artificial intelligence|Computer science}}.
</ref>
and their solutions proved to be useful throughout the technology industry,<ref>
{{Harvnb|NRC|1999}} under "Artificial Intelligence in the 90s", and {{Harvnb|Kurzweil|2005|p=264}}
</ref> such as
[[data mining]],
[[industrial robots|industrial robotics]],
[[logistics]],<ref>{{Harvnb|Russell|Norvig|2003|p=28}}</ref>
[[speech recognition]],<ref>For the new state of the art in AI based speech recognition, see {{Harvtxt|The Economist|2007}}</ref>
banking software,<ref name = "CNN7242006">"AI-inspired systems were already integral to many everyday technologies such as internet search engines, bank software for processing transactions and in medical diagnosis." [[Nick Bostrom]], quoted in {{Harvnb|CNN|2006}}</ref>
medical diagnosis<ref name = "CNN7242006"/>
and [[Google]]'s search engine.<ref>{{Harvtxt|Olsen|2004}},{{Harvtxt|Olsen|2006}}</ref>

The field of AI receives little or no credit for these successes. Many of AI's greatest innovations have been reduced to the status of just another item in the tool chest of computer science.<ref>{{Harvnb|McCorduck|2004|p=423}}, {{Harvnb|Kurzweil|2005|p=265}}, {{Harvnb|Hofstadter|1979|p=601}}</ref> [[Nick Bostrom]] explains "A lot of cutting edge AI has filtered into general applications, often without being called AI because once something becomes useful enough and common enough it's not labeled AI anymore."<ref>{{Harvnb|CNN|2006}}</ref>

Many researchers in AI today deliberately call their work by other names, such as [[Informatics (academic field)|informatics]], [[knowledge-based systems]], [[cognitive system]]s or [[computational intelligence]]. In part, this may be because they considered their field to be fundamentally different from AI, but also the new names help to procure funding. In the commercial world at least, the failed promises of the [[AI Winter]] continue to haunt AI research, as the New York Times reported in 2005: "Computer scientists and software engineers avoided the term artificial intelligence for fear of being viewed as wild-eyed dreamers."<ref>{{Harvnb|Markoff|2005}}</ref><ref>{{Harvnb|The Economist|2007}}</ref><ref>{{Harvnb|Tascarella|2006}}</ref>

===Where is HAL 9000?===
In 1968, [[Arthur C. Clarke]] and [[Stanley Kubrick]] had imagined that by the year [[2001: A Space Odyssey|2001]], a machine would exist with an intelligence that matched or exceeded the capability of human beings. The character they created, [[HAL 9000]], was based on a belief shared by many leading AI researchers that such a machine would exist by the year 2001.<ref>{{Harvnb|Crevier|1993|pp=108<U+2212>109}}</ref>

[[Marvin Minsky]] asks "So the question is why didn't we get HAL in 2001?"<ref>He goes on to say: "The answer is, I believe we could have ... I once went to an international conference on neural net[s]. There were 40 thousand registrants ... but ... if you had an international conference, for example, on using multiple representations for common sense reasoning, I've only been able to find 6 or 7 people in the whole world." {{Harvnb|Minsky|2001}}</ref> Minsky believes that the answer is that the central problems, like [[commonsense reasoning]], were being neglected, while most researchers pursued things like commercial applications of [[neural nets]] or [[genetic algorithms]]. [[John McCarthy (computer scientist)|John McCarthy]], on the other hand, still blames the [[qualification problem]].<ref>{{Harvnb|Maker|2006}}</ref> For [[Ray Kurzweil]], the issue is computer power and, using [[Moore's Law]], he predicts that machines with human-level intelligence will appear by 2029.<ref>{{Harvnb|Kurzweil|2005}}</ref> [[Jeff Hawkins]] argues that neural net research ignores the essential properties of the human [[cerebral cortex|cortex]], preferring simple models that have been successful at solving simple problems.<ref>{{Harvnb|Hawkins|Blakeslee|2004}}</ref> There are many other explanations and for each there is a corresponding research program underway.

== See also ==
*[[History of natural language processing]]
{{Portal|artificial intelligence}}
{{Clear}}

==Notes==
{{Reflist|2}}

==References==

{{refbegin}}
* {{Citation | first = David | last = Berlinski | year = 2000 | title =The Advent of the Algorithm| publisher = Harcourt Books |author-link=David Berlinski | isbn=0-15-601391-6 | oclc = 46890682 }}.
* {{Citation | first = Bruce G. | last = Buchanan  | title = A (Very) Brief History of Artificial Intelligence | magazine = [[AI Magazine]] | date=Winter 2005 | pages=53<U+2212>60 | url=http://www.aaai.org/AITopics/assets/PDF/AIMag26-04-016.pdf | accessdate=2007-08-30 }}.
* {{Citation | first = Rodney | last = Brooks | title = Elephants Don't Play Chess | journal = [[Robotics and Autonomous Systems]] | volume=6 | year =1990 | pages = 3<U+2212>15 | author-link=Rodney Brooks | url=http://people.csail.mit.edu/brooks/papers/elephants.pdf | accessdate=2007-08-30 | doi = 10.1016/S0921-8890(05)80025-9}}.
* {{Citation | last = Butler | first =  Samuel | author-link = Samuel Butler (novelist) | date = 13 June 1863 | title = Darwin Among the Machines | url =http://www.nzetc.org/tm/scholarly/tei-ButFir-t1-g1-t1-g1-t4-body.html | accessdate = 10 October 2008 | newspaper = the Press, Christchurch, New Zealand }}.
* {{Citation | last=CNN | date = 26 July 2006 | title=AI set to exceed human brain power
| url=http://www.cnn.com/2006/TECH/science/07/24/ai.bostrom/ | accessdate=16 October 2007 | publisher=[[CNN]].com }}.
* {{Citation | last = Copeland | first=Jack | author-link=Jack Copeland | year=2000 | title=Micro-World AI | url=http://www.alanturing.net/turing_archive/pages/Reference%20Articles/what_is_AI/What%20is%20AI06.html | accessdate=8 October 2008}}.
* {{Citation | last=Cordeschi | first=Roberto | year = 2002 | title = The Discovery of the Artificial | publisher=Kluwer. | location=Dordrecht }}.
* {{Crevier 1993}}
* {{Citation | first = Brad | last = Darrach | date=20 November 1970  | title=Meet Shakey, the First Electronic Person | magazine=[[Life Magazine]] | pages = 58<U+2212>68 }}.
* {{Citation | first = J. | last = Doyle | year = 1983 | title = What is rational psychology? Toward a modern mental philosophy | magazine = [[AI Magazine]] | volume= 4 | issue =3 |pages = 50<U+2212>53 }}.
* {{Citation | last=Dreyfus | first=Hubert | year =1965 | title = Alchemy and AI  | publisher = [[RAND Corporation]] Memo | author-link = Hubert Dreyfus }}.
* {{Citation | last=Dreyfus | first=Hubert | year =1972 | title = [[What Computers Can't Do]]  | publisher = MIT Press | location = New York  | isbn = 0-06-090613-8 | oclc=5056816 }}.
* {{Citation | last=The Economist | date=7 June 2007 | magazine=[[The Economist]] | title=Are You Talking to Me? | url=http://www.economist.com/science/tq/displaystory.cfm?story_id=9249338 | accessdate=16 October 2008}}.
* {{Citation | first = Edward A. | last = Feigenbaum | first2=Pamela |last2=McCorduck |title = The [[Fifth generation computer|Fifth Generation]]: Artificial Intelligence and Japan's Computer Challenge to the World | publisher = Michael Joseph | year = 1983| author-link = Edward Feigenbaum | isbn = 0-7181-2401-4 }}.
* {{Citation | last=Hawkins | first=Jeff | author-link=Jeff Hawkins | last2=Blakeslee | first2=Sandra | year=2004 | title=[[On Intelligence]] | publisher=Owl Books | location=New York, NY | isbn=0-8050-7853-3 | oclc=61273290 }}.
* {{Citation| last=Hebb | first=D.O.| author-link=Donald Olding Hebb|  title=The Organization of Behavior | publisher=Wiley | location=New York|year=1949 | isbn=0805843000| oclc=48871099 }}.
* {{Citation | last=Hewitt | first=Carl | author-link=Carl Hewitt | last2=Bishop | first2=Peter | last3=Steiger | first3=Richard | year=1973 | title=A Universal Modular Actor Formalism for Artificial Intelligence | url=http://dli.iiit.ac.in/ijcai/IJCAI-73/PDF/027B.pdf | format=PDF |publisher=IJCAI | authorlink2=Peter Bishop | authorlink3=Richard Steiger }}
* {{Citation | last = Hobbes | first = Thomas
| title = [[Leviathan (book)|Leviathan]] | year = 1651 | author-link=Hobbes }}.
* {{Citation | first = Douglas | last = Hofstadter
| title = [[G<U+00F6>del, Escher, Bach|G<U+00F6>del, Escher, Bach: an Eternal Golden Braid]] | date = 1999 (1979)| author-link = Douglas Hofstadter | publisher = Basic Books  | isbn = 0465026567 | oclc = 225590743
}}.
* {{Citation | first = J. | last = Howe | url=http://www.inf.ed.ac.uk/about/AIhistory.html | title = Artificial Intelligence at Edinburgh University: a Perspective | date = November 1994 | accessdate= 30 August 2007}}.
* {{Citation | first = G. | last=Kolata | year=1982 | title=How can computers get common sense? | journal=Science | issue= 4566 | pages=1237<U+2013>1238 | doi = 10.1126/science.217.4566.1237 | volume = 217 | pmid = 17837639 }}.
* {{Citation | first = Ray | last = Kurzweil | title = [[The Singularity is Near]] | year = 2005 | publisher = Viking Press | author-link = Ray Kurzweil | isbn=0143037889 | oclc = 71826177 }}.
* {{Citation | first = George | last = Lakoff | year = 1987 | title = Women, Fire, and Dangerous Things: What Categories Reveal About the Mind | publisher = University of Chicago Press. |author-link=George Lakoff | isbn = 0-226-46804-6}}.
* {{Citation | last=Lenat | first=Douglas |  last2=Guha | first2=R. V.| year = 1989 | title = Building Large Knowledge-Based Systems | publisher = Addison-Wesley| author-link=Douglas Lenat | isbn=0201517523 | oclc=19981533 }}.
* {{Citation | first = Gerald M. | last = Levitt | title = The Turk, Chess Automaton| publisher = McFarland|year = 2000|publication-place = Jefferson, N.C. | isbn = 0-7864-0778-6 }}.
* {{Citation | last = Lighthill | first = Professor Sir James | year = 1973 |
contribution= [[Lighthill report|Artificial Intelligence: A General Survey]] | title = Artificial Intelligence: a paper symposium| publisher = [[Science Research Council]]| author-link=James Lighthill }}
* {{Citation | last = Lucas | first = John | author-link = John Lucas (philosopher) | year = 1961
| title = Minds, Machines and G<U+00F6>del
| journal = [[Philosophy (journal)|Philosophy]] | pages=112<U+2013>127
| url = http://users.ox.ac.uk/~jrlucas/Godel/mmg.html | accessdate = 15 October 2008 | doi = 10.1017/S0031819100057983 | volume = 36 | issue=XXXVI  }}
* {{Citation | last=Maker | first=Meg Houston | year=2006 | title=AI@50: AI Past, Present, Future | location=Dartmouth College
| url=http://www.engagingexperience.com/2006/07/ai50_ai_past_pr.html | accessdate=16 October 2008 }}
* {{Citation | last=Markoff | first=John | author-link=John Markoff | date=14 October 2005
| title=Behind Artificial Intelligence, a Squadron of Bright Real People | url=http://www.nytimes.com/2005/10/14/technology/14artificial.html?_r=1&ei=5070&en=11ab55edb7cead5e&ex=1185940800&adxnnl=1&adxnnlx=1185805173-o7WsfW7qaP0x5/NUs1cQCQ&oref=slogin | accessdate=16 October 2008 | newspaper=[[The New York Times]] }}
* {{Citation | last = McCarthy | first = John | last2 = Minsky | first2 = Marvin | last3 = Rochester | first3 = Nathan | last4 = Shannon | first4 = Claude | url = http://www-formal.stanford.edu/jmc/history/dartmouth/dartmouth.html | accessdate=16 October 2008 | title = A Proposal for the Dartmouth Summer Research Project on Artificial Intelligence | date=August 35, 1955 | author-link = John McCarthy (computer scientist) |  author3-link = Nathaniel Rochester (computer scientist) | author4-link = Claude Shannon}}
* {{Citation | last = McCarthy  | first = John | last2 = Hayes | first2=P. J. | author2-link=Patrick J. Hayes | editor-last=Meltzer | editor-first=B. J. | editor-link=Bernard Meltzer (computer scientist) | editor2-last=Mitchie | editor2-first=Donald | editor2-link=Donald Mitchie | year = 1969
| url=http://www-formal.stanford.edu/jmc/mcchay69/mcchay69.html  | accessdate=16 October 2008
| contribution= Some philosophical problems from the standpoint of artificial intelligence | title=Machine Intelligence 4
 | pages = 463<U+2212>502 | publisher=Edinburgh University Press }}
* {{Citation | last=McCorduck | first=Pamela | year = 2004 | title = Machines Who Think | publisher=A. K. Peters, Ltd. | location=Natick, MA | edition=2nd | isbn=1-56881-205-1 | oclc=52197627}}.
* {{Citation | last = McCullough | first = W. S. | last2 = Pitts | first2 = W. | year = 1943 | title = A logical calculus of the ideas immanent in nervous activity | journal= Bulletin of Mathematical Biophysics | volume= 5 | pages = 115<U+2212>127 | author-link = Warren McCullough | doi = 10.1007/BF02478259 | issue = 4}}
* {{Citation
| last=Menabrea |first=Luigi Federico | authorlink=Ada Lovelace
| last2=Lovelace | first2=Ada
| year=1843
| title=Sketch of the Analytical Engine Invented by Charles Babbage
| journal=[[Scientific Memoirs]] |volume=3
| url= http://www.fourmilab.ch/babbage/sketch.html |accessdate=2008-08-29}} With notes upon the Memoir by the Translator
* {{Citation
| first = Marvin | last = Minsky | author-link=Marvin Minsky
| year = 1967
| title = Computation: Finite and Infinite Machines
| publication-place=Englewood Cliffs, N.J. | publisher = Prentice-Hall }}
* {{Citation
| first = Marvin | last = Minsky | author-link=Marvin Minsky
| first2=Seymour | last2=Papert | author2-link = Seymour Papert
| year = 1969| title = Perceptrons: An Introduction to Computational Geometry | publisher =The MIT Press  | isbn = 0262631113 | oclc = 16924756 }}
* {{Citation
| first = Marvin | last = Minsky | author-link=Marvin Minsky
| year = 1974 | title = A Framework for Representing Knowledge
| url = http://web.media.mit.edu/~minsky/papers/Frames/frames.html | accessdate=16 October 2008}}
* {{Citation
| first = Marvin | last = Minsky | author-link=Marvin Minsky
| title = [[The Society of Mind]]
| publisher = Simon and Schuster
| year = 1986
| isbn=0671657135 | oclc = 223353010 }}
* {{Citation
| first = Marvin | last = Minsky | author-link=Marvin Minsky
| year = 2001
| title=It's 2001. Where Is HAL?
| publisher=Dr. Dobb's Technetcast
| url=http://www.ddj.com/hpc-high-performance-computing/197700454?cid=RSSfeed_DDJ_AI | accessdate=8 August 2009 }}
* {{Citation | first = Hans | last = Moravec | year = 1976 | url= http://www.frc.ri.cmu.edu/users/hpm/project.archive/general.articles/1975/Raw.Power.html | title = The Role of Raw Power in Intelligence | author-link=Hans Moravec | accessdate=16 October 2008 }}
* {{Citation | first = Hans | last = Moravec | year = 1988 | title = Mind Children | publisher = Harvard University Press | isbn=0674576187 | oclc = 245755104 }}
* {{Citation | last =NRC |chapter=Developments in Artificial Intelligence|  title=Funding a Revolution: Government Support for Computing Research | publisher=National Academy Press|year=1999| author-link=United States National Research Council | isbn=0-309-06278-0 | oclc = 246584055}}
* {{Citation | last = Newell | first = Allen | last2 = Simon | first2=H. A. | year = 1963 | contribution=GPS: A Program that Simulates Human Thought| title=Computers and Thought | editor-last= Feigenbaum | editor-first= E.A. |editor2-last= Feldman |editor2-first= J. |publisher= McGraw-Hill | author-link=Allen Newell | isbn=0262560925 | oclc = 246968117|publication-place= New York}}
* {{Citation | last=Nick | first=Martin | year=2005 | title=Al Jazari: The Ingenious 13th Century Muslin Mechanic | publisher=Al Shindagah
| url=http://www.alshindagah.com/marapr2005/jaziri.html | accessdate=16 October 2008 }}.
* {{Citation | last=O'Connor | first=Kathleen Malone | title=The alchemical creation of life (takwin) and other concepts of Genesis in medieval Islam|publisher=University of Pennsylvania |year=1994 | url=http://repository.upenn.edu/dissertations/AAI9503804 | accessdate=2007-01-10}}
* {{Citation | last=Olsen | first=Stefanie | date=May 10, 2004 | publisher=[[CNET]]
| title =Newsmaker: Google's man behind the curtain
| url=http://news.cnet.com/Googles-man-behind-the-curtain/2008-1024_3-5208228.html | accessdate=17 October 2008 }}.
* {{Citation | last=Olsen | first=Stefanie | date=August 18, 2006 | publisher=[[CNET]]
| title =Spying an intelligent search engine
| url=http://news.cnet.com/Spying-an-intelligent-search-engine/2100-1032_3-6107048.html | accessdate=17 October 2008 }}.
* {{Citation | last = Pearl | first = J. | year = 1988 | title = Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference | publisher=Morgan Kaufmann | author-link=Judea Pearl | isbn=1558604790 | oclc = 249625842 | publication-place=San Mateo, California}}.
* {{Russell Norvig 2003}}.
* {{Citation | first = David | last = Poole | first2 = Alan | last2 = Mackworth | first3 = Randy | last3 = Goebel | year = 1998 | title = Computational Intelligence: A Logical Approach | url = http://www.cs.ubc.ca/~poole/ci.html| publisher = Oxford University Press. | isbn = 0-19-510270-3}}.
* {{Citation | last = Samuel | first =Arthur L. | year =1959| title = Some studies in machine learning using the game of checkers| journal =IBM Journal of Research and Development| volume= 3 | issue=3| pages=210<U+2212>219| month=July| author-link=Arthur Samuel | url=http://domino.research.ibm.com/tchjr/journalindex.nsf/600cc5649e2871db852568150060213c/39a870213169f45685256bfa00683d74?OpenDocument| accessdate=2007-08-20 | doi = 10.1147/rd.33.0210}}.
* {{Searle 1980}}.
* {{Citation | last1 =Simon | first1 = H. A. | author-link=Herbert Simon | last2=Newell | first2=Allen | year = 1958
| title = Heuristic Problem Solving: The Next Advance in Operations Research
| journal =Operations Research | volume=6 | doi =10.1287/opre.6.1.1 | pages =1  }}.
* {{Citation | first = H. A. | last= Simon| year = 1965 | title=The Shape of Automation for Men and Management | publisher =Harper & Row | publication-place = New York }}.
* {{Citation | last = Skillings | first =  Jonathan | year = 2006 | publisher=[[CNET]]
| title = Newsmaker: Getting machines to think like us
| url = http://news.cnet.com/Getting-machines-to-think-like-us---page-2/2008-11394_3-6090207-2.html?tag=st.next | accessdate=October 08, 2008 }}.
* {{Citation | last=Tascarella | first=Patty | date=11 Autgust 2006
| title=Robotics firms find fundraising struggle, with venture capital shy | newspaper=[[Pittsburgh Business Times]]
| url=http://www.bizjournals.com/pittsburgh/stories/2006/08/14/focus3.html?b=1155528000%5E1329573 | accessdate= October 08, 2008 }}.
* {{Citation | last=Turing | first=Alan | title=On Computable Numbers, with an Application to the Entscheidungsproblem
| journal=Proceedings of the London Mathematical Society | series=2 | issue = 42 | date=1936-37 | pages= 230<U+2013>265
| url=http://www.abelard.org/turpap2/tp2-ie.asp | accessdate=October 8, 2008}}.
* {{Turing 1950}}.
* {{Citation | first = Joseph | last = Weizenbaum  | author-link=Joseph Weizenbaum | year = 1976 | title = [[Computer Power and Human Reason]] | publisher = W.H. Freeman & Company  | isbn=0140225358 | oclc = 10952283 }}.
{{refend}}.

 <!--- This blank makes it appear as the lead article of the category -->

{{good article}}

{{DEFAULTSORT:History Of Artificial Intelligence}}
[[Category:History of artificial intelligence| ]]

[[es:Historia de la inteligencia artificial]]
[[fa:<U+062A><U+0627><U+0631><U+06CC><U+062E><U+0686><U+0647> <U+0647><U+0648><U+0634> <U+0645><U+0635><U+0646><U+0648><U+0639><U+06CC>]]
[[ru:<U+0418><U+0441><U+0442><U+043E><U+0440><U+0438><U+044F> <U+0438><U+0441><U+043A><U+0443><U+0441><U+0441><U+0442><U+0432><U+0435><U+043D><U+043D><U+043E><U+0433><U+043E> <U+0438><U+043D><U+0442><U+0435><U+043B><U+043B><U+0435><U+043A><U+0442><U+0430>]]
[[vi:L<U+1ECB>ch s<U+1EED> ng<U+00E0>nh tr<U+00ED> tu<U+1EC7> nh<U+00E2>n t<U+1EA1>o]]
[[zh:<U+4EBA><U+5DE5><U+667A><U+80FD><U+7684><U+5386><U+53F2>]]
