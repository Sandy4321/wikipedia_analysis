L’'''histoire de l'intelligence artificielle''' (ou '''I.A.''') démarre dans l'[[antiquité]], avec mythes, légendes et rumeurs d'êtres artificiels dotés d'une intelligence ou d'une conscience par des maîtres-artisans ; comme l'écrit Pamela McCorduck, l'I.A. commence avec « le vieux souhait de jouer à Dieu<ref>{{Harvnb|McCorduck|2004}}</ref> ».

{{Sommaire|align=right|niveau=2|flottant=1}}
La graine de l'intelligence artificielle contemporaine a été plantée par les philosophes classiques, dont Leibniz, qui essaient de décrire le processus de la pensée humaine comme la manipulation mécanique de symboles. Ce travail s'est concrétisé avec l'invention de l'[[Ordinateur|ordinateur programmable numériquement]] dans les années 1940, une machine fondée sur l'abstraction du raisonnement mathématique. Cette machine et les idées qu'elle sous-tend ont inspiré quelques scientifiques qui ont commencé à évoquer sérieusement la faisabilité d'un cerveau électronique.

Le domaine de recherche de l'[[intelligence artificielle]] a été initié lors d'une conférence tenue sur le campus de [[Dartmouth College]] pendant l'été 1956. Suite à cela certains participants dans une recherche sur l'intelligence artificielle. Certains visionnaires ont pronostiqué qu'une machine aussi intelligente qu'un être humain existerait en moins d'une génération et des millions de dollars ont été investis pour réifier cette prédiction. Avec le temps, il est apparu que les difficultés inhérentes à ce projet avaient été grossièrement sous-estimées. En 1973, en réponse aux critiques de [[Michael James Lighthill|James Lighthill]] et aux pressions continuelles des parlements, les gouvernements [[Gouvernement du Royaume-Uni|britannique]] et [[Defense Advanced Research Projects Agency|américain]] ont stoppé les subventions à la recherche en intelligence artificielle sans orientation. Sept ans plus tard, suite  l'initiative visionnaire du [[Cabinet du Japon]], les gouvernements et l'industrie  réinvestissent dans  l'intelligence artificielle, mais à la fin des années 1980 les décideurs désabusés retirent à nouveaux leurs fonds. Ce cycle en dents de scie, alternant périodes de gel de l'intelligence artificielle et de dégel, continue. Mais il y a toujours des idéalistes qui font des prédictions osées<ref>Par exemple {{Harvnb|Kurzweil|2005}} estime que les machines avec une [[Intelligence artificielle#Intelligence artificielle forte|intelligence comparable à celle de l'homme]] existera en 2029.</ref>.

L'intelligence artificielle a progressé, malgré des hauts et des bas et malgré les réticences des technocrates et des investisseurs. Des problèmes qu'on pensait inaccessibles en 1970 ont été résolus et leurs solutions sont distribués commercialement. Cela est aussi dû aux progrès de l'algorithmique qui a permis de programmer des solutions que l'on ne pouvait atteindre autrefois que par des heuristiques. Néanmoins, aucune machine dotée d'une [[Intelligence artificielle#intelligence artificielle forte|intelligence artificielle forte]] n'a encore été construite, contrairement aux prévisions optimistes de la première génération de chercheurs. « Nous ne pouvons  qu'entrevoir le court terme » a concédé [[Alan Turing]], dans un article célèbre de 1950 qui préfigure la recherche moderne sur les machines pensantes. « Mais, » ajoute-t-il, « nous ne pouvons pas envisager l'ampleur du travail qui reste à accomplir<ref name="TuringQuote">{{Harvnb|Turing|1950|p=460}}</ref> ».

Au départ, deux approches s'affrontent : l'approche [[logicisme|logiciste]] ou symbolique, qui vise à recréer les « lois universelles » de la pensée et s'inspirent du concept de la [[machine de Turing]], et l'approche neuronale, incarnée par [[Frank Rosenblatt]], qui essaie d'imiter les processus biologiques cérébraux. Si l'approche logiciste, inspirée des travaux de [[Russell]], [[Frege]], du [[cercle de Vienne]], du [[Algèbre de Boole (logique)|calcul booléen]], etc., l'emporte à la [[DARPA]], principal organisme finançant les recherches en intelligence artificielle, l'approche neuronale refait surface dans les [[années 1980]], inspirant les travaux [[connexionnisme|connexionnistes]].

==Quelques précurseurs==
{{Harvnb|McCorduck|année=2004}} a écrit que « l'[[intelligence artificielle]] sous une forme ou une autre est une idée qui s'est répandue dans l'histoire de la pensée occidentale, un rêve au besoin pressant d'être réalisé, » que l'on retrouve dans les mythes, légendes, histoires, spéculations et [[Automate anthropomorphe|automate]]s de l'humanité<ref>{{Harvnb|McCorduck|2004|page=5–35}}</ref>.

===L'I.A. : mythes, fiction et spéculation===

Les hommes mécaniques et les êtres artificiels sont présents dans la [[mythologie grecque]], par exemple les robots dorés d'[[Héphaïstos]] et [[Pygmalion et Galatée]]<ref>{{Harvnb|McCorduck|2004|page=5}} ; {{Harvnb|Russell|Norvig|2003|page=939}}</ref>.
Au Moyen-Âge, il y avait des rumeurs de secrets mystiques ou de techniques [[Alchimie|alchimique]]s pour imprégner la matière d'un esprit, tels que le ''[[Takwin]]'' de [[Jabir Ibn Hayyan|Geber]], les [[Homoncule (alchimie)|homoncule]]s de [[Paracelse]] et le [[Golem]] de [[Juda Loew ben Bezalel|MaHaRaL]]<ref>{{Harvnb|McCorduck|2004|page=15–16}} ; {{Harvnb|Buchanan|2005|page=50}} (Golem) ; {{Harvnb|McCorduck|2004|page=13–14}} (Paracelse) ; {{Harvnb|O'Connor|1994}} (''Takwin'')</ref>.
Au {{s|xix}}, l'idée d'hommes artificiels et de machines pensantes prend corps dans des œuvres de fiction, telles que ''[[Frankenstein ou le Prométhée moderne|Frankenstein]]'' de [[Mary Shelley]] ou encore ''[[R. U. R. (Rossum's Universal Robots)]]'' de [[Karel Čapek]]<ref>{{Harvnb|McCorduck|2004|page=17–25}}</ref>,
et des essais de spéculation, comme ''Darwin among the Machines'' de [[Samuel Butler (1835-1902)|Samuel Butler]]<ref>{{Harvnb|Butler|1863}}</ref>.
L'I.A. a depuis continué à être un élément important de [[science-fiction]] jusqu'à aujourd'hui.

===Automates===
{{Article détaillé|Automate anthropomorphe}}
[[Fichier:Al-jazari robots.jpg|thumb|250px|left|L'automate programmable d'[[Al-Djazari]] (1206 {{Ap JC}})]]
Des [[Automate anthropomorphe|automates anthropomorphes]] réalistes ont été construits par des artisans de toutes les civilisations, dont Yan Shi qui travaillait pour [[Zhou Muwang|Ji Man]]<ref>{{Harvnb|Needham|1986|page=53}}</ref>, [[Héron d'Alexandrie]]<ref>{{Harvnb|McCorduck|2004|page=6}}</ref>, [[Al-Djazari]]<ref>{{Harvnb|Nick|2005}}</ref> et [[Johann Wolfgang von Kempelen|Wolfgang von Kempelen]]<ref>{{Harvnb|McCorduck|2004|page=17}} ; {{Harvnb|Levitt|2000}}</ref>.
Les plus vieux automates sont les statues sacrées d'[[ancienne Égypte]] et de [[Grèce antique]]. Les croyants étaient persuadés que les artisans avaient imprégné ces statues avec des esprits réels, capables de sagesse et d'émotion — [[Hermès Trismégiste]] a écrit qu'« en découvrant la vraie nature des dieux, l'homme a été capable de le reproduire<ref>Cité dans {{Harvnb|McCorduck|2004|page=8}}. {{Harvnb|Crevier|1993|page=1}} et {{Harvnb|McCorduck|2004|page=6–9}} traitent des statues sacrées.</ref>{{,}}<ref>D'autres automates importants ont été construits par [[Hâroun ar-Rachîd]] {{Harv|McCorduck|2004|page=10}}, [[Jacques de Vaucanson]] {{Harv|McCorduck|2004|page=16}} et [[Leonardo Torres Quevedo]] {{Harv|McCorduck|2004|page=59–62}}</ref> ».

===Raisonnement formel===
L'intelligence artificielle se fonde sur l'hypothèse que le processus de pensée humaine peut être mécanisé. L'étude du raisonnement mécanique—ou « formel »— a un long historique. Les philosophes [[Philosophie chinoise|chinois]], [[Philosophie indienne|indien]]s et [[Philosophie grecque et romaine#L'« âge d'or » de la Grèce|grec]]s ont tous développé des méthodes structurées de déduction formelle au cours du premier millénaire {{Ap JC}}. Leurs idées ont étaient développées à travers les siècles par des philosophes comme [[Aristote]] (qui a donné une analyse formelle du [[syllogisme]]),  [[Euclide]] (dont les ''[[Éléments d'Euclide|Éléments]]'' ont été un modèle de raisonnement formel), [[Al-Khawarizmi]] (auquel on doit l'[[algèbre]] et dont le nom a donné « [[algorithme]] ») et les philosophes  [[Scolastique|scolastique]]s européens comme [[Guillaume d'Ockham]] et [[Jean Duns Scot|Duns Scot]]<ref name="Berlinski 2000">{{Harvnb|Berlinski|2000}}</ref>.


Le philosophe majorquin [[Raymond Lulle]] (1232–1315) a conçu plusieurs ''machines logiques'' dédiées à la production de connaissance par des moyens logiques<ref>{{Ouvrage|langue=es|nom1=Carreras Artau|nom2=Tomás y Joaquín|titre=Historia de la filosofía española. Filosofía cristiana de los siglos XIII al XV|lieu=Madrid|année=1939|volume=I}}</ref> ; Lulle décrit ses machines en tant qu'entités mécaniques qui pouvaient combiner des vérités fondamentales et indéniables via de simples opérations logiques, générées par la machine grâce à des mécanismes, de manière à produire tout le savoir possible<ref>{{Ouvrage|langue=en|nom1=Bonner|prénom1=Anthony|titre=The Art and Logic of Ramón Llull: A User's Guide|éditeur=Brill|année=2007}}</ref>. Le travail de Lulle a une grande influence sur [[Gottfried Leibniz]], qui a redéveloppé ses idées<ref>{{Ouvrage|langue=en|prénom1=Anthony|nom1=Bonner (éd.)|titre=Doctor Illuminatus. A Ramon Llull Reader|éditeur=Princeton University|année=1985|titre volume=Llull's Influence: The History of Lullism|page=57-71}}</ref>.

[[Fichier:Gottfried Wilhelm von Leibniz.jpg||thumb|150px|[[Gottfried Leibniz]], qui spéculait qu'on pouvait réduire la raison humaine à des calculs mécaniques]]
Au {{s|xvii}}, [[Gottfried Leibniz|Leibniz]], [[Thomas Hobbes]] et [[René Descartes]] ont exploré la possibilité que toute la pensée rationnelle puisse être aussi systématique que l'algèbre ou la géométrie<ref>
I.A. et mécanisme du {{s|xvii}} :
* {{Harvnb|McCorduck|2004|p=37–46}}
* {{Harvnb|Russell|Norvig|2003|p=6}}
* {{Harvnb|Haugeland|1986|loc=chap. 2}}
* {{Harvnb|Buchanan|2005|p=53}}
</ref>.
Dans le ''[[Léviathan (Thomas Hobbes)|Léviathan]]'' de [[Hobbes]], on retrouve la célèbre phrase : « la raison [...] n'est rien d'autre que le fait de calculer<ref>
Hobbes et l'I.A. :
* {{Harvnb|McCorduck|2004|p=42}}
* {{Harvnb|Hobbes|1651|loc=chap. 5}}
</ref> ».
[[Gottfried Leibniz|Leibniz]] imaginait un langage universel du raisonnement (sa ''[[Caractéristique universelle|characteristica universalis]]'') qui assimilerait l'argumentation à un calcul, afin qu'« il n'y a[it] pas plus de besoin de se disputer entre deux philosophes qu'entre deux comptables. Car il leur suffirait de prendre leur crayon et leur ardoise en main, et de se dire l'un l'autre (avec un ami en témoin, au besoin) : ''Calculons !''<ref>
Leibniz et l'I.A. :
* {{Harvnb|McCorduck|2004|p=41}}
* {{Harvnb|Russell|Norvig|2003|p=6}}
* {{Harvnb|Berlinski|2000|p=12}}
* {{Harvnb|Buchanan|2005|p=53}}
</ref> ».
Ces philosophes ont commencé à articuler les hypothèses d'un [[Système formel|système de symboles physiques]] qui deviendra par la suite l'un des dogmes de la recherche en I.A.

Au {{s|xx}}, l'étude de la [[logique mathématique]] a fourni l'essentiel des avancées qui ont rendu  plausible l'intelligence artificielle. Les bases ont été mises en place avec des œuvres telles que ''Les Lois de la Pensée'' de [[George Boole|Boole]] et ''[[Idéographie]]'' de [[Frege]]. S'appuyant sur le système de Frege, [[Bertrand Russell|Russell]] et [[Alfred North Whitehead|Whitehead]] ont présenté un traitement formel des fondements des mathématiques dans leur chef d'œuvre ''[[Principia Mathematica]]'' en 1913. Inspiré par le succès de Russell, [[Programme de Hilbert|David Hilbert]] a défié les mathématiciens des années 1920-1930 de répondre à cette question fondamentale : « Le raisonnement mathématique peut-il être entièrement formalisé<ref name="Berlinski 2000"/> ? »
On répondit à sa question par les [[Théorèmes d'incomplétude de Gödel|théorèmes d'incomplétude]] de [[Kurt Gödel|Gödel]], la [[machine de Turing|machine]] de [[Alan Turing|Turing]] et le [[lambda-calcul]] de [[Alonzo Church|Church]]<ref name="Berlinski 2000"/>{{,}}<ref>
Le [[lambda-calcul]] est particulièrement important en I.A., car il a inspiré le langage [[Lisp]] (le principal langage utilisé en I.A.). {{Harvnb|Crevier|1993|p=190-196,61}}</ref>.
Leur réponse était surprenante à plusieurs titres. Tout d'abord, ils prouvèrent qu'il y avait, en fait, des limitations dans ce que la logique mathématique pouvait accomplir.

[[Fichier:Classic shot of the ENIAC.jpg|thumbnail|250px|left|thumb|L'[[ENIAC]], à la Moore School of Electrical Engineering.]]
Mais aussi (et plus important encore pour l'I.A.) leurs travaux ont suggéré que, sous ces conditions, ''toute'' forme de raisonnement mathématique pouvait être mécanisée. La [[thèse de Church]] impliquait qu'un appareil mécanique, manipulant des symboles aussi simples que des 0 et des 1, pouvait imiter tout processus concevable de déduction mathématique. Cette notion-clé se traduisit par la [[machine de Turing ]]—une simple construction théorique qui capturait l'essence de la manipulation de symboles abstraits. Cette invention inspira une poignée de scientifiques qui commencèrent alors à discuter de la possibilité de machines pensantes<ref name="Berlinski 2000"/><ref>
La [[machine de Turing]] :{{Harvnb|McCorduck|2004|p=63–64}}, {{Harvnb|Crevier|1993|p=22–24}}, {{Harvnb|Russell|Norvig|2003|p=8}} et également {{Harvnb|Turing|1936}}</ref>.

===Intelligence artificielle et premiers ordinateurs ===
Les machines à calculer sont apparues dès l'antiquité<ref group="Note">Par exemple la [[Machine d'Anticythère|machine d'Anticythère]].</ref> et ont été améliorées tout au long de l'histoire par de nombreux mathématiciens et ingénieurs, dont [[Gottfried Wilhelm Leibniz|Leibniz]]. Au début du {{s|xix}}, [[Charles Babbage]]  conçoit la machine à calculer programmable (la [[Machine analytique]]), sans jamais la construire. A sa suite, [[Ada Lovelace]]  spécule que la machine « peut composer des pièces de musique élaborées et scientifiques de toutes complexité et longueur<ref name="Menabrea1843">{{Harvnb|Menabrea|1843}}</ref>{{,}}<ref group="Note">[[Ada Lovelace]] est généralement considérée comme le premier programmeur grâce aux notes qu'elle a écrites qui détaillent complètement une méthode pour calculer les [[Nombre de Bernoulli|nombres de Bernoulli]] avec la Machine.</ref> ».

Les premiers ordinateurs modernes sont les machines massives de [[cryptanalyse]] de la [[Seconde Guerre mondiale]] (telles que le [[Zuse 3|Z3]], l'[[ENIAC]] et le [[Colossus (ordinateur)|Colossus]])<ref>{{Harvnb|McCorduck|2004|p=61–62, 64–66}}, {{Harvnb|Russell|Norvig|2003|p=14–15}}</ref>, conçues, en ce qui concerne les deux dernières, à partir des fondements théoriques établis par [[Alan Turing]] et développés par [[John Von Neumann]]<ref>Von Neumann : {{Harvnb|McCorduck|2004|p=76–80}}</ref>.

==Naissance de l'intelligence artificielle 1943−1956==
[[Fichier:BRL61-IBM 702.jpg|thumb|420px|L'IBM 702 : un ordinateur utilisé par la première génération de chercheurs en I.A.]]
''Une note sur les sections de cet article''.<ref>Les dates de début et de fin des sections de cet article correspondent à {{Harvnb|Crevier|1993}} et {{Harvnb|Russell|Norvig|2003|p=16−27}}. Les thèmes, tendances et projets sont traités dans la période où le gros du travail a été effectué.</ref>

Dans les années 1940 et 1950, une poignée de scientifiques d'une large gamme de domaines (mathématiques, psychologie, ingénierie, économie et science politique) ont commencé à discuter de la possibilité de créer un cerveau artificiel. Ce domaine de recherche de l'[[intelligence artificielle]] a été fondé en tant que discipline académique en 1956.

===Cybernétique et premiers réseaux neuronaux===
Les toutes premières recherches dans le domaine des machines pensantes ont été inspirées par une convergence d'idées qui se sont progressivement répandues de la fin des années 1930 au début des années 1950. De récentes recherches en [[neurologie]] ont montré que le cerveau  était un réseau électrique de [[neurone]]s qui envoyaient des impulsions de type tout-ou-rien. La [[cybernétique]] de [[Norbert Wiener]] a décrit les contrôles et la stabilité dans les réseaux électriques. La [[théorie de l'information]] de [[Claude Shannon]] détaille des signaux numériques (i.e., signaux tout-ou-rien). La [[théorie du calcul]] d'[[Alan Turing]] montre que toute forme de calcul peut être représentée numériquement. Les relations étroites entre ces idées suggèrent la possibilité de construire un [[cerveau artificiel]]<ref>{{Harvnb|McCorduck|2004|p=51–57, 80–107}}, {{Harvnb|Crevier|1993|p=27–32}}, {{Harvnb|Russell|Norvig|2003|p=15, 940}}, {{Harvnb|Moravec|1988|p=3}}, {{Harvnb|Cordeschi|2002|loc=Chap. 5}}.</ref>.

On peut citer comme exemples de travaux de cette veine les robots tels que les [[Tortues de Bristol]] de [[William Grey Walter]] et la {{lien|Bête de Johns Hopkins|trad=Johns Hopkins Beast}}. Ces machines n'utilisent pas d'ordinateurs, d'électronique numérique ni de raisonnement symbolique ; elles étaient entièrement contrôlées par des circuits analogiques<ref>{{Harvnb|McCorduck|2004|p=98}}, {{Harvnb|Crevier|1993|p=27−28}}, {{Harvnb|Russell|Norvig|2003|p=15, 940}}, {{Harvnb|Moravec|1988|p=3}}, {{Harvnb|Cordeschi|2002|loc=Chap. 5}}.</ref>.

[[Walter Pitts]] et [[Warren McCulloch]] ont analysé des réseaux de neurones artificiels idéaux et ont montré comment ils pourraient effectuer de simples opérations logiques. Ils ont été les premiers à évoquer ce que des chercheurs plus tard appelleraient un [[réseau neuronal]]<ref>{{Harvnb|McCorduck|2004|p=51–57, 88–94}}, {{Harvnb|Crevier|1993|p=30}}, {{Harvnb|Russell|Norvig|2003|p=15−16}}, {{Harvnb|Cordeschi|2002|loc=Chap. 5}} et voir aussi {{Harvnb|McCulloch|Pitts|1943}}</ref>. Un des étudiants inspirés par Pitts et McCulloch était [[Marvin Minsky]], à l'époque jeune étudiant de 24 ans. En 1951 (avec Dean Edmonds), il construisit la première machine à réseau neuronal, le {{lien|SNARC|trad=Stochastic neural analog reinforcement calculator}}<ref>{{Harvnb|McCorduck|2004|p=102}}, {{Harvnb|Crevier|1993|p=34−35}} et {{Harvnb|Russell|Norvig|2003|p=17}}</ref>.
Minsky allait devenir l'un des plus importants leaders et innovateurs en I.A. des cinquante prochaines années.

===L'I.A. dans les jeux===
En 1951, en utilisant la machine [[Ferranti Mark I]] de l'[[Université de Manchester]], [[Christopher Strachey]] a écrit un programme de jeu de dames et Dietrich Prinz un de jeu d'échecs<ref>cf. {{en}}''[http://www.alanturing.net/turing_archive/pages/Reference%20Articles/BriefHistofComp.html A Brief History of Computing]'' sur AlanTuring.net.</ref>. Le jeu de dames d'[[Arthur Samuel]], développé au milieu des années 1950 et au début des années 1960, a fini par acquérir un niveau suffisant pour défier un bon amateur<ref>{{Ouvrage|nom1=Schaeffer|prénom1=Jonathan|titre=One Jump Ahead: Challenging Human Supremacy in Checkers|année=1997|consulté le=2009|éditeur=Springer|isbn=978-0-387-76575-4|numéro chapitre=6}}</ref>. L'[[Intelligence artificielle (jeux vidéo)|I.A. dans les jeux]] continuera à servir de mètre-étalon des avancées en intelligence artificielle tout au long de l'histoire.

===Test de Turing===
En 1950 [[Alan Turing]] publie un [[Computing machinery and intelligence|papier mémorable]] dans lequel il spécule sur la possibilité de créer des machines dotées d'une véritable intelligence<ref>{{Harvnb|McCorduck|2004|p=70−72}}, {{Harvnb|Crevier|1993|p=22−25}}, {{Harvnb|Russell|Norvig|2003|p=2−3,948}}, {{Harvnb|Haugeland|1985|p=6−9}}, {{Harvnb|Cordeschi|2002|p=170–176}}. Voir aussi {{Harvnb|Turing|1950}}</ref>.
Il remarque qu'il est difficile de définir l'« intelligence » et imagine son célèbre [[Test de Turing]]. Si une machine peut mener une conversation (par [[téléscripteur]] interposé) qu'on ne puisse différencier d'une conversation avec un être humain, alors la machine pouvait être qualifiée d'« intelligente ». Cette version simplifiée du problème a permis à Turing d'argumenter de manière convaincante qu'une « machine pensante » était au-moins ''plausible'', ce papier répondant à toutes les objections classiques à cette proposition<ref>{{Harvnb|Russell|Norvig|2003|p=948}} déclare que Turing répond à toutes les objections majeures à l'I.A. qui sont apparues dans les années qui suivirent la publication de ce papier.</ref>. Le test de Turing a été la première hypothèse sérieuse dans le domaine de la philosophie de l'intelligence artificielle.

===Raisonnement symbolique et le Théoricien Logique===
Quand l'accès aux [[ordinateur]]s est devenu possible au milieu des années 1950, peu de scientifiques ont instinctivement compris qu'une machine qui pouvait manipuler des nombres pouvait aussi manipuler des symboles et que cette manipulation de symboles pouvait potentiellement être l'essence-même de la pensée humaine. Il a fallu de nouvelles approches pour appréhender la création de machines pensantes<ref>{{Harvnb|McCorduck|2004|p=137–170}}, {{Harvnb|Crevier|1993|p=44–47}}</ref>.

En 1955, [[Allen Newell]] et (le futur prix Nobel) [[Herbert Simon]] ont créé le « {{Lien|Théoricien Logique|trad=Logic Theorist}} » (avec l'aide de [[John Clifford Shaw|Cliff Shaw]]). Le programme finira par prouver 38 des 52 premiers théorèmes des ''[[Principia Mathematica]]'' de [[Bertrand Russell|Russell]] et [[Alfred North Whitehead|Whitehead]], et a même trouvé des preuves nouvelles et plus élégantes pour quelques uns d'entre eux<ref>{{Harvnb|McCorduck|2004|p=123–125}}, {{Harvnb|Crevier|1993|p=44−46}} et {{Harvnb|Russell|Norvig|2003|p=17}}</ref>.
Simon raconte qu'ils ont « résolu le vénérable [[problème corps-esprit]], expliquant comment un système composé de matière peut avoit les propriétés de l'esprit<ref>
Cité dans {{Harvnb|Crevier|1993|p=46}} et {{Harvnb|Russell|Norvig|2003|p=17}}</ref> ».
(C'est l'une des premières formulations d'un mouvement philosophique que [[John Searle]] appelera plus tard « [[Chambre chinoise|I.A. forte]] » : les machines peuvent contenir des esprits de manière similaire aux corps humains<ref>{{Harvnb|Russell|Norvig|2003|p=947,952}}</ref>.)

=== Conférence de Dartmouth de 1956 : naissance de l'intelligence artificielle ===
La Conférence de Dartmouth de 1956<ref> {{Harvnb|McCorduck|2004|p=111–136}}, {{Harvnb|Crevier|1993|p=49–51}} et {{Harvnb|Russell|Norvig|2003|p=17}}</ref> a été organisée par [[Marvin Minsky]], [[John McCarthy]] et deux scientifiques seniors : [[Claude Shannon]] et [[Nathaniel Rochester (scientifique)|Nathan Rochester]] d'[[International Business Machines|IBM]]. La thèse de la conférence incluait cette assertion : « chaque aspect de l'apprentissage ou toute autre caractéristique de l'intelligence peut être si précisément décrit qu'une machine peut être conçue pour le simuler<ref>
Voir {{Harvnb|McCarthy|Minsky|Rochester|Shannon|1955}}. Voir également {{Harvnb|Crevier|1993|p=48}} où [[Daniel Crevier|Crevier]] déclare que « [cette thèse] est devenue plus tard connue comme l’'hypothèse des systèmes de symbole physique' ». L'hypothèse de [[système de symbole physique]] a été developpée et nommée par [[Allen Newell|Newell]] et [[Herbert Simon|Simon]] dans leur papier sur le ''[[General Problem Solver]]''. {{Harvnb|Newell|Simon|1963}} Cela comporte une définition plus spécifique de la « machine » en tant qu'agent qui manipule des symboles (voir aussi la [[philosophie de l'intelligence artificielle]]).</ref> ».
Parmi les participants on retrouve [[Ray Solomonoff]], [[Oliver Selfridge]], [[Trenchard More]], [[Arthur Samuel]], [[Allen Newell]] et [[Herbert Simon]], qui vont tous créer des programmes importants durant les premières décennies de la recherche en I.A.<ref>
{{Harvnb|McCorduck|2004|p=129–130}} raconte comment les anciens de la conférence de Dartmouth ont dominé les deux premières décennies de la recherche en I.A., les surnommant la « faculté invisible ».</ref>.
À la conférence, Newell et Simon ont débuté le « [[Théoricien Logique]] » et McCarthy a convaincu l'auditoire d'accepter l'expression « Intelligence Artificielle » comme intitulé du domaine<ref>« Je ne jurerai pas et je ne l'avais pas encore vu avant », McCarthy indique à [[Pamela McCorduck]] en 1979. {{Harvnb|McCorduck|2004|p=114}} Cependant, [[John McCarthy|McCarthy]] a aussi déclaré sans équivoque « J'ai inventé le terme » dans une interview du [[CNET]]. {{Harv|Skillings|2006}}</ref>.
La conférence de Dartmouth de 1956 a été le moment-clé où l'I.A. a trouvé son nom, sa mission, ses premières réussites et ses acteurs importants, et est largement considérée comme la naissance de l'I.A.<ref>{{Harvnb|Crevier|1993|p=49}} écrit que « la conférence est généralement reconnue comme la date de naissance officielle de la nouvelle science. »</ref>.

==L'âge d'or 1956−1974==
Les années qui suivirent la conférence de Dartmouth furent une ère de découverte, de conquêtes effrénées de nouvelles contrées. Les programmes développés à l'époque sont considérés par la plupart des personnes comme simplement « extraordinaires<ref>Russell et Norvig ont écrit que « c'était extraordinaire dès qu'un ordinateur faisait quoi que ce soit de vaguement malin. » {{Harvnb|Russell|Norvig|2003|p=18}}</ref> » : des ordinateurs résolvaient des problèmes algébriques de mots, prouvaient des théorèmes en géométrie et apprenaient à parler anglais. À cette époque, peu auraient crû que de tels comportements « intelligents » de machines étaient tout simplement possibles<ref>{{Harvnb|Crevier|1993|pp=52−107}}, {{Harvnb|Moravec|1988|p=9}} et {{Harvnb|Russell|Norvig|2003|p=18−21}}</ref>. Les chercheurs exprimaient alors un optimisme intense dans le privé et dans leurs papiers, ils prédisaient qu'une machine complètement intelligente serait construite dans les 20 ans à venir<ref>{{Harvnb|McCorduck|2004|p=218}}, {{Harvnb|Crevier|1993|p=108−109}} et {{Harvnb|Russell|Norvig|2003|p=21}}</ref>. Les agences gouvernementales comme la [[Defense Advanced Research Projects Agency|DARPA]] investissaient massivement dans ce nouveau domaine<ref>{{Harvnb|Crevier|1993|pp=52−107}}, {{Harvnb|Moravec|1988|p=9}}</ref>.

===Le travail===
Beaucoup de programmes ont été couronnés de succès et de nouvelles directions tentées à la fin des années 1950 et dans les années 1960. Les plus influentes sont décrites plus bas.

====Raisonnement par tâtonnements====
Ils étaient nombreux parmi les premiers programmes d'I.A. à utiliser le même [[algorithme]] fondamental. Pour remplir certains objectifs (comme remporter un jeu ou prouver un théorème), ils procédaient pas à pas vers la solution (en effectuant un mouvement ou une déduction à la fois) comme s'ils naviguaient dans un labyrinthe, [[Retour sur trace|revenant en arrière]] dès qu'ils se heurtaient à une impasse. Ce paradigme était appelé « raisonnement par tâtonnements<ref>Le raisonnement par tâtonnements : {{Harvnb|McCorduck|2004|p=247–248}}, {{Harvnb|Russell|Norvig|2003|p=59−61}}</ref> ».

La principale difficulté réside dans le fait que, pour beaucoup de problèmes, le nombre de chemins possibles à travers le « labyrinthe » est tout simplement astronomique (la fameuse « [[explosion combinatoire]] »). Des chercheurs ont alors essayé de réduire l'espace de recherche à l'aide d'[[heuristique]] ou de « règles empiriques » qui élimineraient ces chemins dont il était peu probable qu'ils mènent à une solution<ref>Heuristique : {{Harvnb|McCorduck|2004|p=246}}, {{Harvnb|Russell|Norvig|2003|p=21−22}}</ref>.

[[Allen Newell|Newell]] et [[Herbert A. Simon|Simon]] ont essayé de capturer une version générale de cet algorithme dans un programme appelé le ''[[General Problem Solver]]''<ref>GPS: {{Harvnb|McCorduck|2004|p=245–250}}, {{Harvnb|Crevier|1993|p=GPS?}}, {{Harvnb|Russell|Norvig|2003|p=GPS?}}</ref> (« solutionneur de problème général »). Certains programmes de « recherche » ont été capables d'accomplir des tâches impressionnantes comme des résolutions de problèmes géométriques et algébriques, tels que le ''[[Geometry theorem prover|Geometry Theorem Prover]]'' d'Herbert Gelernter (1958) et le [[Symbolic automatic integrator|SAINT]], écrit par James Slagle, un des étudiants de [[Marvin Minsky|Minsky]]<ref>{{Harvnb|Crevier|1993|p=51−58,65−66}} et {{Harvnb|Russell|Norvig|2003|p=18−19}}</ref> (1961). D'autres programmes cherchaient à travers des objectifs et sous-objectifs pour planifier des actions, comme le système [[STRIPS]] développé à [[Université Stanford|Stanford]] pour contrôler le comportement de leur robot, [[Shakey the Robot|Shakey]]<ref>{{Harvnb|McCorduck|2004|p=268–271}}, {{Harvnb|Crevier|1993|p=95−96}}, {{Harvnb|Moravec|1988|p=14−15}}</ref>.

[[Fichier:SemanticNetArbre_sémantique_fr.jpg|left|thumb|400px|Un exemple de réseau sémantique.]]

====Langage naturel====
Un but majeur de la recherche en I.A. est de permettre aux ordinateurs de communiquer en [[Traitement automatique du langage naturel|langage naturel]] comme l'anglais. Un des premiers succès était le programme [[STUDENT (programme)|STUDENT]] de [[Daniel G. Bobrow|Bobrow]], qui pouvait résoudre des problèmes algébriques rédigés pour lycéens<ref>{{Harvnb|McCorduck|2004|p=286}}, {{Harvnb|Crevier|1993|p=76−79}}, {{Harvnb|Russell|Norvig|2003|p=19}}</ref>.

Un [[réseau sémantique]] représente des concepts (par ex. « maison », « porte ») à l'aide de nœuds et les relations entre les concepts (par ex. « possède un ») par des liaisons entre ces nœuds. Le premier programme d' I.A. à utiliser un réseau sémantique a été écrit par [[Ross Quillian]]<ref>{{Harvnb|Crevier|1993|p=79−83}}</ref> et la version la plus performante (et controversée) a été la ''[[Conceptual dependency theory]]'' de [[Roger Schank]]<ref>{{Harvnb|Crevier|1993|p=164−172}}</ref>.

[[ELIZA]] de [[Joseph Weizenbaum]] pouvait mener des conversations si réalistes que certains utilisateurs se sont laissé abuser en croyant communiquer avec un être humain et non un programme. En réalité, ELIZA n'avait aucune idée de ce dont elle parlait. Elle donnait simplement une « réponse-bateau » ou reformulait en réponse grâce à quelques règles de grammaire. ELIZA était le premier [[agent conversationnel]]<ref>{{Harvnb|McCorduck|2004|p=291–296}}, {{Harvnb|Crevier|1993|p=134−139}}</ref>.

====Micro-mondes====
À la fin des années 1960, [[Marvin Minsky]] et [[Seymour Papert]] du Laboratoire d'I.A. du [[Massachusetts Institute of Technology|M.I.T.]] ont proposé que la recherche d'I.A. se concentre sur des situations artificiellement simplifiées appelées aussi micro-mondes. Ils ont mentionné à juste titre que dans les sciences performantes comme la physique, les principes fondamentaux étaient souvent mieux compris en utilisant des modèles simplifiés tels que des avions sans friction, ou des corps parfaitement rigides. La majorité de la recherche s'est alors centrée sur un « [[monde-blocs]] », qui consistait en un ensemble de blocs colorés de formes et tailles variées disposés sur une surface plane<ref>{{Harvnb|McCorduck|2004|p=299–305}}, {{Harvnb|Crevier|1993|p=83−102}}, {{Harvnb|Russell|Norvig|2003|p=19}} et {{Harvnb|Copeland|2000}}</ref>.

Ce paradigme a permis des travaux innovants dans la vision industrielle de [[Gerald Jay Sussman|Gerald Sussman]] (qui dirigeait l'équipe), [[Adolfo Guzman]], [[David Waltz]] (qui inventa la « [[propagation de contraintes]] »), et surtout [[Patrick Winston]]. Au même moment, [[Marvin Minsky|Minsky]] et [[Seymour Papert|Papert]] construisait un bras robotique qui empilait des blocs, insufflant la vie dans ces monde-blocs. La plus grande réussite de ces programmes micro-mondes a été le [[SHRDLU]] de [[Terry Winograd]]. Ce dernier pouvait communiquer en anglais à l'aide de phrases ordinaires, planifier des opérations et les exécuter<ref>{{Harvnb|McCorduck|2004|p=300–305}}, {{Harvnb|Crevier|1993|p=84−102}}, {{Harvnb|Russell|Norvig|2003|p=19}}</ref>.

===L'optimisme===
La première génération de chercheurs en I.A. faisait les prévisions suivantes à propos de leur travail :
* En 1958, [[Herbert Simon|H. Simon]] et [[Allen Newell]] : « d'ici dix ans un ordinateur sera le champion du monde des échecs » et « d'ici dix ans, un ordinateur découvrira et résoudra un nouveau théorème mathématique majeur<ref>{{Harvnb|Simon|Newell|1958|p=7−8}} quoted in {{Harvnb|Crevier|1993|p=108}}. Voir aussi {{Harvnb|Russell|Norvig|2003|p=21}}</ref> ».
* En 1965, [[Herbert Simon|H. Simon]] : « des machines seront capables, d'ici vingt ans, de faire tout travail que l'homme peut faire<ref>{{Harvnb|Simon|1965|p=96}} quoted in {{Harvnb|Crevier|1993|p=109}}</ref> ».
* En 1967, [[Marvin Minsky]] : « dans une génération [...] le problème de la création d'une 'intelligence artificielle' en grande partie résolu<ref>{{Harvnb|Minsky|1967|p=2}} cité dans {{Harvnb|Crevier|1993|p=109}}</ref> ».
* En 1970, [[Marvin Minsky]] (dans le magazine ''[[Life]]'') : « Dans trois à huit ans nous aurons une machine avec l'intelligence générale d'un être humain ordinaire<ref>Minsky croit fermement qu'on l'a mal cité. Voir {{Harvnb|McCorduck|2004|p=272–274}}, {{Harvnb|Crevier|1993|p=96}} et {{Harvnb|Darrach|1970}}.</ref> ».

===L'argent===
En juin 1963 le [[Massachusetts Institute of Technology|M.I.T.]] reçoit une subvention de 2,2 millions de $ de la toute jeune ARPA (« Agence pour les Projets de Recherche Avancée », qui deviendra plus tard la [[Defense Advanced Research Projects Agency|DARPA]]). L'argent a été utilisé pour financer le {{lien|Projet MAC|trad=MIT Computer Science and Artificial Intelligence Laboratory#Project_MAC}} qui englobe le « Groupe I.A. » fondé par [[Marvin Minsky|Minsky]] et [[John McCarthy (computer scientist)|McCarthy]] cinq ans plus tôt. L'[[DARPA|ARPA]] continuera à fournir trois millions de dollars par an jusqu'aux années 1970<ref>{{Harvnb|Crevier|1993|p=64−65}}</ref>.
L'ARPA a fait des subventions similaires au programme de [[Allen Newell|Newell]] et [[Herbert Simon|Simon]] à [[Université Carnegie-Mellon|Carnegie-Mellon]] et au Projet [[Université Stanford|Stanford I.A.]] (fondé par John McCarthy en 1963)<ref>{{Harvnb|Crevier|1993|p=94}}</ref>. Un autre laboratoire important d'I.A. a été établi à l'[[Université d'Édimbourg]] par [[Donald Michie]] en 1965<ref>{{Harvnb|Howe|1994}}</ref>.
Ces quatre institutions continueront d'être les principaux centres de recherche en I.A. (et financement) au niveau académique pendant de nombreuses années<ref>{{Harvnb|McCorduck|2004|p=131}}, {{Harvnb|Crevier|1993|p=51}}. McCorduck remarque également que les financements étaient pour la plupart dirigés par les anciens des Conférences de Dartmouth de 1956.</ref>.

L'argent était distribué avec peu contrôle : L'ancien professeur de Minsky à [[Université d'Harvard|Harvard]], [[Joseph Carl Robnett Licklider|J. C. R. Licklider]], alors à la tête du « Bureau des Techniques de Traitement de l'Information » (''IPTO'') et directeur du Programme ''Command & Control'' de l'ARPA, croyait que son organisation devait « financer des personnes, pas des projets ! » et autorisait les chercheurs à poursuivre toutes les pistes qui leur semblaient intéressantes<ref>{{Harvnb|Crevier|1993|p=65}}</ref>. Cela créa une atmosphère de liberté totale au M.I.T. qui donna naissance à la culture ''[[Hacker (université)|hacker]]''<ref>{{Harvnb|Crevier|1993|p=68−71}}, et {{Harvnb|Turkle|1984}}</ref>. Succédèrent à Licklider (1962-64) [[Ivan Sutherland]] (1964-66), [[Robert Taylor]] (1966-69) puis [[Lawrence Roberts]] (1969-1972), tous proches du M.I.T. et dans la contnuité de Licklider concernant l'I.A. Néanmoins cette attitude non-interventionniste ne dura pas.

==La première hibernation de l'intelligence artificielle (1974−1980) ==
Dans les années 1970, l'intelligence  subit critiques et revers budgétaires, car les chercheurs en intelligence artificielle n'appréhendent pas les difficultés des problèmes auxquels ils sont confrontés. Leur immense optimisme a engendré une attente excessive et quand les résultats promis ne se matérialisent pas, les investissements consacrés à l'intelligence artificielle s'étiolent<ref>{{Harvnb|Crevier|1993|p=100−144}} et {{Harvnb|Russell|Norvig|2003|p=21−22}}</ref>. Dans la même période, le [[connexionisme]] a été presque complètement mis sous le boisseau pour 10 ans par la critique dévastatrice de [[Marvin Minsky]] sur les [[perceptron]]s<ref name="Perceptrons">{{Harvnb|McCorduck|2004|p=104−107}}, {{Harvnb|Crevier|1993|p=102−105}}, {{Harvnb|Russell|Norvig|2003|p=22}}</ref>.
Malgré l'image négative de l'intelligence artificielle dans le grand public à la fin des années 1970, de nouvelles idées sont explorées en [[programmation logique]], raisonnement de ''bon sens''<ref group="Note">Le ''raisonnement de bon sens'' est la branche de l'intelligence artificielle qui tente de répliquer la pensée humaine. Dans ce domaine, il y a :
* les bases de connaissance de culture générale,
* les méthodes de raisonnement imitant la pensée humaine (raisonnement à base de connaissances par défaut, raisonnement rapide dans un large éventail de domaines, tolérance à l'incertitude, prise de décisions sous connaissance incomplète et correction a posteriori quand les connaissances s'améliorent),
* le développement de nouveaux types d'architectures cognitives compatibles avec plusieurs méthodes et représentations de raisonnement.</ref> et dans d'autres directions<ref>{{Harvnb|Crevier| 1993|p=163−196}}</ref>.

===Les problèmes===
Au début des années soixante-dix, les capacités des programmes d'I.A. sont limitées. Les plus performants  peinent à manipuler des versions simplistes des problèmes qu'ils sont supposés résoudre  et tous les problèmes sont, d'une certaine manière, des « broutilles<ref>{{Harvnb|Crevier|1993|p=146}}</ref> ». De fait, les chercheurs en I.A. font face à plusieurs limites fondamentales insurmontables et bien que certaines limites soient dépassées depuis, d'autres demeurent de vrais obstacles<ref>{{Harvnb|Russell|Norvig|2003|p=20−21}}</ref>.
====Limites de la puissance de calcul ====
{{section à recycler}}
L'espace mémoire et la puissance de calcul sont trop limités pour des poblèmes intéressants. Par exemple, le travail de [[Ross Quillian]] sur le langage naturel est démontré avec un vocabulaire de ''vingt'' mots, car il ne peut y en avoir plus en mémoire<ref>{{Harvnb|Crevier|1993|p=146−148}}, voir aussi {{Harvnb|Buchanan|2005|p=56}}:{{en}} ''{{citation|langue=en|Early programs were necessarily limited in scope by the size and speed of memory}}''</ref>. [[Hans Moravec]] se plaint en 1976 du fait que les ordinateurs soient des millions de fois trop faibles pour mettre en évidence de l'intelligence.  En-dessous d'un certain seuil, c'est juste impossible, mais, comme la puissance [[Loi de Moore|augmente]], ça devient finalement facile<ref>{{Harvnb|Moravec|1976}}. [[John McCarthy|McCarthy]] a toujours été opposé à Moravec là-dessus, dès leurs premiers jours ensemble au Laboratoire d'I.A. de [[Stanford University|Stanford]]. Il a déclaré : « Je dirais qu'il y a cinquante ans, les capacités des machines étaient trop faibles, mais il y a trente ans, les capacité des machines n'étaient plus le vrai problème » dans une interview sur [[CNET (site)|CNET]]. {{Harv|Skillings|2006}}</ref>. Quant à la vision par ordinateur, Moravec estime que le simple fait d'égaler les capacités de la rétine humaine à détecter les mouvements et les contours en temps réel nécessiterait un ordinateur générique capable de 10<sup>9</sup> opérations/seconde ({{unité|1000|[[Instructions par seconde|MIPS]]}}<ref>{{en}}''{{citation|langue=en|ROBOT: Mere Machine to Transcendent Mind|auteur=Hans Moravec}}''</ref>). En fait, en 2011, les applications de vision par ordinateur concrètes ont besoin de {{formatnum:10000}} à {{unité|1000000|MIPS}}. Par comparaison, l'ordinateur le plus rapide en 1976, le [[Cray (entreprise)#Cray-1|Cray-1]] (vendu entre 5 et {{unité|8000000|$}}), était seulement capable d'environ 80 à 130 MIPS, et un ordinateur de bureau typique de l'époque n'atteignait même pas 1 MIPS.

==== Complétude NP ====
En 1972, suite au [[théorème de Cook]], [[Richard Karp]] a montré qu'il y avait de [[21 problèmes NP-complets de Karp|nombreux problèmes]] très difficiles, pour lesquels trouver des solutions optimales était impensable, avec comme conséquence que les problèmes fondamentaux de l'intelligence artificielle ne passeront pas à l'échelle.<ref>{{Harvnb|Russell|Norvig|2003|p=9,21−22}} et {{Harvnb|Lighthill|1973}}</ref>.

====Raisonnement et base de connaissance de [[culture générale]]====
De nombreuses applications majeures d'intelligence artificielle comme la [[Vision par ordinateur|vision]] ou le [[langage naturel]] ont simplement besoin d'énormes quantités d'information du monde réel : le programme doit avoir une idée de ce qu'il est en train de regarder ou de parler. Cela nécessite que le programme ait une connaissance du monde équivalente à celle d'un enfant. Les chercheurs découvrent rapidement que cela représente concrètement une ''large'' quantité d'information. Personne en 1970 ne pouvait construire une telle base de données et personne ne connaissait un programme qui pourrait intégrer autant d'information<ref>{{Harvnb|McCorduck|2004|p=300,421}}, {{Harvnb|Crevier|1993|p=113−114}}, {{Harvnb|Moravec|1988|p=13}}, {{Harvnb|Lenat|Guha|1989|loc=(Introduction)}}, {{Harvnb|Russell|Norvig|2003|p=21}}</ref>.

====Le [[Paradoxe de Moravec]]====
Démontrer des théorèmes ou résoudre des problèmes géométriques est relativement faisable par les ordinateurs, mais une simple tâche comme  reconnaître un visage ou traverser une pièce sans collision est extrêmement compliquée. Cela explique pourquoi la recherche en [[Vision industrielle|vision]] et en [[robotique]] a fait si peu de progrès au milieu des années 1970<ref>{{Harvnb|McCorduck|2004|p=456}}, {{Harvnb|Moravec|1988|p=15−16}}</ref>.

====Le [[Problème du cadre|cadre]] et les problèmes de qualification====
Les chercheurs en I.A. (comme [[John McCarthy]]) qui se sont servi de la [[logique]] ont découvert qu'ils ne pouvaient pas représenter des déductions ordinaires qui impliquaient de la [[Planification (intelligence artificielle)|planification]] ou des raisonnements par défaut sans avoir à modifier la structure de la logique elle-même. Ils ont dû développer de nouvelles logiques (comme les [[Logique non monotone|logiques non-monotones]] et [[Logique modale|modale]]s) pour essayer de résoudre ces problèmes<ref>{{Harvnb|McCarthy|Hayes|1969}}, {{Harvnb|Crevier|1993|p=117−119}}</ref>.

===La fin des investissements===
Les agences qui ont investi dans la recherche en I.A. (comme le [[Gouvernement du Royaume-Uni|gouvernement britannique]], la [[Defense Advanced Research Projects Agency|DARPA]] et le NRC, [[Conseil national de la recherche des États-Unis|Conseil américain de la recherche]]) deviennent frustrées par le manque de progrès et finissent par couper pratiquement tous les fonds de recherche fondamentale en I.A. Ce comportement commence dès 1966 quand un rapport de l'ALPAC<ref group="Note">L'ALPAC (''Automatic Language Processing Advisory Committee'') est le comité américain de sept scientifiques chargé de surveiller les progrès en matière de traitement du langage.</ref> paraît critiquer les efforts de traduction automatisée. Après avoir dépensé 20 millions de dollars, le NRC décide de tout arrêter<ref>{{Harvnb|McCorduck|2004|p=280–281}}, {{Harvnb|Crevier|1993|p=110}}, {{Harvnb|Russell|Norvig|2003|p=21}} et {{Harvnb|NRC|1999}} dans « ''Success in Speech Recognition'' » (reconnaissance en reconnaissance de la parole).</ref>.
En 1973, le {{Lien|Lighthill report|texte=Rapport Lighthill}} sur l'état de la recherche en I.A. en Angleterre a critiqué l'échec lamentable de l'I.A. à atteindre ses « ambitieux objectifs » et a conduit au démantèlement de la recherche en I.A. dans ce pays<ref>{{Harvnb|Crevier|1993|p=117}}, {{Harvnb|Russell|Norvig|2003|p=22}}, {{Harvnb|Howe|1994}} et voir aussi {{Harvnb|Lighthill|1973}}.
</ref> (Ce rapport mentionne en particulier le problème d'[[explosion combinatoire]] comme une des raisons des échecs de l'I.A.<ref>{{Harvnb|Russell|Norvig|2003|p=22}}, {{Harvnb|Lighthill|1973}},  [[John McCarthy]] a répondu que « le problème de l'explosion combinatoire était connu en I.A. depuis le départ » dans {{en}} [http://www-formal.stanford.edu/jmc/reviews/lighthill/lighthill.html ''Review of Lighthill report'']</ref>).
Quant à la DARPA, elle a été extrêmement déçue par les chercheurs travaillant dans le programme ''[[Reconnaissance automatique de la parole|Speech Understanding Research]]'' à [[Université Carnegie-Mellon|Carnegie-Mellon]] et a annulé une subvention annuelle de trois millions de dollars<ref>{{Harvnb|Crevier|1993|p=115−116}} (où ce constat apparaît). D'autres points de vue sont exposés dans {{Harvnb|McCorduck|2004|p=306–313}} et {{Harvnb|NRC|1999}} dans « ''Success in Speech Recognition'' ».</ref>.
Vers 1974, trouver des financements pour des projets d'I.A. était donc chose rare.

[[Hans Moravec]] a attribué la crise aux prédictions irréalistes de ses collègues. « Beaucoup de chercheurs se sont retrouvés piégés dans un entrelacs d'exagérations croissantes<ref>{{Harvnb|Crevier|1993|p=115}}. Moravec explique que « leurs promesses initiales à la DARPA ont été bien trop optimistes. Bien sûr, ce qu'ils livraient derrière était bien loin du compte. Mais ils sentaient qu'ils ne pouvaient promettre moins pour leur prochain objectif, et donc ils promirent davantage ».
</ref>. »
Un autre problème est apparu :  le vote de l'Amendement [[Mike Mansfield|Mansfield]] en 1969, a mis la DARPA  sous une pression croissante pour qu'elle ne finance que des « recherches directement applicables, plutôt que des recherches exploratoires fondamentales ». Un financement pour de l'exploration créative, en roue libre, tel qu'il avait cours dans les années soixante ne viendrait plus de la DARPA. Au lieu de cela, l'argent était redirigé vers des projets spécifiques avec des objectifs précis, comme des chars de combat autonomes ou des systèmes de gestion de batailles<ref>{{Harvnb|NRC|1999}} dans « Shift to Applied Research Increases Investment ». Bien que le tank autonome fut un échec, le système de gestion de batailles (appelé « ''Dynamic Analysis and Replanning Tool'' ») a été un énorme succès, économisant des milliards dans la première [[Guerre du Golfe (1990-1991)|Guerre du Golfe]], remboursant les investissements et justifiant la politique pragmatique de la DARPA, au-moins à son niveau.
</ref>.

===Critiques universitaires===
Plusieurs philosophes ont émis de fortes objections aux affirmations des chercheurs en I.A. Un des premiers opposants est [[John Lucas]], qui a contesté que le [[Théorèmes d'incomplétude de Gödel|théorème d'incomplétude]] de [[Kurt Gödel|Gödel]] démontre qu'un [[système formel]] (comme un programme informatique) ne puisse jamais prouver certaines affirmations, contrairement aux êtres humains<ref>Critique de l'I.A. de Lucas et Penrose : {{Harvnb|Crevier 1993|p=22}}, {{Harvnb|Russell|Norvig|2003|p=949−950}}, {{Harvnb|Hofstadter|1980|p=471−477}} et aussi {{Harvnb|Lucas|1961}}</ref>. [[Hubert Dreyfus]] a ridiculisé les promesses rompues des années soixante et a critiqué les hypothèses de l'I.A., argumentant que le raisonnement humain avait en fait besoin de très peu de « traitement symbolique » mais surtout du sentiment d’''[[embodiment]]'', d'[[instinct]], d'un « [[Être et Temps#Être-au-monde et préoccupation|savoir-faire]] » inconscient<ref>« Savoir-faire » est une expression de Dreyfus. Il distingue le « savoir-faire » de la « connaissance » (classique), une version moderne de la distinction d'[[Heidegger]] entre l'« étant disponible » (''{{lang|en|readiness-to-hand}}'' en anglais, ''{{lang|de|Zuhandenheit}}'' en allemand) et l'« étant subsistant »  (respectivement ''{{lang|en|presence-at-hand}}'' et ''{{lang|de|Vorhandenheit}}''). {{Harv|Dreyfus|Dreyfus|1986}}</ref>{{,}}<ref>{{lien|texte=Critiques d'Hubert Dreyfus sur l'intelligence artificielle|Hubert Dreyfus's views on artificial intelligence}} : {{Harvnb|McCorduck|2004|p=211−239}}, {{Harvnb|Crevier|1993|p=120−132}}, {{Harvnb|Russell|Norvig|2003|p=950−952}} et également {{Harvnb|Dreyfus|1965}}, {{Harvnb|Dreyfus|1972}}, {{Harvnb|Dreyfus|Dreyfus|1986}}</ref>. L'argument de la [[Chambre chinoise]] avancé par [[John Searle]] en 1980, essaie de montrer qu'on ne pouvait pas dire qu'un programme « comprenait » les symboles qu'il utilisait (une qualité appelée « [[intentionnalité]] »). Si les symboles n'avaient aucun sens pour la machine, Searle argumente qu'on ne peut pas alors qualifier la machine de « pensante<ref>Critique de l'I.A. de Searle : {{Harvnb|McCorduck|2004|p=443−445}}, {{Harvnb|Crevier|1993|p=269−271}}, {{Harvnb|Russell|Norvig|2004|p=958−960}} ainsi que {{Harvnb|Searle|1980}}</ref> ».

Ces critiques ne sont pas vraiment prises au sérieux par les chercheurs en I.A., tant certaines semblent tomber à côté. Les problèmes tels que l'indécidabilité et la définition de la culture générale semblent beaucoup plus immédiats et graves. On n'est pqs très sûr de ce que la différence entre le « savoir-faire » et l'« intentionnalité » apporte pratiquement à un [[programme informatique]]. [[Marvin Minsky|Minsky]] dit de Dreyfus et Searle qu'« ils ont mal compris, on devrait les ignorer<ref>Cité dans {{Harvnb|Crevier|1993|p=143}}</ref> ». Les critiques de Dreyfus, qui enseigne au M.I.T., ont été accueillies fraîchement : il a plus tard dit que les chercheurs en I.A. « n'osaient pas manger avec moi de peur d'être vus ensemble<ref>Cité dans {{Harvnb|Crevier|1993|p=122}}</ref> ». [[Joseph Weizenbaum]], l'auteur d'[[ELIZA]], considère, lui, que le comportement de ses collègues à l'égard de [[Hubert Dreyfus|Dreyfus]] est non-professionnel et infantile. Bien qu'il critique ouvertement les positions de Dreyfus, il a clairement fait comprendre que ce n'était pas [des manières] de traiter un homme<ref>« J'étais alors le seul membre de la communauté d'I.A. qu'on pouvait voir déjeuner avec Dreyfus. Et j'ai clairement fait comprendre qu'on ne traitait pas ainsi un autre être humain. » Joseph Weizenbaum, cité dans {{Harvnb|Crevier|1993|p=123}}.</ref>.

Weizenbaum commence à avoir de sérieux doutes éthiques à propos de l'I.A. quand [[Kenneth Colby]] écrit [[ELIZA|DOCTOR]], un [[agent conversationnel]] thérapeute. Weizenbaum est gêné par le fait que Colby voit en son programme sans esprit un outil thérapeutique sérieux. Une querelle éclate alors, et la situation empire quand Colby omet de mentionner la contribution de Weizenbaum au programme. En 1976, [[Joseph Weizenbaum|Weizenbaum]] publie ''{{lien|Computer Power and Human Reason|texte=Puissance informatique et raison humaine}}'' qui explique que le mauvais usage de l'intelligence artificielle peut potentiellement conduire à dévaloriser la vie humaine<ref>Critique de l'I.A. de Weizenbaum : {{Harvnb|McCorduck|2004|p=356−373}}, {{Harvnb|Crevier|1993|p=132−144}}, {{Harvnb|Russell|Norvig|2003|p=961}} et aussi {{Harvnb|Weizenbaum|1976}}</ref>.

===Perceptrons et la période sombre du connexionnisme===
Un [[perceptron]] est un type de [[réseau neuronal]] introduit en 1958 par [[Frank Rosenblatt]], qui a été un camarade d'école de [[Marvin Minsky]] au [[Bronx High School of Science]]. Comme la plupart des chercheurs en I.A., il est optimiste sur sa puissance, prédisant qu'« un perceptron pourra finalement être capable d'apprendre, prendre des décisions, et traduire des langues ». Un programme de recherche actif dans ce paradigme a été mené pendant les années soixante mais s'est brutalement arrêté après la publication du livre de [[Marvin Minsky|Minsky]] et [[Seymour Papert|Papert]] en 1969 intitulé ''[[Perceptron]]s''. Dans ce livre sont suggérées plusieurs limitations à ce que les perceptrons pouvaient faire et que les prédictions de [[Frank Rosenblatt]] ont été abusivement exagérées. L'effet de ce livre a été dévastateur : concrètement quasiment aucune recherche du tout dans le domaine du [[connexionnisme]] n'a été entamée pendant 10 ans. Finalement, une nouvelle génération de chercheurs refera vivre le domaine, qui deviendra par la suite un champ critique et une partie utile de l'intelligence artificielle. [[Frank Rosenblatt|Rosenblatt]] ne vivra pas pour le voir, car il décède d'un accident de bateau peu après la publication du livre<ref name="Perceptrons"/>.

===Les élégants : calcul des prédicats, Prolog et systèmes experts===
[[John McCarthy]] introduit l'usage de la logique en I.A. dès 1958,  dans son ''Advice Taker''<ref group="Note">''Advice Taker'' (« Preneur de Conseils » en français) est un programme informatique hypothétique décrit par MacCarthy dans son {{Ouvrage|titre=Programs with Common Sense|année=1958}} et est le premier programme à utiliser la logique en tant qu'outil de représentation et non en tant que matière d'étude.</ref>{{,}}<ref>{{Harvnb|McCorduck|2004|p=51}}, {{Harvnb|Russell|Norvig|2003|p=19, 23}}</ref>.
En 1963, [[J. Alan Robinson]] découvre une méthode relativement simple pour implémenter la déduction. Pour cela il invente les concepts de [[règle de résolution|résolution]] et d'[[unification]]. En effet, des implémentations plus directes, comme celles essayées par McCarthy et ses étudiants à la fin des années soixante, se sont révélées particulièrement inefficaces, car les algorithmes requièrent un nombre astronomique d'étapes pour démontrer des théorèmes très simples<ref>{{Harvnb|McCorduck|2004|p=51}}, {{Harvnb|Crevier|1993|p=190−192}}</ref>. Une utilisation plus fructueuse de la logique a été développée dans les années 1970 par [[Robert Kowalski]] à l'[[Université d'Édimbourg]] et [[Alain Colmerauer]] et [[Philippe Roussel]] à l'[[Faculté des Sciences de Luminy|Université de Marseille-Luminy]] qui ont créé le langage de programmation [[Prolog]].<ref>{{Harvnb|Crevier|1993|p=193−196}}</ref>.
Prolog utilise un sous-ensemble du [[calcul des prédicats]], les [[Clause de Horn|clauses de Horn]],  qui permet des calculs plus efficaces. D'autres chercheurs utilisent des règles de production, notamment les [[Système expert|systèmes experts]] d'[[Edward Feigenbaum]] et les logiciels d'[[Allen Newell]] et [[Herbert Simon]] qui conduit à [[Soar (architecture cognitive)|Soar]] et la {{Ouvrage|titre original=Unified Theory of Cognition|titre=Théory unifiée de la cognition|année=1990}}<ref>{{Harvnb|Crevier|1993|p=145−149,258−63}}</ref>.

L'approche logique  a été critiquée dès son apparition. Ainsi [[Hubert Dreyfus]] note que les êtres humains se servent rarement de logique quand ils résolvent des problèmes. Les expériences de psychologues tels que [[Peter Cathcart Wason|Peter Wason]], [[Eleanor Rosch]], [[Amos Tversky]], [[Daniel Kahneman]] et d'autres corroborent plus ou moins cet avis<ref>{{Harvnb|Wason|1966}} a montré que les humains éprouvent des difficultés sur des problèmes complètement abstraits, mais quand le problème est reformulé pour permettre l'utilisation de l'[[intelligence sociale]] plus intuitive, leurs performances augmentent considérablement. (Voir la[[tâche de sélection de Wason]]) {{Harvnb|Tversky|Slovic|Kahnemann|1982}} ont montré, eux, que les humains sont médiocres sur des problèmes élémentaires qui impliquent un raisonnement incertain. (Voir la [[Biais cognitif#Liste de biais cognitifs|liste de biais cognitifs]] pour plusieurs exemples). Le travail d'[[Eleanor Rosch]] est décrit dans {{Harvnb|Lakoff|1987}}</ref>.
McCarthy a rétorqué que ce que les humains font n'est pas pertinent, expliquant que le but est d'avoir des machines qui peuvent résoudre des problèmes, pas des machines qui pensent comme des humains<ref>
Une première occurrence de l'opinion de [[John McCarthy|McCathy]] apparait dans le journal [[Science (journal)|Science]] : « C'est de l'I.A., donc peu importe que ce soit psychologiquement correct » {{Harv|Kolata|1982}}, et il a confirmé 20 ans plus tard son opinion à la conférence [[AI@50]] (''Dartmouth Artificial Intelligence Conference: The Next Fifty Years'') de 2006 où il explique que « l'Intelligence artificielle n'est pas, par définition, la simulation de l'intelligence humaine » {{Harv|Maker|2006}}.</ref>.  Mais la critique la plus sévère de l'approche fondée sur la déduction automatique vient du théoricien de l'informatique [[Stephen Cook]] qui montre dans son célèbre article ''« The Complexity of Theorem-Proving Procedures »'' (''« La complexité des procédures des démonstration de théorèmes »'') qu'il n'y a pas de procédures automatiques efficaces de démonstration de théorèmes sauf si [[problème P = NP|P = NP]].

===Les brouillons : cadres et scripts===
Parmi les critiques de l'approche de [[John McCarthy|McCarthy]] on trouve ses collègues à travers le pays au [[Massachusetts Institute of Technology|M.I.T.]] [[Marvin Minsky]], [[Seymour Papert]] et [[Roger Schank]] ont essayé de résoudre des problèmes comme la « compréhension d'une histoire » et la « reconnaissance d'objets » qui ''demandent'' à une machine de penser comme une personne. Pour utiliser des concepts ordinaires comme une « chaise » ou un « restaurant », elles doivent faire toutes les mêmes hypothèses illogiques que les gens font d'habitude. Malheureusement, de tels concepts imprécis sont difficiles à représenter en logique. [[Gerald Jay Sussman|Gerald Sussman]] observe qu'« utiliser un langage précis pour décrire des concepts imprécis ne rend pas ces derniers plus précis<ref>{{Harvnb|Crevier|1993|p=175}}</ref> ». Schank décrit ces  approches anti-logiques comme « {{lien|Neats vs. scruffies|texte=brouillonnes}} », qu'il oppose aux paradigmes « {{lien|Neats vs. scruffies|texte=élégants}} » utilisés par McCarthy, Kowalski, [[Edward Feigenbaum|Feigenbaum]], [[Allen Newell|Newell]] et Simon<ref>« Brouillons contre Élégants » (''Neat vs. scruffy'') : {{Harvnb|McCorduck|2004|p=421–424}} (qui décrit l'état du débat en 1984). {{Harvnb|Crevier|1993|p=168}} (qui documente l'usage initial du terme par Schank). Un autre aspect du conflit est intitulé « la distinction procédural/déclaratif » mais ne s'est pas révélé important dans les recherches en I.A. ultérieures.</ref>.

En 1975, dans un papier majeur, Minsky note que beaucoup de ses pairs chercheurs « brouillons » utilisent le même type d'outillage : un ''cadre de travail'' qui englobe toutes les {{lien|commonsense knowledge|texte=hypothèses de culture générale}} d'un sujet donné. Par exemple, si on utilise le concept d'un « oiseau », il y a une pléiade de faits qui viennent immédiatement à l'esprit : on peut assumer qu'il vole, il mange des vers{{etc.}}. On sait que ces faits ne sont pas toujours vrais et que des déductions à partir de ces faits ne seraient pas « logiques », mais ces ensembles structurés d'hypothèses font partie du ''contexte'' de tout ce qui fait partie de nos discussions ou pensées. Il appelle ces structures les « [[Cadre (intelligence artificielle)|cadres]] ». Schank a utilisé une version de cadres qu'il a appelé « [[Scripts (intelligence artificielle)|scripts]] » pour répondre positivement aux questions sur des nouvelles en anglais<ref>{{Harvnb|McCorduck|2004|p=305–306}}, {{Harvnb|Crevier|1993|p=170−173, 246}} et {{Harvnb|Russell|Norvig|2003|p=24}}. L'article de Minsky sur les cadres : {{Harvnb|Minsky|1974}}.</ref>. Quelques années plus tard la [[programmation orientée objet]] adoptera la notion-clé d'« [[Héritage (informatique)|héritage]] » de la recherche en I.A. sur les cadres.

==Le boom 1980–1987==
Dans les années 1980, une classe de programmes d'I.A. appelée « [[Système expert|systèmes experts]] » a été adoptée par les entreprises à travers le monde et la [[Représentation des connaissances|connaissance]] est devenue le sujet central de la recherche classique en I.A. Au cours de cette période, le gouvernement japonais a massivement financé l'I.A. via son initiative « {{lien|Fifth Generation Computer Systems project|texte=Ordinateurs de cinquième génération}} ». Un autre évènement encourageant du début des années 1980 a été la renaissance du [[connexionnisme]] à travers les travaux de [[John Hopfield]] et [[David Everett Rumelhart|David Rumelhart]]. Une fois encore, l'I.A. était couronnée de succès.

===La montée des systèmes experts===
Un [[système expert]] est un programme qui répond à des questions ou résout des problèmes dans un domaine de connaissance donné, à l'aide de règles logiques dérivées de la connaissance des experts de ce domaine. Les tout premiers exemples ont été développés par [[Edward Feigenbaum]] et ses étudiants. [[Dendral]], commencé en 1965, a identifié des composants chimiques à partir de relevés de spectrométrie. [[Mycin]], développé en 1972, a permis de diagnostiquer des maladies infectieuses du sang. Ces programmes ont confirmé la viabilité de l'approche<ref>{{Harvnb|McCorduck|2004|p=327–335}} (Dendral), {{Harvnb|Crevier|1993|p=148−159}}, {{Harvnb|Russell|Norvig|2003|p=22−23}}</ref>.

Les systèmes experts se limitent volontairement à un petit domaine de connaissance spécifique (esquivant ainsi le problème de [[culture générale]]) et leur design simple permet de construire ces programmes relativement facilement et de les améliorer une fois déployés. Au final, ces programmes se sont montrés ''utiles'' : c'est la première fois que l'intelligence artificielle trouve une application pratique<ref>{{Harvnb|Crevier|1993|p=158−159}} et {{Harvnb|Russell|Norvig|2003|p=23−24}}</ref>.

En 1980, un système expert appelé [[Xcon]] a été livré par [[Université Carnegie-Mellon|Carnegie-Mellon]] à [[Digital Equipment Corporation|DEC]]. Le succès est énorme : l'entreprise a pu économiser 40 millions de dollars par an dès 1986<ref>{{Harvnb|Crevier|1993|p=198}}</ref>. Dès lors, les sociétés de par le monde commencent à développer et déployer leurs systèmes experts et vers 1985 on dépense plus d'un milliard de dollars en I.A., majoritairement dans des départements internes d'intelligence artificielle. Tout un secteur industriel s'est créé autour de ces systèmes experts, dont des compagnies de matériel informatique comme [[Symbolics]] et [[Lisp Machines (entreprise)|LMI]] (Lisp Machines, Inc.) et des éditeurs de logiciels tels que [[IntelliCorp (logiciel)|IntelliCorp]] et [[Cleverpath AION Business Rules Expert|Aion]]<ref>{{Harvnb|McCorduck|2004|p=434–435}}, {{Harvnb|Crevier|1993|p=161−162,197−203}} et {{Harvnb|Russell|Norvig|2003|p=24}}</ref>.

===La révolution de la connaissance===
La puissance des systèmes experts vient de l'expertise qu'ils contiennent. Ils font partie d'une nouvelle direction de recherche en I.A. qui a gagné du terrain dans les années 1970. « Les chercheurs en I.A. commençaient à soupçonner — avec réticence, car ça allait contre le canon scientifique de parcimonie — que l'intelligence puisse très bien être basée sur la capacité à utiliser une large quantité de savoirs divers de différentes manières<ref>{{Harvnb|McCorduck|2004|p=299}}</ref> » remarque [[Pamela McCorduck]]. « La grande leçon des années soixante-dix a été que les comportements intelligents dépendaient énormément du traitement de la connaissance, parfois d'une connaissance très avancée dans le domaine d'une tâche donnée<ref>{{Harvnb|McCorduck|2004|p=421}}</ref>. » Les [[Base de connaissance|systèmes de bases de connaissance]] et l'[[ingénierie des connaissances]] sont devenus centraux dans la recherche en intelligence artificielle des années 1980<ref>Révolution de la connaissance : {{Harvnb|McCorduck|2004|p=266–276, 298–300, 314, 421}}, {{Harvnb|Russell|Norvig|p=22–23}}</ref>.

Les années 1980 ont aussi vu la naissance de [[Cyc (projet)|Cyc]], la première tentative d'attaque frontale du problème de culture générale : une base de données gigantesque a été créée dans le but de contenir tous les faits triviaux qu'une personne moyenne connait. [[Douglas Lenat]], qui a démarré et dirigé le projet, argumente qu'il n'y a aucun raccourci ― le seul moyen pour des machines de connaître la signification de concepts humains était de leur apprendre, un concept à la fois, et manuellement. On s'attend bien sûr à ce que le projet se déroule sur plusieurs décennies<ref>Cyc : {{Harvnb|McCorduck|2004|p=489}}, {{Harvnb|Crevier|1993|p=239−243}}, {{Harvnb|Russell|Norvig|2003|p=363−365}} et {{Harvnb|Lenat|Guha|1989}}</ref>.

===L'argent est de retour : projets de la cinquième génération===
En 1981, le [[Ministère japonais de l'Économie, du Commerce et de l'Industrie]] réserve 850 millions de dollars pour le projet des {{lien|Fifth Generation Computer Systems project|texte=ordinateurs de cinquième génération}}. Leur objectif est d'écrire des programmes et de construire des machines qui peuvent tenir des conversations, traduire, interpréter des images et raisonner comme des êtres humains<ref>{{Harvnb|McCorduck|2004|p=436–441}}, {{Harvnb|Crevier|1993|p=211}}, {{Harvnb|Russell|Norvig|2003|p=24}} et voir également {{Harvnb|Feigenbaum|McCorduck|1983}}</ref>. Au grand dam des tenants de l'{{lien|Neats vs. scruffies|texte=approche brouillonne}}, ils choisissent [[Prolog]] comme langage informatique principal de leur projet<ref>{{harvnb|Crevier|1993|p=195}}</ref>, qu'ils modifient d'ailleurs assez profondément pour qu'il s'adapte à leur besoin.

D'autres pays répondent avec de nouveaux programmes équivalents. Le Royaume-Uni démarre le projet {{lien|Alvey|texte=Alvey}} de 350 millions de livres. Un consortium d'entreprises américaines forment la ''Microelectronics and Computer Technology Corporation'' (ou ''MCC'') pour financer des projets en informatique et en intelligence artificielle à grande échelle<ref>{{Harvnb|Crevier|1993|p=240}}.</ref>{{,}}<ref name = "Norvig 25" /> . La [[DARPA]] a aussi réagi en fondant la ''Strategic Computing Initiative'' (Initiative Informatique Stratégique) et en triplant ses investissements en I.A. entre 1984 et 1988<ref>{{Harvnb|McCorduck|2004|p=426–432}}, {{Harvnb|NRC|1999}} dans « ''Shift to Applied Research Increases Investment'' »</ref>.
[[Fichier:Hopfield-net.png|thumb|left|Un [[Réseau de neurones de Hopfield|réseau d'Hopfield]] à quatre nœuds.]]

===La renaissance du connexionnisme===
En 1982, le physicien [[John Hopfield]] a été capable de démontrer qu'un certain type de réseau neuronal (désormais appelé un « [[Réseau de neurones de Hopfield|réseau de Hopfield]] ») pouvait apprendre et traiter de l'information d'une manière totalement inédite. Au cours de la même période, [[David Everett Rumelhart|David Rumelhart]] a rendu populaire une nouvelle méthode de formation des réseaux neuronaux appelée « [[rétropropagation du gradient]] » (découverte quelques années avant par [[Paul Werbos]]). Ces deux nouvelles découvertes ont fait renaître le champ du [[connexionnisme]] qui avait été largement abandonné depuis 1970<ref name = "Norvig 25">{{Harvnb|Russell|Norvig|2003|p=25}}</ref>{{,}}<ref>{{Harvnb|Crevier|1993|p=214−215}}.</ref>.

Le tout jeune domaine a été unifié et inspiré par l'apparence du ''Traitement Parallèle Distribué'' de 1986—une collection d'articles en deux volumes éditée par Rumelhart et le psychologue [[James Lloyd McClelland|McClelland]]. Les réseaux neuronaux deviendront un succès commercial dans les années 1990, quand on commencera à les utiliser comme moteurs d'applications telles que la [[reconnaissance optique de caractères]] et la [[reconnaissance automatique de la parole|reconnaissance vocale]]<ref name = "Norvig 25" />{{,}}<ref>{{Harvnb|Crevier|1993|p=215−216}}.</ref>.

==La crise : le second hiver de l'I.A. 1987−1993==
La fascination de la communauté économique pour l'intelligence artificielle a gonflé puis chuté dans les années 1980 en suivant le schéma classique d'une [[bulle économique]]. L'effondrement de l'I.A. a eu lieu au niveau de la ''perception'' que les investisseurs et les agences gouvernementales en avaient — le domaine scientifique continue ses avancées malgré les critiques. [[Rodney Allen Brooks|Rodney Brooks]] et [[Hans Moravec]], chercheurs dans le domaine voisin de la [[robotique]], plaident pour une approche entièrement neuve de l'intelligence artificielle.

===Un second hiver===
L'expression « hiver de l'I.A. » a circulé parmi les chercheurs qui, ayant déjà vécu les coupes de budget de 1974, réalisent avec inquiétude que l'excitation autour des systèmes experts est hors de contrôle et qu'il y aurait sûrement de la déception derrière<ref>{{Harvnb|Crevier|1993|p=203}}. L’''hiver de l'I.A.'' est apparu pour la première fois dans le nom d'un séminaire sur le sujet de l’''[[Association for the Advancement of Artificial Intelligence]]''.</ref>. Leurs craintes sont effectivement fondées : entre la fin des années 1980 et le début des années 1990, l'intelligence artificielle a subi une série de revers financiers.

Les premiers indices d'une tempête à venir ont été le brusque effondrement du marché du [[matériel informatique]] spécialiste de l'intelligence artificielle en 1987. Les ordinateurs de bureau d'[[Apple Computer|Apple]] et [[International Business Machines|IBM]] ont progressivement amélioré leur vitesse et leur puissance et en 1987 ils deviennent plus performants que les fleurons du marché, tels que la meilleure [[machine Lisp]] de [[Symbolics]]. Il n'y a donc plus aucune raison de les acheter. Du jour au lendemain, une industrie complète pesant un demi-milliard de dollars est totalement détruite<ref>{{Harvnb|McCorduck|2004|p=435}}, {{Harvnb|Crevier|1993|p=209−210}}</ref>.

Au final, les premiers systèmes experts à succès comme le [[Xcon]] ont un coût de maintenance trop élevé. Ils sont difficiles à mettre à jour, ils ne peuvent pas apprendre, ils sont trop « {{lien|Software brittleness|texte=sensibles}} » (ainsi, ils peuvent faire des erreurs grotesques quand les paramètres sortent des valeurs habituelles), et s'embourbent dans des problèmes (tels que le problème de qualification) qui ont été identifiés des années auparavant. Les systèmes experts ont été réellement utiles, mais uniquement dans des contextes très spécifiques<ref>{{Harvnb|McCorduck|2004|p=435}} (qui cite des raisons institutionnelles pour leur ultime échec), {{Harvnb|Crevier|1993|p=204−208}} (qui cite ici la difficulté de la maintenance du savoir, c'est-à-dire apprentissage et mise à jour continus), {{Harvnb|Lenat|Guha|1989|loc=Introduction}} (qui met l'accent sur l'extrême sensibilité et l'incapacité à manipuler des qualifications limites)</ref>.

À la fin des années 1980, la ''Strategic Computing Initiative'' (Initiative Informatique Stratégique) de la DARPA a coupé ses fonds pour l'I.A. totalement et d'un coup. Une nouvelle direction à la DARPA ayant conclu que l'intelligence artificielle n'est plus la « nouvelle vague », elle a redirigé les fonds vers des projets qui lui semblent plus propices à des résultats rapides<ref>{{Harvnb|McCorduck|2004|p=430–431}}</ref>.

Vers 1991, la liste impressionnante des objectifs mis sur papier en 1981 par le Japon pour ses ''Ordinateurs de cinquième génération'' n'a pas été remplie. D'ailleurs certains d'entre eux, comme le fait de « mener une conversation ordinaire » ne l'ont toujours pas été vingt ans plus tard<ref name="FifthGenEnd">{{Harvnb|McCorduck|2004|p=441}}, {{Harvnb|Crevier|1993|p=212}}. McCorduck écrit à ce sujet : « Deux décennies et demie plus tard, nous avons pu observer que le Japon n'a pas réussi à remplir tous ses objectifs ambitieux. »</ref>. Comme pour d'autres projets en intelligence artificielle, la barre est beaucoup plus élevée que ce qu'il est vraiment possible de faire<ref name="FifthGenEnd"/>.

===L'importance du corps : Nouvelle intelligence artificielle et embodiment===
À la fin des années 1980, plusieurs chercheurs plaident pour une approche de l'intelligence artificielle complètement inédite, centrée sur la robotique<ref>{{Harvnb|McCorduck|2004|p=454–462}}</ref>. Ils pensent que pour montrer une intelligence réelle, une machine doit avoir conscience de son ''corps'' — elle doit percevoir, bouger, survivre et se gérer dans le monde. Ils expliquent que ces capacités senso-motrices sont essentielles aux capacités de plus haut niveau telles que le raisonnement de culture générale et que le raisonnement abstrait est en fait la capacité humaine la ''moins'' intéressante ou importante (cf. le [[paradoxe de Moravec]]). Ils défendent une intelligence « par la base<ref>{{Harvnb|Moravec|1988|p=20}} a écrit : « Je suis sûr que la direction de bas en haut de la recherche en I.A. rencontrera un jour la plus classique voie de haut en bas, et ce, après avoir parcouru la majorité du chemin, prête à livrer au monde réel la compétence et le savoir de culture générale qui ont échappé jusqu'ici aux programmes de raisonnement de manière si frustrante. Des machines complètement intelligentes couronneront la réunion de ces deux efforts. »</ref>. »

L'approche ravive des idées de la [[cybernétique]] et de la [[régulation]] qui ne sont pas très populaires depuis les années soixante. Un des précurseurs a été [[David Marr]], arrivé au M.I.T. à la fin des années 1970 fort de réussites passées en neuroscience théorique pour mener le groupe étudiant la [[Vision par ordinateur|vision]]. Il réfute toutes les approches symboliques (''à la fois'' la logique de [[John McCarthy|McCarthy]] et les cadres de [[Marvin Minsky|Minsky]]), argumentant que l'intelligence artificielle a besoin de comprendre la machinerie physique de la vision par la base avant qu'un traitement symbolique puisse être mis en place (Le travail de Marr a été brutalement stoppé par la leucémie en 1980.)<ref>{{Harvnb|Crevier|1993|p=183−190}}.</ref>.

Dans un papier de 1990 intitulé ''Elephants Don't Play Chess<ref>{{en}}[http://people.csail.mit.edu/brooks/papers/elephants.pdf ''Elephants Don't Play Chess'' (PDF)]</ref>'' (« Les éléphants ne jouent pas aux échecs »), le chercheur en robotique [[Rodney Allen Brooks|Rodney Brooks]] vise directement l'hypothèse de système symbolique physique, expliquant que les symboles ne sont pas toujours requis étant donné que « le monde est son propre meilleur modèle. Il est toujours parfaitement à jour. Il contient toujours tous les détails nécessaires. Le truc, c'est de le mesurer correctement et de manière répétée<ref>{{Harvnb|Brooks 1990|p=3}}</ref> ». Dans les années 1980 et 1990, beaucoup de [[Sciences cognitives|cogniticiens]] rejettent également le modèle de traitement symbolique de l'esprit en expliquant que le corps est essentiel dans le raisonnement, une thèse appelée [[embodiment]]<ref>Voir, par exemple, {{Harvnb|Lakoff|Turner|1999}}</ref>.

==L'intelligence artificielle depuis 1993 ==
Le champ de l'intelligence artificielle, avec plus d'un demi-siècle derrière lui, a finalement réussi à atteindre certains de ses plus anciens objectifs. On a commencé à s'en servir avec succès dans le secteur technologique, même sans avoir vraiment été mise en avant. Quelques réussites sont venues avec la montée en puissance des ordinateurs et d'autres ont été obtenues en se concentrant sur des problèmes isolés spécifiques et en les approfondissant avec les plus hauts standards d'intégrité scientifique. Néanmoins, la réputation de l'I.A., dans le monde des affaires au-moins, est loin d'être parfaite. En interne, on n'arrive pas à vraiment expliquer les raisons de l'échec de l'intelligence artificielle à répondre au rêve d'un niveau d'intelligence équivalent à l'homme qui a captivé l'imagination du monde dans les années 1960. Tous ces facteurs expliquent la fragmentation de l'I.A. en de nombreux sous-domaines concurrents dédiés à une problématique ou une voie précise, allant même parfois jusqu'à choisir un nom qui évite l'expression désormais souillée d'« intelligence artificielle<ref>{{Harvnb|McCorduck|2004|p=424}} discute cet éclatement et la mise au ban des objectifs initiaux de l'I.A.</ref> ». L'I.A. a du coup été à la fois plus prudente mais aussi plus fructueuse que jamais.
[[Fichier:Deep Blue.jpg|thumb|210px|[[Deep Blue]], un ordinateur semblable à celui-ci a battu [[Garry Kasparov]] en mai 1997. C'est la première machine à remporter une partie d'échecs contre un champion du monde en titre.]]

===Moments-clés et loi de Moore===
Le 11 May 1997, [[Deep Blue]] est devenu le premier système informatique de jeu d'échecs à battre le champion du monde en titre, [[Garry Kasparov]]<ref>{{Harvnb|McCorduck|2004|p=480–483}}</ref>. En 2005, un robot de Stanford a remporté le ''[[DARPA Grand Challenge]]'' en conduisant de manière autonome {{unité|131|[[Mille international|milles]]}} de piste de désert sans la découvrir au préalable<ref>{{en}} [http://www.darpa.mil/grandchallenge/ Page d'accueil de DARPA Grand Challenge]</ref>. Deux ans plus tard, une équipe de Carnegie-Mellon remporte le ''[[DARPA Urban Challenge]]'', cette fois en navigant en autonome pendant {{unité|55|milles}} dans un environnement urbain tout en respectant les conditions de trafic et le code de la route<ref>{{en}}[http://archive.darpa.mil/grandchallenge/ Archive du DARPA Grand Challenge]</ref>. En février 2011, dans un match de démonstration du [[jeu télévisé]] [[Jeopardy!]], le [[Systèmes de questions-réponses|système de questions-réponses]] d'I.B.M., [[Watson (intelligence artificielle)|Watson]], a battu les deux plus grands champions de Jeopardy!, Brad Rutter et Ken Jennings, avec une marge confortable<ref>{{Article|langue=en| url=http://www.nytimes.com/2011/02/17/science/17jeopardy-watson.html | journal=The New York Times | prénom1=John | nom1=Markoff | titre=On 'Jeopardy!' Watson Win Is All but Trivial |année=2011|mois=février|jour=16}}</ref>.

Ces succès ne reposent pas sur de nouveaux paradigmes révolutionnaires, mais sur une application minutieuse des techniques d'ingénierie et sur la puissance phénoménale des ordinateurs de l'époque<ref>
{{Harvnb|Kurzweil|2005|p=274}} écrit que les améliorations du jeu d'échecs en informatique, « d'après la sagesse populaire, sont uniquement dues à l'accroissement de la force brute du matériel informatique ».</ref>. En effet, la machine [[Deep Blue]] est 10 millions de fois plus rapide que la [[Ferranti Mark I]] à qui [[Christopher Strachey]] a appris à jouer aux échecs en 1951<ref group="Note">La durée d'un cycle de [[Ferranti Mark I]] était de {{unité|1.2|ms}}, ce qui correspond grossièrement à environ {{unité|833|[[FLOPS|flops]]}}. [[Deep Blue]] fournissait, lui, {{unité|11.38|gigaflops}} (sans même prendre en compte le matériel spécialement conçu pour les échecs qui équipait Deep Blue). ''À la louche'', ces deux grandeurs diffèrent d'un facteur 10⁷.</ref>. Cette augmentation spectaculaire suit la [[loi de Moore]], qui a prédit que la vitesse et la capacité de mémoire des ordinateurs doublent tous les deux ans. On est tout lentement en train de surmonter le problème de « puissance informatique brute ».

===Agents intelligents===
Un nouveau paradigme, les « [[Agent intelligent|agents intelligents]] », s'est progressivement imposé au cours des années 1990<ref>{{Harvnb|McCorduck|2004|p=471–478}}, {{Harvnb|Russell|Norvig|2003|p=55}}, où ils écrivent : « La notion d'agent-entier est désormais largement acceptée dans le domaine. » On discute du paradigme de l'[[agent intelligent]] dans les textes majeurs de l'I.A., comme {{Harvnb|Russell|Norvig|2003|p=32−58, 968−972}}, {{Harvnb|Poole|Mackworth|Goebel|1998|p=7−21}} et {{Harvnb|Luger|Stubblefield|2004|p=235−240}}</ref>. Bien que les premiers chercheurs aient proposé des approches modulaires de type « diviser pour régner » en intelligence artificielle<ref>Le [[modèle d'acteur]] de [[Carl Hewitt]] est le précurseur de la définition moderne des agents intelligents. {{Harv|Hewitt|Bishop|Steiger|1973}} John Doyle {{Harv|Doyle|1983}} et le classique ''The Society of Mind'' de [[Marvin Minsky]] {{Harv|Minsky|1986}} ont tous les deux utilisés le terme « agent ». Parmi d'autres propositions « modulaires », on trouve l'« architecture par prémisses » de Rodney Brook, la programmation orientée objet{{etc.}}.</ref>, l'[[agent intelligent]] n'a pas atteint sa forme moderne avant que [[Judea Pearl]], [[Allen Newell]] et d'autres n'y amènent des concepts de [[théorie de la décision]] et d'[[économie]]<ref name="R27">{{Harvnb|Russell|Norvig|2003|p=27, 55}}</ref>. Quand la définition économique de l'[[Homo œconomicus|agent rationnel]] s'est combinée à la définition informatique de l'[[programmation orientée objet|objet]] ou encore du [[module (programmation)|module]], le paradigme de l'[[agent intelligent]] s'installe.

Un [[agent intelligent]] est un système qui perçoit son environnement et entreprend des actions qui maximisent ses chances de réussite. Grâce à cette définition, de simple programmes qui résolvent des problèmes spécifiques sont des « agents intelligents », tout comme le sont des êtres humains et des organisations d'êtres humaines comme les [[entreprise]]s. Le paradigme de l'agent intelligent définit l'intelligence artificielle comme l'« étude des agents intelligents ». C'est une généralisation de certaines des premières définitions de l'I.A. : elle va au-delà de l'étude de l'intelligence humaine ; elle étudie tout type d'intelligence<ref>C'est cette définition de l'intelligence artificielle qui est globalement acceptée par tous les textes du {{s-|xxi}}, cf. {{Harvnb|Russell|Norvig|2003|p=32}} et {{Harvnb|Poole|Mackworth|Goebel|1998|p=1}}.</ref>.

Ce paradigme a ouvert aux chercheurs la voie vers l'étude de problèmes isolés ; les solutions trouvées sont à la fois vérifiables et utiles. Un langage commun permet de décrire les problèmes et partager leurs solutions entre les uns et les autres, et d'autres domaines ont également utilisé ce concept d'agents abstraits, comme l'économie et la [[régulation]]. On pense qu'une « architecture agent » (comme la [[Soar (architecture cognitive)|Soar]] de [[Allen Newell|Newell]]) permettrait un jour à des chercheurs de construire des systèmes plus polyvalents et intelligents à base d'agents intelligents<ref name="R27"/><ref>{{Harvnb|McCorduck|2004|p=478}}</ref>.

===« Victoire des élégants »===
Les chercheurs en intelligence artificielle ont commencé à développer et utiliser des outils mathématiques sophistiqués comme jamais auparavant<ref>{{Harvnb|McCorduck|2004|p=486–487}}, {{Harvnb|Russell|Norvig|2003|p=25–26}}</ref>. On s'est globalement rendu compte que de nombreux problèmes que l'I.A. devait résoudre ont déjà été entamés par les chercheurs des domaines comme les [[mathématiques]], l'[[économie]] ou encore la [[recherche opérationnelle]]. Le langage mathématique commun permet à la fois d'améliorer la collaboration avec des champs mieux établis et plus fructueux mais aussi la réalisation de résultats mesurables et démontrables ; l'intelligence artificielle gagne en « orthodoxie scientifique ». {{Harvnb|Russell|Norvig|2003}} qualifie cela de rien de moins qu'une « révolution » et « la victoire des {{Lien|neats and scruffies|texte=élégants}}<ref name="RN25">{{Harvnb|Russell|Norvig|2003|p=25−26}}</ref>{{,}}<ref>{{Harvnb|McCorduck|2004|p=487}}: « Au moment où j'écris ces lignes, l'intelligence artificielle bénéficie d'une hégémonie élégante. »</ref> ».

Le livre-charnière de 1988 de [[Judea Pearl]]<ref>{{Harvnb|Pearl|1988}}</ref> amène également la [[probabilité]] et la [[théorie de la décision]] dans l'I.A. Parmi les nombreux outils utilisés, on trouve le [[réseau bayésien]], le [[modèle de Markov caché]], la [[théorie de l'information]], le [[calcul stochastique]] et les plus classiques [[optimisation (mathématiques)|optimisation]]s. Des descriptions mathématiques précises ont aussi été développées pour les paradigmes d'« [[intelligence computationnelle]] » comme les [[Réseau neuronal|réseaux neuronaux]] et les [[Algorithme évolutionniste|algorithmes évolutionnistes]]<ref name="RN25"/>.

===L'I.A., travailleur de l'ombre===
Des algorithmes initialement développés par des chercheurs en intelligence artificielle commencent à faire partie de systèmes plus larges. L'I.A. a résolu beaucoup de problèmes très complexes<ref>Voir certaines {{Lien|Applications of artificial intelligence#Computer science|texte=applications de l'intelligence artificielle}}.</ref> et leurs solutions ont servi à travers tout le secteur technologique<ref>
{{Harvnb|NRC|1999}} dans « Artificial Intelligence in the 90s », et {{Harvnb|Kurzweil|2005|p=264}}</ref>, tels que l'[[exploration de données]], la [[robotique industrielle]], la [[logistique]]<ref>{{Harvnb|Russell|Norvig|2003|p=28}}</ref>, la [[Reconnaissance automatique de la parole|reconnaissance vocale]]<ref>Pour un état de l'art de l'intelligence artificielle sur la reconnaissance vocale en 2007, lire {{Harvnb|The Economist|2007}}</ref>, des applications bancaires<ref name = "CNN7242006">« Des systèmes inspirées par l'I.A. faisaient déjà partie de nombreuses technologies de tous les jours telles que les moteurs de recherche Internet, les applications bancaires de traitement de transactions et les diagnostics médicaux. » [[Nick Bostrom]], cité dans {{Harvnb|CNN|2006}}</ref>,
des diagnostics médicaux<ref name = "CNN7242006"/>
et le moteur de recherche de [[Google]]<ref>{{Harvnb|Olsen|2004}},{{Harvnb|Olsen|2006}}</ref>.

Le domaine de l'intelligence artificielle n'a quasiment reçu aucun crédit pour ces réussites. Certaines de ses plus grandes innovations ont été réduites au statut d'un énième item dans la boîte à outils de l'informatique<ref>{{Harvnb|McCorduck|2004|p=423}}, {{Harvnb|Kurzweil|2005|p=265}}, {{Harvnb|Hofstadter|1979|p=601}}</ref>. [[Nick Bostrom]] explique : « Beaucoup d'I.A. de pointe a filtré dans des applications générales, sans y être officiellement rattachée car dès que quelque chose devient suffisamment utile et commun, on lui retire l'étiquette d'I.A.<ref>{{Harvnb|CNN|2006}}</ref>. »

Beaucoup de chercheurs en intelligence artificielle dans les années quatre-vingt-dix ont volontairement appelé leurs études par d'autres noms, tels que l'informatique, les systèmes à base de connaissances, les systèmes cognitifs ou l'intelligence computationnelle. Cela peut être partiellement car ils considèrent leur domaine comme fondamentalement différent de l'I.A., mais aussi car ces nouveaux noms facilitent les financements. Dans le secteur commercial au-moins, les promesses non tenues de l'hiver de l'I.A. continuent de hanter la recherche en intelligence artificielle, comme le [[New York Times]] le rapporte en 2005 : « Les scientifiques en informatique et les ingénieurs logiciel ont évité l'expression 'intelligence artificielle' par crainte d'être considérés comme de doux illuminés rêveurs<ref>{{Harvnb|Markoff|2005}}</ref>{{,}}<ref>{{Harvnb|The Economist|2007}}</ref>{{,}}<ref>{{Harvnb|Tascarella|2006}}</ref>. »

===Mais où est HAL 9000 ?===
En 1968, [[Arthur C. Clarke]] et [[Stanley Kubrick]] ont imaginé que dès l'année [[2001, l'Odyssée de l'espace|2001]], une machine existerait avec une intelligence comparable, voire qui excéderait les capacités des êtres humaines. Le personnage qu'ils ont créé, [[HAL 9000]], se fonde sur une croyance partagée par nombre de chercheurs majeurs en intelligence artificielle qu'une telle machine existerait en 2001<ref>{{Harvnb|Crevier|1993|p=108−109}}</ref>.

[[Marvin Minsky]] interpelle donc : « Donc la question est pourquoi nous n'avons pas eu HAL en 2001<ref>Il continue ainsi : « La réponse est, Je crois que l'on aurait pu… J'ai assisté une fois à une conférence internationale sur le[s] réseau[x] neurona[ux]. Il y avait quarante mille inscrits… mais… si vous faisiez une conférence internationale sur, par exemple, les représentations multiples du raisonnement de culture générale, je n'ai réussi à trouver que 6 ou 7 personnes dans le monde entier. » {{Harvnb|Minsky|2001}}</ref> ? » Minsky pense que la réponse est que les problèmes centraux comme le raisonnement de culture générale, sont négligés, car la plupart des chercheurs se concentrent sur des choses telles que des applications commerciales des réseaux neuronaux ou des [[Algorithme génétique|algorithmes génétiques]]. [[John McCarthy]], d'un autre côté, blâme encore le problème de qualification<ref>{{Harvnb|Maker|2006}}</ref>. Pour [[Ray Kurzweil]], le problème est la puissance informatique et, en utilisant la loi de Moore, il prédit que les machines avec une intelligence comparable à l'humain arriveraient vers 2029<ref>{{Harvnb|Kurzweil|2005}}</ref>. Hawkins argumente que la recherche en réseau neuronal ignore les propriétés principales du [[Cortex cérébral|cortex]] humain, préférant des modèles simples, pour résoudre des problèmes simples<ref>{{Harvnb|Hawkins|Blakeslee|2004}}</ref>. Il y a plein d'autres explications et en face de chacune d'entre elles, on trouve un domaine de recherche en cours.

==Notes==
{{Références|groupe=Note}}

==Références==
{{Traduction/Référence|en|History of artificial intelligence}}
{{Références|colonnes=2}}

== Annexes ==
=== Bibliographie ===
{{refbegin}}
* {{Ouvrage | langue=en | prénom1 = David | nom1 = Berlinski | année  = 2000 | titre =The Advent of the Algorithm| éditeur = Harcourt Books | isbn=0-15-601391-6 | oclc = 46890682 }}
* {{Article | langue=en | prénom1 = Rodney | nom1 = Brooks | titre = Elephants Don't Play Chess | périodique = Robotics and Autonomous Systems | volume=6 | année =1990 | passage = 3−15 | lien auteur1=Rodney Brooks | url=http://people.csail.mit.edu/brooks/papers/elephants.pdf | consulté le=30 août 2007 | doi = 10.1016/S0921-8890(05)80025-9}}
* {{Ouvrage | langue=en | prénom1 = Bruce G. | nom1 = Buchanan  | titte = A (Very) Brief History of Artificial Intelligence | éditeur = AI Magazine | année =2005 | passage=53−60 | url=http://www.aaai.org/AITopics/assets/PDF/AIMag26-04-016.pdf }}
* {{Ouvrage | langue=en  | nom1 = Butler | prénom1 =  Samuel | lien auteur1 = Samuel Butler (1835-1902) | date = 13 |mois = juin |année = 1863 | titre = Darwin Among the Machines | url =http://www.nzetc.org/tm/scholarly/tei-ButFir-t1-g1-t1-g1-t4-body.html | éditeur = the Press | lieu=  Christchurch}}
* {{Article | langue=en | nom1=CNN | jour = 26 | mois = juillet | année = 2006 | titre=AI set to exceed human brain power
| url=http://www.cnn.com/2006/TECH/science/07/24/ai.bostrom/ | consulté le=16 octobre 2007 | périodique=CNN.com| lien périodique=CNN }}.
* {{Ouvrage| langue=en | nom1 = Copeland | prénom1=Jack | année=2000 | titre=Micro-World AI | url = http://www.alanturing.net/turing_archive/pages/Reference%20Articles/what_is_AI/What%20is%20AI06.html | consulté le=8 octobre 2008}}.
* {{Ouvrage | langue=en | nom1 =Cordeschi | prénom1=Roberto | année = 2002 | titre = The Discovery of the Artificial | éditeur =Kluwer | lieu=Dordrecht }}
* {{Ouvrage | langue=en| prénom1 = Daniel | nom1 = Crevier | année = 1993 | titre = AI: The Tumultuous Search for Artificial Intelligence
| éditeur = BasicBooks| isbn = 0-465-02997-3| lieu = New York| lien auteur1 =Daniel Crevier }}
* {{Article| langue=en | prénom1 = Brad | nom1 = Darrach | année = 1970 | mois = novembre | jour = 20 | titre=Meet Shakey, the First Electronic Person | périodique = Life Magazine| lien périodique = Life Magazine| passage = 58−68 }}
* {{Article | langue=en | prénom1 = J. | nom1 = Doyle | année = 1983 | titre = What is rational psychology? Toward a modern mental philosophy | périodique = AI Magazine | volume= 4 | numéro =3 |passage = 50−53 }}
* {{Ouvrage | langue=en | nom1=Dreyfus | prénom1=Hubert | année =1965 | titre = Alchemy and AI  | éditeur = RAND Corporation Memo | lien auteur = Hubert Dreyfus }}
* {{Ouvrage | langue=en | nom1=Dreyfus | prénom1=Hubert | année=1972 | titre = What Computers Can't Do  | éditeur = MIT Press | lieu = New York  | isbn = 0-06-090613-8 | oclc=5056816 }}
* {{Article | langue=en | nom1=The Economist | jour=7 | mois=juin | année=2007 | périodique=The Economist| lien périodique=The Economist | titre=Are You Talking to Me? | url=http://www.economist.com/science/tq/displaystory.cfm?story_id=9249338 | consulté le=16 octobre 2008}}
* {{Ouvrage | langue=en | prénom1 = Edward A. | nom1 = Feigenbaum | prénom2=Pamela |nom2=McCorduck |titre = The Fifth Generation: Artificial Intelligence and Japan's Computer Challenge to the World | éditeur = Michael Joseph | année = 1983| lien auteur1 = Edward Feigenbaum | isbn = 0-7181-2401-4 }}
* {{Ouvrage | langue=en | nom1=Hawkins | prénom1=Jeff | lien auteur1=Jeff Hawkins | nom2=Blakeslee | prénom2=Sandra | année=2004 | titre=On Intelligence | éditeur=Owl Books | lieu=New York | isbn=0-8050-7853-3 | oclc=61273290 }}
* {{Ouvrage | langue=en | nom1=Hebb | prénom1=D.O.| lien auteur=Donald Olding Hebb|  titre=The Organization of Behavior | éditeur=Wiley | lieu=New York|année=1949 | isbn=0-8058-4300-0| oclc=48871099 }}
* {{Ouvrage | langue=en | nom1=Hewitt | prénom1=Carl | lien auteur1=Carl Hewitt | nom2=Bishop | prénom2=Peter | nom3=Steiger | prénom3=Richard | année=1973 | titre=A Universal Modular Actor Formalism for Artificial Intelligence | url=http://dli.iiit.ac.in/ijcai/IJCAI-73/PDF/027B.pdf | format=PDF |éditeur=IJCAI | lien auteur2=Peter Bishop | lien auteur3=Richard Steiger }}
* {{Ouvrage | langue=en | nom1 = Hobbes | prénom1 = Thomas | langue=en| titre = Leviathan | lien titre = Léviathan (Thomas Hobbes) | année= 1651 | lien auteur1 =Thomas Hobbes }}
* {{Ouvrage | langue=en | prénom1 = Douglas | nom1 = Hofstadter| titre = Gödel, Escher, Bach: an Eternal Golden Braid| lien titre = Gödel, Escher, Bach | année = 1979| lien auteur1 = Douglas Hofstadter | éditeur = Basic Books  | isbn = 0-465-02656-7 | oclc = 225590743}}
* {{Ouvrage| langue=en | prénom1 = J. | nom1 = Howe | url=http://www.inf.ed.ac.uk/about/AIhistory.html | titre = Artificial Intelligence at Edinburgh University: a Perspective | année = 1994 | consulté le= 30 août 2007 }}
* {{Ouvrage |langue=en | prénom1 = G. | nom1=Kolata | année=1982 | titre=How can computers get common sense? | périodique=Science | numéro= 4566 | passage=1237–1238 | doi = 10.1126/science.217.4566.1237 | volume = 217 | pmid = 17837639 |bibcode = 1982Sci...217.1237K }}
* {{Ouvrage| langue=en| prénom1=Ray| nom1=Kurzweil| lien auteur1=Raymond Kurzweil| titre=The Singularity is Near|lien titre=Humanité 2.0|sous-titre=When Humans Transcend Biology|éditeur =Penguin|lieu =New York| année=2005| pages totales=652| isbn=0-14-303788-9|isbn2=978-0-14-303788-0|oclc= 71826177|bnf=}}
* {{Ouvrage |langue=en | prénom1 = George | nom1 = Lakoff | année = 1987 | titre = Women, Fire, and Dangerous Things: What Categories Reveal About the Mind | éditeur = University of Chicago Press. |lien auteur=George Lakoff | isbn = 0-226-46804-6}}
* {{Ouvrage |langue=en | nom1=Lenat | prénom1=Douglas |  nom2=Guha | prénom2=R. V.| année = 1989 | titre = Building Large Knowledge-Based Systems | éditeur = Addison-Wesley| lien auteur=Douglas Lenat | isbn=0-201-51752-3 | oclc=19981533 }}
* {{Ouvrage | langue=en | prénom1 = Gerald M. | nom1 = Levitt | titre = The Turk, Chess Automaton| éditeur = McFarland|année  = 2000|lieu = Jefferson| isbn = 0-7864-0778-6 }}
* {{Ouvrage |langue=en | nom1 = Lighthill | prénom1 = Professor Sir James | année = 1973 |sous-titre= Artificial Intelligence: A General Survey | titre = Artificial Intelligence: a paper symposium| éditeur = Science Research Council| lien auteur=James Lighthill }}
* {{Ouvrage |langue=en | nom1 = Lucas | prénom1 = John | lien auteur1 = John Lucas | année = 1961| titre = Minds, Machines and Gödel| périodique = Philosophy | passage=112–127| url = http://users.ox.ac.uk/~jrlucas/Godel/mmg.html | consulté le = 15 octobre 2008 | doi = 10.1017/S0031819100057983 | volume = 36 | numéro=XXXVI  }}
* {{Ouvrage|langue=en | nom1=Maker | prénom1=Meg Houston | année=2006 | titre=AI@50: AI Past, Present, Future | lieu=Dartmouth College
| url=http://www.engagingexperience.com/2006/07/ai50_ai_past_pr.html | consulté le=16 octobre 2008 }}
* {{Article |langue=en | nom1=Markoff | prénom1=John | lien auteur=John Markoff | jour=14 | mois=octobre| année= 2005| titre=Behind Artificial Intelligence, a Squadron of Bright Real People | url=http://www.nytimes.com/2005/10/14/technology/14artificial.html?_r=1&ei=5070&en=11ab55edb7cead5e&ex=1185940800&adxnnl=1&adxnnlx=1185805173-o7WsfW7qaP0x5/NUs1cQCQ&oref=slogin | consulté le=16 octobre 2008 | périodique=The New York Times | lien périodique=The New York Times}}
* {{Ouvrage  | langue=en | nom1= McCarthy | prénom1 = John |lien auteur1= John McCarthy|  nom2 = Minsky | prénom2 = Marvin | nom3 = Rochester | prénom3 = Nathan | nom4 = Shannon | prénom4 = Claude | lien auteur4 = Claude Shannon |url = http://www-formal.stanford.edu/jmc/history/dartmouth/dartmouth.html | titre = A Proposal for the Dartmouth Summer Research Project on Artificial Intelligence | année = 1955 | mois = août | consulté le=16 octobre 2008}}
* {{Ouvrage | langue=en| nom1 = McCarthy  | prénom1 = John | nom2 = Hayes | prénom2=P. J. | lien auteur2=Patrick J. Hayes | nom3=Meltzer | prénom3=B. J. | lien auteur3=Bernard Meltzer | nom4=Mitchie | prénom4=Donald | lien auteur4=Donald Mitchie |responsabilité3=éditeur|responsabilité4=éditeur| année = 1969| url=http://www-formal.stanford.edu/jmc/mcchay69/mcchay69.html  | consulté le=16 octobre 2008| sous-titre= Some philosophical problems from the standpoint of artificial intelligence | titre=Machine Intelligence 4 | passage = 463−502 | éditeur=Edinburgh University Press }}
* {{Ouvrage | langue=en| nom1= McCorduck | prénom1 =Pamela | année = 2004 | titre = Machines Who Think | éditeur =A. K. Peters, Ltd. | lieu =Natick | numéro d'édition =2 | isbn=1-56881-205-1 | langue=en}}
* {{Ouvrage| langue=en | nom1 = McCulloch | prénom1= Warren Sturgis |lien auteur1 = Warren McCulloch|  nom2 = Pitts | prénom2 = W. | année = 1943 | titre = A logical calculus of the ideas immanent in nervous activity | éditeur = Bulletin of Mathematical Biophysics | volume= 5 | passage = 115−127 | doi = 10.1007/BF02478259 | numéro = 4}}
* {{Ouvrage | langue=en | nom1 =Menabrea |prénom1 =Luigi Federico | | nom2 =Lovelace | prénom2 =Ada | lien auteur2 = Ada Lovelace| année =1843 |id=Menabrea1843| titre=Sketch of the Analytical Engine Invented by Charles Babbage| éditeur = Scientific Memoirs |volume=3| url= http://www.fourmilab.ch/babbage/sketch.html |consulté le=29 août 2008}} avec des notes du traducteur sur le mémoire
* {{Ouvrage| langue=en | prénom1 = Marvin | nom1 = Minsky | lien auteur1 =Marvin Minsky| année = 1967| titre = Computation: Finite and Infinite Machines| lieu =Englewood Cliffs, N.J. | éditeur  = Prentice-Hall }}
* {{Ouvrage | langue=en | prénom1 = Marvin | nom1 = Minsky | lien auteur1=Marvin Minsky| prénom2=Seymour | nom2=Papert | lien auteur2 = Seymour Papert | année = 1969| titre = Perceptrons: An Introduction to Computational Geometry | éditeur =The MIT Press  | isbn = 0-262-63111-3 | oclc = 16924756 }}
* {{Ouvrage | langue=en | prénom1 = Marvin | nom1 = Minsky | lien auteur1=Marvin Minsky| année = 1974 | titre = A Framework for Representing Knowledge| url = http://web.media.mit.edu/~minsky/papers/Frames/frames.html | consulté le=16 octobre 2008}}
* {{Ouvrage | langue=en | prénom1 = Marvin | nom1 = Minsky | lien auteur=Marvin Minsky | titre = The Society of Mind| éditeur = Simon and Schuster| année = 1986| isbn=0-671-65713-5 | oclc = 223353010 }}
* {{Ouvrage | langue=en | prénom1 = Marvin | nom1 = Minsky | lien auteur1=Marvin Minsky| année = 2001| titre=It's 2001. Where Is HAL?
| éditeur=Dr. Dobb's Technetcast| url=http://www.ddj.com/hpc-high-performance-computing/197700454?cid=RSSfeed_DDJ_AI | consulté le=8 août 2009 }}
* {{Ouvrage | langue=en | prénom1 = Hans | nom1 = Moravec | année = 1976 | url= http://www.frc.ri.cmu.edu/users/hpm/project.archive/general.articles/1975/Raw.Power.html | titre = The Role of Raw Power in Intelligence | lien auteur=Hans Moravec | consulté le=16 octobre 2008 }}
* {{Ouvrage | langue=en | prénom1= Hans | nom1 = Moravec | année = 1988 | titre = Mind Children | éditeur = Harvard University Press | isbn=0-674-57618-7 | oclc = 245755104 }}
* {{Ouvrage| langue=en | nom1 = Newell | prénom1 = Allen | nom2 = Simon | prénom2 =H. A. | année = 1963 | sous-titre =GPS: A Program that Simulates Human Thought| titre=Computers and Thought | éditeur= McGraw-Hill | isbn=0-262-56092-5 | oclc = 246968117|lieu = New York | lien auteur1=Allen Newell|nom3= Feigenbaum | prénom3= E.A. |nom4= Feldman |prénom4= J. |responsabilité3= éditeur|responsabilité4=éditeur}}
* {{Ouvrage | langue=en| nom1=Nick | prénom1=Martin | année =2005 | titre=Al Jazari: The Ingenious 13th Century Muslin Mechanic | éditeur =Al Shindagah | url=http://www.alshindagah.com/marapr2005/jaziri.html | consulté le=16 octobre 2008 }}
* {{Ouvrage |langue=en| nom1 =NRC |titre chapitre=Developments in Artificial Intelligence|  titre=Funding a Revolution: Government Support for Computing Research | éditeur=National Academy Press|année=1999| lien auteur1=Conseil national de la recherche des États-Unis | isbn=0-309-06278-0 | oclc = 246584055}}
* {{Ouvrage | langue=en | nom1=O'Connor | prénom1=Kathleen Malone | titre=The alchemical creation of life (takwin) and other concepts of Genesis in medieval Islam|éditeur =University of Pennsylvania |année =1994 |url=http://repository.upenn.edu/dissertations/AAI9503804|consulté le=10 janvier 2007}}
* {{Article |langue=en| nom1=Olsen | prénom1=Stefanie | mois=mai |jour=10| année=2004 | périodique=CNET| lien périodique=CNET| titre =Newsmaker: Google's man behind the curtain| url=http://news.cnet.com/Googles-man-behind-the-curtain/2008-1024_3-5208228.html | consulté le=17 octobre 2008 }}
* {{Article |langue=en| nom1=Olsen | prénom1=Stefanie | jour = 18|mois=août|année= 2006 | périodique=CNET| lien périodique=CNET| titre =Spying an intelligent search engine| url=http://news.cnet.com/Spying-an-intelligent-search-engine/2100-1032_3-6107048.html | consulté le=17 octobre 2008 }}
* {{Ouvrage |langue=en| nom1 = Pearl | prénom1 = J. | année = 1988 | titre = Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference | éditeur=Morgan Kaufmann | lien auteur=Judea Pearl | isbn=1-55860-479-0 | oclc = 249625842 | lieu=San Mateo (Californie)}}
* {{Ouvrage | langue=en | prénom1 = David | nom1 = Poole | prénom2 = Alan | nom2 = Mackworth | prénom3 = Randy | nom3 = Goebel | année = 1998 | titre = Computational Intelligence: A Logical Approach | url = http://www.cs.ubc.ca/~poole/ci.html| éditeur = Oxford University Press. | isbn = 0-19-510270-3}}
* {{Ouvrage | langue=en| prénom1= Stuart J. | nom1= Russell | prénom2 = Peter | nom2 = Norvig | titre = Artificial Intelligence: A Modern Approach | url = http://aima.cs.berkeley.edu/ | année= 2003 | numério d'édition = 2| éditeur = Prentice Hall | lieu = Upper Saddle River| isbn = 0-13-790395-2 | lien auteur1 =Peter Norvig}}
* {{Article |langue=en| nom1 = Samuel | prénom1 =Arthur L. | année =1959| titre = Some studies in machine learning using the game of checkers| périodique =IBM Journal of Research and Development| volume= 3 | numéro=3| passage=210−219| mois=juillet| lien auteur1=Arthur Samuel | url=http://domino.research.ibm.com/tchjr/journalindex.nsf/600cc5649e2871db852568150060213c/39a870213169f45685256bfa00683d74?OpenDocument| consulté le=20 août 2007 | doi = 10.1147/rd.33.0210}}
* {{Ouvrage | langue=en | nom1 = Searle| prénom1 = John | lien auteur1 = John Searle | année = 1980 | titre = Minds, Brains and Programs | url =  http://web.archive.org/web/20071210043312/http://members.aol.com/NeoNoetics/MindsBrainsPrograms.html  | consulté le = 13 mai 2009| périodique = Behavioral and Brain Sciences | volume = 3| numéro = 3| passage= 417–457| doi = 10.1017/S0140525X00005756}}
* {{Ouvrage| langue=en | nom1 =Simon | prénom1 = H. A. | nom2=Newell | prénom2=Allen | année = 1958 | titre = Heuristic Problem Solving: The Next Advance in Operations Research | éditeur =Operations Research | volume=6 | doi =10.1287/opre.6.1.1  }}
* {{Ouvrage| langue=en  | prénom1 = H. A. | nom1 = Simon| année = 1965 | titre=The Shape of Automation for Men and Management | éditeur =Harper & Row | lieu = New York }}
* {{Article | langue=en | nom1 = Skillings | prénom1 =  Jonathan | année= 2006 | périodique=CNET | lien périodique=CNET | titre = Newsmaker: Getting machines to think like us| url = http://news.cnet.com/Getting-machines-to-think-like-us---page-2/2008-11394_3-6090207-2.html?tag=st.next | consulté le=8 octobre 2008}}
* {{Article |langue=en| nom1=Tascarella | prénom1=Patty | jour = 11|mois=août|année= 2006
| titre=Robotics firms find fundraising struggle, with venture capital shy | périodique=Pittsburgh Business Times
| url=http://www.bizjournals.com/pittsburgh/stories/2006/08/14/focus3.html?b=1155528000%5E1329573 | consulté le= 8 octobre 2008 }}.
* {{Ouvrage| nom1=Turing | prénom1=Alan | langue=en| titre=On Computable Numbers, with an Application to the ''Entscheidungsproblem''| éditeur =Proceedings of the London Mathematical Society | série =2 | numéro = 42 | année =1936 | passage= 230–265| url=http://www.abelard.org/turpap2/tp2-ie.asp | doi = 10.1112/plms/s2-42.1.230 |lien auteur1= Alan Turing}}
* {{Article|langue= en|prénom1= Alan|nom1=Turing|lien auteur1= Alan Turing|titre= Computing Machinery and Intelligence|périodique=Mind|mois=octobre|année= 1950|volume= LIX|numéro= 236|pages= 433–460|issn= 0026-4423|url texte= http://loebner.net/Prizef/TuringArticle.html|consulté le=| id = Turing1950}}
* {{Ouvrage|langue=en | prénom1 = Joseph | nom1 = Weizenbaum  | lien auteur1=Joseph Weizenbaum | année = 1976 | titre = Computer Power and Human Reason | éditeur = W.H. Freeman & Company  | isbn=0-14-022535-8 | oclc = 10952283 }}
{{refend}}

=== Articles connexes ===
* [[Histoire des ordinateurs]]
* [[Intelligence artificielle]]
* [[Principaux projets et réalisations en intelligence artificielle]]

[[Catégorie:Intelligence artificielle]]
[[Catégorie:Histoire des sciences|Intelligence artificielle]]
{{Lien BA|en}}

[[en:History of artificial intelligence]]
[[es:Historia de la inteligencia artificial]]
[[fa:تاریخچه هوش مصنوعی]]
[[ja:人工知能の歴史]]
[[ru:История искусственного интеллекта]]
[[vi:Lịch sử ngành trí tuệ nhân tạo]]
[[zh:人工智能的历史]]