{{Confusion|texte=Ne doit pas être confondu avec [[Probabilité]]. Voir [[Interconnexions entre la théorie des probabilités et la statistique]] pour des sujets similaires.}}

[[Image:Probabilite nd6.png|333px|thumb|right|Courbes de probabilité.]]

La '''théorie des probabilités''' est l'étude [[mathématiques|mathématique]] des phénomènes caractérisés par le hasard et l'incertitude. Elle forme avec la [[statistique]] les deux ''sciences du hasard'' qui sont partie intégrante des mathématiques. Les débuts de l'étude des probabilités correspondent aux premières observations du hasard dans les [[jeu de hasard|jeux]] ou dans les [[Climat|phénomènes climatiques]] par exemple.

Bien que le calcul de probabilités sur des questions liées au hasard existent depuis longtemps, la formalisation mathématique n'est que récente. Elle date du début du {{s-|XX|e}} avec l'axiomatique de Kolmogorov. Des objets tels que les [[Événement (probabilités)|événements]], les [[mesure de probabilité|mesures de probabilité]], les [[espace probabilisé|espaces probabilisés]] ou les [[variable aléatoire|variables aléatoires]] sont centraux dans la théorie. Ils permettent de traduire de manière abstraite les comportements ou des quantités mesurées qui peuvent etre supposés aléatoires. En fonction du nombre de valeurs possibles pour le phénomène aléatoire étudié, la theorie des probabilités est dite ''discrète'' ou ''continue''. Dans le cas discret, c'est-à-dire pour un nombre au plus dénombrable d'états possibles, la théorie des probabilités se rapproche de la théorie du [[dénombrement]] ; alors que dans le cas continu, la [[théorie de l'intégration]] et la [[théorie de la mesure]] donnent les outils nécessaires. 

Les objets et résultats probabilistes sont un support nécessaire à la [[statistique]], c'est le cas par exemple du [[théorème de Bayes]], de l'évaluation des [[quantile]]s ou du [[théorème central limite]] et de la [[loi normale]]. Cette modélisation du hasard permet également de résoudre plusieurs [[Paradoxe probabiliste|paradoxes probabilistes]].

Qu'il soit discret ou continu, le [[calcul stochastique]] est l'étude des phénomènes aléatoires qui dépendent du temps. La notion d'[[intégrale stochastique]] et d'[[équation différentielle stochastique]] font partie de cette branche de la théorie des probabilités. Ces [[processus aléatoire]]s permettent de faire des liens avec plusieurs domaines plus appliqués tels que les [[mathématiques financières]], la [[mécanique statistique]], le [[traitement d'images]], etc.

== Historique ==
{{article détaillé|Histoire des probabilités}}

Avant que l'étude des probabilités soit considérée comme une science, l'observation du hasard dans les évènements naturels a amené les philosophes et les scientifiques a réfléchir sur la notion de liens entre évènements, causes et conséquences, et lois de la nature<ref name="Laplaceii">{{Harvsp|Laplace|1814|p=ii}}</ref>. Les jeux de hasard, les situations météorologiques ou les trajectoires des astres ont faits partie des domaines étudiés<ref name="Laplaceiii">{{Harvsp|Laplace|1814|p=iii}}</ref>. Les explications données sont alors liées au [[destin]], à une colère celeste ou à une présence divine<ref name="Laplaceiii"/>.

Il est communément admis que le début de la science des probabilités se situe au {{s-|XVI|e}} avec l'analyse de jeux de hasard par [[Gerolamo Cardano|Jérôme Cardan]] et au {{s-|XVII|e}} avec les discussions entre [[Pierre de Fermat]] et [[Blaise Pascal]] au sujet du [[problème des partis]] posé par [[Antoine Gombaud, chevalier de Méré]]<ref name="Quetelet7"/>. Cette nouvelle théorie est nommée ''géométrie alétoire'' par [[Antoine Gombaud, chevalier de Méré|le chevalier de Méré]] en 1654, elle est appelée par la suite ''calcul conjectural'', ''arithmetique politique'' et plus communément aujourd'hui ''théorie des probabilités''<ref name="Quetelet7">{{Harvsp|Quetelet|1853|p=7}}</ref>. Cette théorie, dite des probabilités modernes, est alors étudiée par de nombreux penseurs jusqu'au {{s-|XIX|e}} : [[Kepler]], [[Galilée (savant)|Galilée]], [[Gottfried Wilhelm Leibniz|Leibniz]], [[Christian Huygens|Huygens]], [[Edmond Halley|Halley]], [[Georges-Louis Leclerc de Buffon|Buffon]], les frères [[Famille Bernoulli|Bernoulli]], [[De Moivre]], [[Euler]], [[Jean le Rond D'Alembert|D'Alembert]], [[Nicolas de Condorcet|Condorcet]], [[Pierre-Simon de Laplace|Laplace]], [[Joseph Fourier|Fourier]]<ref name="Quetelet8">{{Harvsp|Quetelet|1853|p=78}}</ref>{{,}}<ref name="Jacod1">{{Harvsp|Jacod|Protter|2003|p=1}}</ref>. Elle est principalement basée sur les évènements discrets et la [[combinatoire]].

Au début du {{s-|XX|e}}, [[Andreï Kolmogorov|Kolmogorov]] fit la connexion entre la [[théorie de la mesure]] de Borel, la [[théorie de l'intégration]] de Lebesgue et les probabilités<ref name="Jacod1">{{Harvsp|Jacod|Protter|2003|p=1}}</ref>.

Des considérations [[analyse (mathématiques)|analytiques]] ont forcé l'introduction de variables aléatoires '''continues''' dans la théorie. Cette idée prend tout son essor dans la théorie moderne des probabilités, dont les fondations ont été posées par [[Andreï Kolmogorov|Andreï Nikolaevich Kolmogorov]]. Kolmogorov combina la notion d'[[univers (mathématiques)|univers]], introduite par [[Richard von Mises]] et la [[théorie de la mesure]] pour présenter son système d'axiomes pour la théorie des probabilités en 1933. Très vite, son approche devint la base incontestée des probabilités modernes.

== Définition ==
Suivant les époques ou les domaines d'application, la '''théorie des probabilités''' peut prendre des noms différents : '''la théorie de la probabilité mathématique'''<ref name="Cournotiv">{{Harvsp|Cournot|1843|p=iv}}</ref>, '''le calcul des probabilités'''<ref name="Cournoti">{{Harvsp|Cournot|1843|p=i}}</ref>, ou plus simplement '''les probabilités''' bien qu'il ne faille pas confondre avec ''la [[probabilité]]'' d'un évènement qui est l'évaluation de son caractère probable ou ''une [[loi de probabilité|probabilité]]'' qui est une loi (ou mesure) de probabilité.

Il a été difficile de donner une définition de la théorie des probabilités. Dans son cours vers 1893, [[Henri Poincaré]] s'exprime ainsi : « On ne peut guère donner de définition satisfaisante de la Probabilité. On dit généralement ... etc »<ref group="a" name="vonmises">{{article|langue=fr|prénom1=Richard |nom1=von Mises|lien auteur1=Richard von Mises|titre=Théorie des Probabilités. Fondement et applications|périodique=annales de l'IHP|volume=3|numéro=2|année=1932|pages=137-190|url texte=http://archive.numdam.org/ARCHIVE/AIHP/AIHP_1932__3_2/AIHP_1932__3_2_137_0/AIHP_1932__3_2_137_0.pdf}}</ref>. Cependant, il est toujours fait mention de l'étude de notions comme le [[hasard]], l'[[aléa]], la [[chance]] ou encore le caractère [[Wikt:probable|probable]] d'un évènement. Une définition peut être donnée sous la forme : 
:La théorie des probabilités est l'étude mathématique des phénomènes caractérisés par le hasard et l'incertitude<ref group="b">intialement en anglais : ''probability theory is a branch of mathematics concerned with the analysis of random phenomena.''.</ref>{{,}}<ref group="a" name="britannica">{{Lien web|url=http://www.britannica.com/EBchecked/topic/477530/probability-theory|titre=Probability theory|année=2012|site=Encyclopædia Britannica}}</ref>.
C'est-à-dire que la théorie des probabilités est un domaine des [[mathématiques]]. Ce n'a pas toujours été le cas, cette théorie a été rattachée à la [[Théorie des jeux|théorie des jeux de hasard]]<ref group="a" name="stanford">{{Lien web|auteur=Alan Hájek|url=http://plato.stanford.edu/archives/sum2012/entries/probability-interpret/|titre=Interpretations of Probability|année=2012|site=Stanford Encyclopedia of Philosophy}}</ref>, à la philosophie<ref name="Laplacei">{{Harvsp|Laplace|1814|p=i}}</ref>, les [[Géométrie|géomètres]] ont été parmi les premiers scientifiques à utiliser le calcul des probabilités<ref name="Cournotv">{{Harvsp|Cournot|1843|p=v}}</ref>. Il est à noter que le groupe mathématique [[Nicolas Bourbaki|Bourbaki]], créé en 1930 et dont le but est de proposer une présentation cohérente des mathématiques, a été critiqué pour ne pas avoir pris suffisamment en considération la théorie des probabilités : « Bourbaki s'est écarté des probabilités, les a rejetées, les a considérées comme non rigoureuses et, par son influence considérable, a dirigé la jeunesse hors du sentier des probabilités. » soulignait [[Laurent Schwartz (mathématicien)|Laurent Schwartz]] dans son autobiographie<ref name="schwartz" group="a">{{ouvrage|langue=fr|prénom1=Laurent|nom1=Schwartz|titre=Un mathématicien aux prises avec le siècle|lien titre=Un mathématicien aux prises avec le siècle|éditeur=Odile Jacob|lien éditeur=Éditions Odile Jacob|année=1997|passage=172|pages totales=531|isbn=2-7381-0462-2|lire en ligne=http://books.google.fr/books?id=Eqc0cyFR0AEC&pg=PA172&lpg=PA172&dq=Bourbaki+et+probabilit%C3%A9s&source=bl&ots=qx4j3bHjf9&sig=UD7YLNzXaSjfsI9Fet9LYo4ncqs&hl=fr&ei=PpRgTvT0LsGr-QaOsqko&sa=X&oi=book_result&ct=result&resnum=8&ved=0CFIQ6AEwBw#v=onepage&q&f=false}}</ref>.

=== Axiomatique ===
[[Image:Andrej Nikolajewitsch Kolmogorov.jpg|upright=0.6|thumb|alt=Andreï Kolmogorov|Andreï Kolmogorov]]
{{article détaillé|Axiomes des probabilités|Espace probabilisé}}
Pour pleinement appartenir aux mathématiques, la théorie des probabilités a eu besoin d'une [[axiomatique]]. Plusieurs constructions sont proposées au début du {{s-|XX|e}} comme la ''théorie des collectifs'' de [[Richard von Mises]] ou l'axiomatique de [[Andreï Kolmogorov]]. Cette dernière étant la plus pratique des axiomatiques disponibles à l'époque a été adoptée définitivement par les scientifiques à partir de 1950<ref group="a" name="chaumont">{{ouvrage|langue=fr|prénom1=Loïc|nom1=Chaumont|prénom2=Laurent|nom2=Mazliak |prénom3=Marc|nom3=Yor|lien auteur3=Marc Yor|titre=A.N. Kolmogorov |sous-titre=Quelques aspects de l'œuvre probabiliste|éditeur=Belin|lien éditeur=Éditions Belin|année=2003|lire en ligne=http://math.univ-angers.fr/~chaumont/rpdfiles/Kolmogorov.pdf}}</ref>. Elle a permis de pouvoir étudier le calcul des probabilités au-delà des probabilités finies, dites ''théorie discrète des probabilités'' et de considérer un cadre plus général pour la théorie des probabilités. Dans cette axiomatique, la théorie des probabilités est basée sur un [[espace probabilisé]] et ainsi beaucoup de notions correspondent à des notions de la [[théorie de l'intégration]]<ref name="Le Gall91">{{Harvsp|Le Gall|2006|p=91}}</ref>. Cependant dans la théorie des probabilités, le but est de proposer un modèle pour une expérience aléatoire.
*Un [[ensemble]], souvent noté <math>\scriptstyle \Omega</math>, représente l'ensemble de toutes les éventualités possibles, c'est-à-dire qu'il donne tous les hasards différents de l'expérience<ref name="Le Gall91"/>. Cet ensemble est également appelé ''univers des possibles''.
*Un ensemble <math>\scriptstyle \mathcal A</math> contient les [[Événement (probabilités)|événements]] qui regroupe les éventualités pour les lesquelles une certaine propriété est vérifiée. Ces évènements représentent les ensembles de possibilités pour lesquels on cherche la probabilité. Mathématiquement, un élément <math>\scriptstyle A\in \mathcal A</math> est un sous-ensemble de <math>\scriptstyle \Omega</math> et l'ensemble d'ensemble <math>\scriptstyle \mathcal A</math> est une [[Tribu (mathématiques)|tribu]]<ref name="Le Gall91"/>.
*L'espace <math>\scriptstyle (\Omega,\mathcal A)</math> est muni d'une [[mesure de probabilité]] afin de pouvoir calculer la [[probabilité]] d'une situation liée à l'expérience aléatoire. Mathématiquement, cette mesure de probabilité est une [[Fonction (mathématiques)|fonction]] qui à chaque évènement <math>\scriptstyle A\in \mathcal A</math> associe une valeur entre 0 et 1, dite ''probabilité de l'évènement A''. Cette probabilité <math>\scriptstyle \mathbb P</math> vérifie les trois [[axiomes des probabilités]]<ref name="Sinai6">{{Harvsp|Sinaï|1992|p=6}}</ref> :
*#''(positivité)'' la probabilité d'un évènement est une valeur entre 0 et 1 : pour tout <math>\scriptstyle A\in \mathcal A</math>, <math>\scriptstyle 0\leq \mathbb P(A)\leq 1</math>,
*#''(masse unitaire)'' la probabilité de l'univers est 1 : <math>\scriptstyle \mathbb P(\Omega) = 1</math>,
*#''(additivité)'' pour toute suite dénombrable d'évènements <math>\scriptstyle A_1,A_2,\dots \in \mathcal A</math> indépendants deux à deux, c'est-à-dire tels que <math>\scriptstyle A_i\cap A_j=\emptyset</math> pour tous <math>\scriptstyle i\neq j</math>, alors <math>\scriptstyle \mathbb P(\bigcup_{i\geq 1}A_i)=\sum_{i\geq 1}\mathbb P(A_i)</math>.

L'intérêt de cette construction plutôt abstraite est qu'elle permet une explication globale des calculs de probabilités et notamment des paradoxes qui occupaient tant les scientifiques tels que [[Joseph Bertrand]] (voir le [[paradoxe de Bertrand]]), [[Émile Borel]] (voir le [[paradoxe du singe savant]]), etc<ref group="a" name="chaumont"/>.

A titre d'exemple, donnons une modélisation sous forme d'espace probabilisé du lancer d'un dé :
*<math>\scriptstyle \Omega=\{1,2,3,4,5,6\}</math>, 
*<math>\scriptstyle \mathcal A=\mathcal P(\Omega)=\{\emptyset,\{1\},\dots,\{6\},\{1,2\},\dots,\{1,6\},\{2,3\},\dots,\{2,3,4,5,6\},\Omega\}</math> 
*<math>\scriptstyle \mathbb P(A)=\frac{Card(A)}{6}</math>.

Cependant cette axiomatique n'est pas nécessaire pour calculer des probabilités dans des cas simples notamment dans le cas discret. Il est facile de calculer que la probabilité d'obtenir un chiffre pair dans un lancer de dé est de 1/2.

=== Variable aléatoire ===
{{article détaillé|Variable aléatoire}}
[[Image:Twodice.svg|thumb|alt=deux dés|Diagramme représentant les résultats du lancer de deux dés et les probabilités des sommes possibles.]]
L'espace probabilisé <math>\scriptstyle (\Omega,\mathcal A,\mathbb P)</math> construit dans la section précédente est un espace abstrait. Il n'est pas forcément adapté pour effectuer des calculs. Lorsque les résultats possibles de l'expérience aléatoire ne sont pas des nombres, c'est le cas des résultats ''pile'' et ''face'' dans un lancer de pièce, il est utile de pouvoir associé une valeur numérique à chaque résultat. Une [[variable aléatoire]] remplit ce rôle.

Une variable aléatoire est une [[Fonction mesurable|application mesurable]] <math>\scriptstyle X:\Omega \rightarrow E</math> où <math>\scriptstyle (E,\mathcal E)</math> est un [[espace mesurable]]<ref name="Le Gall93">{{Harvsp|Le Gall|2006|p=93}}</ref>. C'est-à-dire qu'à chaque éventualité <math>\scriptstyle \omega\in\Omega</math> est associée une valeur <math>\scriptstyle X(\omega)</math>. Si cette valeur est réelle, la variable aléatoire est dite [[Variable aléatoire réelle|réelle]].

Comme précisé précédemment, il n'est pas toujours utile de définir l'espace probabilisé <math>\scriptstyle (\Omega,\mathcal A,\mathbb P)</math>, mais il est possible de donner directement les variables aléatoires sur l'espace <math>\scriptstyle (E,\mathcal E)</math>. La variable aléatoire s'écrit simplement <math>\scriptstyle X</math> au lieu de <math>\scriptstyle X(\omega)</math>.

De la même manière qu'il existe des cas continus et discrets pour la théorie des probabilités, il existe des variables aléatoires discrètes<ref name="Sinai9">{{Harvsp|Sinaï|1992|p=9}}</ref> et continues<ref name="Le Gall94">{{Harvsp|Le Gall|2006|p=94}}</ref>. Il est possible de considérer un [[vecteur aléatoire]] comme une variable aléatoire multidimensionnelle : <math>\scriptstyle X=(X_1,\dots, X_n)</math>. Lorsque la dimension ''n'' du vecteur n'est plus finie mais infinie, on parle de marche aléatoire ; lorsque la dimension est infinie non dénombrable, on parle de processus stochastique (voir la section ''[[#Calcul stochastique|Calcul stochastique]]'' ci-dessous).

;Exemple
Donnons un exemple simple du lancer de deux dés, c'est-à-dire le lancer d'un dé répété une fois. Une première variable <math>\scriptstyle X_1</math> aléatoire donne le résultat du premier lancer, une deuxième <math>\scriptstyle X_2</math> donne le résultat du deuxième lancer, c'est-à-dire <math>\scriptstyle X_1(\omega)\in\{1,2,3,4,5,6\}</math> et <math>\scriptstyle X_2(\omega)\in\{1,2,3,4,5,6\}</math> que l'on note plus simplement <math>\scriptstyle X_1\in\{1,2,3,4,5,6\}</math> et <math>\scriptstyle X_2\in\{1,2,3,4,5,6\}</math>.

Il est possible de s'intéresser à la somme des deux résultats, qui peut être notée par une variable aléatoire<ref name="Le Gall93"/> : <math>\scriptstyle S\in\{2,3,\dots,12\}</math>.

=== Théorie des probabilités discrète ===
La théorie des probabilités est dite '''discrète''' lorsque l'ensemble <math>\scriptstyle \Omega</math> de l'[[espace probabilisé]] est [[Ensemble fini|fini]] ou [[Ensemble dénombrable|dénombrable]]<ref name="Sinai1">{{Harvsp|Sinaï|1992|p=1}}</ref>. Le plus simple exemple d'étude en théorie des probabilités discrète est le jeu de [[pile ou face]], dans ce cas l'univers <math>\scriptstyle \Omega</math> ne contient que deux éléments : ''pile'' et ''face''. Les études d'un lancer de [[dé]], d'un tirage d'une carte dans un [[jeu de cartes]] ou par exemple du [[loto]] font également parties de la théorie des probabilités discrète.

Avant que la théorie de la mesure soit introduite, la probabilité d'un évènement a été définie comme le nombre de cas favorables divisé par le nombre de cas possibles. De manière plus pratique, une expérience aléatoire était répétée un nombre ''N'' de fois, le nombre de fois où l'évènement ''A'' est réalisé est noté <math>\scriptstyle N_A</math>. Lorsque ''N'' tend vers l'infini, la proportion <math>\scriptstyle N_A/N</math> converge vers une valeur dite probabilité de ''A''<ref name="Le Gall92">{{Harvsp|Le Gall|2006|p=92}}</ref>.

Cependant ce raisonnement n'est pas si simple pour toute question relative à une expérience aléatoire. Les différentes manières de compter ont amenées des paradoxes probabilistes. L'axiomatique de Kolomogorov (vois la section ci-dessus) a permis de résoudre ces problèmes. Dans le cas de la théorie discrète, pour une expérience non répétée, l'axiomatique s'écrit<ref name="Le Gall92"/> :
:<math>\begin{cases}\Omega=\{\omega_1,\omega_2,\dots , \omega_n\} & \text{ pour le cas d'un univers fini, }\\ \Omega=\{\omega_1,\omega_2,\omega_3,\omega_4,\dots\}&\text{ pour le cas d'un univers infini dénombrable. }\end{cases}</math>
où le choix <math>\scriptstyle \omega_1=1,\omega_2=2,\dots</math> peut être effectué pour représenter les différents résultats équiprobables de l'expérience. Plusieurs choix de tribu sont possibles, cependant il est raisonnable pour une étude discrète de choisir la tribu de [[ensemble des parties]] puisqu'il contient tous les évènements possibles :
:<math>\mathcal A=\mathcal P(\Omega)</math>.
Dans le cas de la théorie discrète, la mesure de probabilité possède la particularité de pouvoir être définie uniquement sur les singletons<ref name="Le Gall94">{{Harvsp|Le Gall|2006|p=94}}</ref> : <math>\scriptstyle \mathbb P(\{\omega_1\}),\mathbb P(\{\omega_2\}),\dots </math>. Les probabilités des autres évènements s'obtiennent grâce aux axiomes des probabilités (voir la section ci-dessus).

Lorsque l'univers <math>\scriptstyle \Omega</math> est fini, contenant ''n'' éléments, il est possible de choisir la mesure uniforme<ref name="Sinai9">{{Harvsp|Sinaï|1992|p=9}}</ref> : <math>\scriptstyle\mathbb P(\{\omega_1\})=\dots=\mathbb P(\{\omega_n\})=\frac{1}{n}</math> et ainsi obtenir la formule utile et cohérente à l'intuition des scientifiques plus anciens :
:<math>\mathbb P(A)=\frac{Card(A)}{n}</math> pour tout <math>A\in \mathcal A</math>.
Grâce à l'utilisation de ces formules, la théorie des probabilités discrète repose sur la théorie des combinaisons, aujourd'hui appelée la [[combinatoire]] et le [[dénombrement]]<ref name="Cournot21">{{Harvsp|Cournot|1843|p=21}}</ref>.

;Exemple
Reprenons l'exemple du lancer de deux dés<ref name="Le Gall92"/>. L'ensemble de tous les possibles est :
:<math>\scriptstyle \Omega=\{1,2,3,4,5,6\}^2=\{1,2,3,4,5,6\}\times \{1,2,3,4,5,6\} = \{(1,1),(1,2),\dots,(1,6),(2,1),(2,2),\dots\}</math>
C'est-à-dire que <math>\scriptstyle \Omega</math> contient tous les couples de deux chiffres, le premier correspondant au résultat du premier dé, le deuxième au résultat du deuxième. Un choix possible pour la tribu <math>\scriptstyle \mathcal A</math> est l'[[ensemble des parties]] :
:<math>\scriptstyle \mathcal A=\mathcal P(\Omega) = \{A\text{ sous-ensemble de } \Omega\}.</math>
Le choix de l'espace <math>\scriptstyle (\Omega,\mathcal A)</math> est fait de tel sorte que les singletons de <math>\scriptstyle \Omega</math> aient tous la même probabilité, ils sont dits [[équiprobable]]s. Il est alors possible de calculer les probabilités de plusieurs évènements comme 
:<math>\scriptstyle A=\{\text{obtenir 1 pour les deux dés}\}=\{(1,1)\}</math>, donc <math>\scriptstyle \mathbb P(A) = \frac{1}{36}</math>.
:<math>\scriptstyle B=\{\text{obtenir 1 pour le premier dé}\}=\{(1,1),(1,2),\dots,(1,6)\}</math>, donc <math>\scriptstyle \mathbb P(B) = \frac{6}{36}=\frac{1}{6}</math>. <math>\scriptstyle \mathbb P(B)</math> s'obtient également en décomposant en singletons : <math>\scriptstyle \mathbb P(B)=\mathbb P(\{(1,1)\})+\dots + \mathbb P(\{(1,6)\})=\frac{1}{36}+\dots + \frac{1}{36}=\frac{1}{6}</math>.

=== Théorie des probabilités continue ===
La théorie des probabilités est dite '''continue''' lorsque l'univers <math>\scriptstyle \Omega</math> n'est plus dénombrable mais quelconque, possiblement non [[Espace topologique|topologique]]<ref group="a" name="chaumont"/>. C'est-à-dire lorsque la théorie des probabilité n'est plus discrète.

Il est possible de choisir plusieurs tribus, cependant lorsque l'univers est l'ensemble des réels, il est classique de lui munir la [[tribu borélienne]] qui possède de bonnes propriétés. Si ce n'est pas le cas, l'utilisation des variables aléatoires permet de représenter l'univers par l'ensemble des réels <math>\scriptstyle \mathbb R</math>. Le terme théorie des probabilités continue est également utilisé pour désigner le cas où la variable aléatoire, ou la loi de probabilité, associée est [[loi de probabilité absolument continue|absolument continue]], c'est-à-dire qu'elle possède une densité.

La mesure de probabilité se définie plus facilement sur <math>\scriptstyle \mathbb R</math>, c'est-à-dire qu'il est plus facile de définir la [[loi de probabilité]] de la variable aléatoire<ref group="a" name="chaumont"/> :
:<math>\mathbb P(A)=\mathbb P(\{\omega, X(\omega)\in  B\})=\mathbb P(X\in B)</math> pour tout <math>\scriptstyle A\subset \Omega</math> tel que <math>\scriptstyle B\subset \mathcal E</math> soit l'[[image réciproque]] de <math>\scriptstyle A</math> par <math>\scriptstyle X</math> : <math>A=X^{-1}(B)</math>.

Dans certains cas de la théorie des probabilités continue, la variable aléatoire réelle est dite absolument continue par rapport à la mesure de Lebesgue<ref name="Le Gall94"/>, c'est-à-dire qu'il existe une fonction <math>\scriptstyle f:\mathbb R\rightarrow \mathbb R_+</math> telle que :
:<math>\mathbb P(X\in B)= \int_{\mathbb R} \bold 1_B(x) f(x)\mathrm d x</math>
où le terme <math>\scriptstyle \bold 1</math> dans l'[[Intégration (mathématiques)|intégrale]] est une [[indicatrice]]. La fonction <math>\scriptstyle f</math> est appelée la [[densité de probabilité]] de <math>\scriptstyle X</math>.

Grâce à l'utilisation de ces formules, la théorie des probabilités continue repose sur la [[théorie de l'intégration]]<ref name="Le Gall91"/>.

;Exemple
Des algorithmes<ref name="Le Gall114">{{Harvsp|Le Gall|2006|p=114}}</ref> de calcul utilisent des valeurs choisies de manière uniforme entre 0 et 1. C'est-à-dire que l'on choisit (aléatoirement) une valeur [[nombre réel|réelle]] entre 0 et 1 telle qu'aucune des valeurs n'est plus de chance d'apparaître qu'une autre. Pour formaliser cette expérience, il y a un espace probabilisé <math>\scriptstyle (\Omega, \mathcal A , \mathbb P)</math> non détaillé ici, cependant on se donne une variable aléatoire <math>\scriptstyle X</math> à valeurs dans <math>\scriptstyle E=[0,1]</math> muni de sa [[tribu borélienne]] <math>\scriptstyle \mathcal E=\mathcal B([0,1])</math> ainsi que les probabilités<ref name="Le Gall98">{{Harvsp|Le Gall|2006|p=98}}</ref> :
:<math> \mathbb P(X\in [a,b])=\frac{1}{b-a}</math> pour tout intervalle <math>\scriptstyle [a,b]</math>.

== Propriétés et outils ==
=== Calculs élémentaires ===
[[Image:Venn-7.svg|thumb|upright=0.5|Représentation en gris, par un [[diagramme de Venn]] de l'évènement <math>\scriptstyle A^c</math>.]]
[[Image:Venn-4.svg|thumb|upright=0.5|Représentation en gris de l'évènement <math>\scriptstyle A\cup B</math>.]]
[[Image:Venn-3.svg|thumb|upright=0.5|Représentation, en gris, de l'évènement <math>\scriptstyle A\cap B</math>.]]
{{article détaillé|Probabilités (mathématiques élémentaires)}}
Plusieurs formules dites élémentaires se déduisent des axiomes des probabilités (voir la section ci-dessus). Certaines sont intuitives, d'autres le sont moins.

Il est à noter que toute tribu contenant l'[[ensemble vide]], le deuxième axiome des probabilités permet d'obtenir sa probabilité : <math>\scriptstyle \mathbb P(\emptyset)=0</math>. Un évènement de probabilité nulle est appelé [[ensemble négligeable]], ensemble <math>\scriptstyle \mathbb P</math>-négligeable, ou ensemble impossible<ref name="Sinai7">{{Harvsp|Sinaï|1992|p=7}}</ref>. Il existe des ensembles négligeables autres que l'ensemble vide. Par exemple la probabilité d'obtenir le résultat pile lors d'une infinité de lancers de pile ou face est nulle.

Il est possible de calculer la probabilité de la négation d'une proposition ; mathématiquement, c'est la probabilité du [[Complémentaire (théorie des ensembles)|complémentaire]] d'un ensemble. Il est également possible d'obtenir la probabilité de se trouver dans une configuration ou dans une autre, cela correspond à une [[Union (mathématiques)|union]] de deux ensembles. Quant à la probabilité de se retrouver dans deux situations simultanément, c'est la probabilité de l'[[Intersection (mathématiques)|intersection]] des deux ensembles<ref name="Bertoin7">{{Harvsp|Bertoin|2000|p=7}}</ref>. Elle est nulle si et seulement si les deux ensembles sont [[Ensembles disjoints|disjoints]].
:<math>\mathbb P(A^c)=1-\mathbb P(A),</math>
:<math>\mathbb{P}(A\cup B)  = \mathbb{P}(A)+\mathbb{P}(B)-\mathbb{P}(A\cap B), </math>
:<math>\mathbb P(A\cap B)=0 \Leftrightarrow A\cap B = \emptyset</math>.

;Exemple
Reprenons l'exemple du lancer de deux dés. 

La probabilité d'obtenir au moins une fois un 6 se calcule à partir de la probabilité de ne pas obtenir de 6 lors des deux lancers :
:<math>\mathbb P({\scriptstyle\text{ obtenir au moins un 6}})=1-\mathbb P({\scriptstyle\text{ne pas obtenir de 6}})=1-\left(\frac{5}{6}\right)^2=\frac{11}{36}</math>.
Cet évènement est le même qu'obtenir un 6 au premier lancer ou un 6 au deuxième lancer. Sa probabilité s'obtient également par le calcul de la probabilité de l'union :
:<math>\begin{align}\mathbb P({\scriptstyle\text{obtenir un 6 au 1}^\text{er}\text{ ou au 2}^\text{ème}\text{ lancer}})&=\mathbb P({\scriptstyle\text{obtenir 6 au 1}^\text{er}\text{ lancer}})+\mathbb P({\scriptstyle\text{obtenir 6 au 2}^\text{ème}\text{ lancer}}) - \mathbb P({\scriptstyle\text{obtenir 6 au 1}^\text{er}\text{ et au 2}^\text{ème}\text{ lancer}})\\
&=\frac{1}{6}+\frac{1}{6}-\left(\frac{1}{6}\right)^2 = \frac{11}{36}
\end{align}</math>

=== Indépendance ===
{{article détaillé|Indépendance (probabilités)}}
La notion d'indépendance est une hypothèse utilisée depuis longtemps en théorie des probabilités. Plusieurs lancers de dés successifs sont considérés indépendants. Dans ce cas l'hypothèse est raisonnable, cependant d'autres situations d'indépendance peuvent paraître indépendantes alors qu'elles ne le sont pas. C'est le cas par exemple du [[problème de Monty Hall]]. L'indépendance n'est pas toujours intuitive et demande alors d'être étudiée.

L'indépendance peut se définir sur les ensembles<ref name="Jacod15">{{Harvsp|Jacod|Protter|2003|p=15}}</ref>, deux évènements ''A'' et ''B'' sont dits indépendants si la probabilité que ''A'' apparaissent ne dépend pas de la connaissance de l'obtention de ''B''. Mathématiquement, les évènements sont indépendants si et seulement si la probabilité de leur intersection est égale au produit de leur probabilité<ref name="Sina44">{{Harvsp|Sinaï|1992|p=44}}</ref> :
:<math>A \text{ et }B\text{ sont indépendants }\Leftrightarrow \mathbb P(A\cap B)=\mathbb P(A)\mathbb P(B)</math>
L'indépendance se définit également pour les variables aléatoires en utilisant la formule précédente. Les variables aléatoires ''X'' et ''Y'' sont indépendantes si<ref name="Sina45"/> :
:<math>\mathbb P(X\in C_1,Y\in C_2)=\mathbb P(X\in C_1)\mathbb P(Y\in C_2)</math>, pour tout <math>C_1\in \mathcal E</math> et tout <math>C_2\in \mathcal E</math>,
en reprenant les notation de la section ''[[#Variable aléatoire|variable aléatoire]]'' et <math>\mathcal E=\mathcal B(\mathbb R)</math> pour les [[variable aléatoire réelle|variables aléatoires réelles]].

De même, des [[tribu (mathématiques)|tribus]] <math>\scriptstyle \mathcal A_1</math> et <math>\scriptstyle \mathcal A_2</math> sont dites indépendantes si<ref name="Sina45">{{Harvsp|Sinaï|1992|p=45}}</ref> :
:<math>\mathbb P(A_1\cap A_2)=\mathbb P(A_1)\mathbb P(A_2)</math>, pour tout <math>A_1\in \mathcal A_1</math> et tout <math>A_2\in \mathcal A_2</math>.

Lorsque l'on considère plusieurs évènements, variables aléatoires ou tribus, il existe plusieurs notions d'indépendance. Les évènements ''A'', ''B'' et ''C'' sont dits<ref name="Jacod15"/>
*indépendants deux à deux si : <math>\begin{cases}\mathbb P(A\cap B)&=\mathbb P(A)\mathbb P(B), \\ \mathbb P(A\cap C)&=\mathbb P(A)\mathbb P(C) \text{ et } \\ \mathbb P(B\cap C)&=\mathbb P(B)\mathbb P(C),\end{cases}</math>
*mutuellement indépendants si : ils sont indépendants deux à deux et <math>\mathbb P(A\cap B\cap C)=\mathbb P(A)\mathbb P(B)\mathbb P(C)</math>.
Ces définitions se généralisent pour plus de trois évènements, variables aléatoires ou tribus, possiblement un nombre infini<ref name="Jacod15"/>.

=== Probabilité conditionnelle et théorème de Bayes ===
{{article détaillé|Probabilité conditionnelle|Théorème de Bayes|Formule des probabilités totales}}
À partir des probabilités élémentaires, il est possible de définir la probabilité conditionnelle d'un évènement ''A'' sachant un autre évènement ''B''. La probabilité de l'évènement ''A'' est diminuée ou augmentée si l'évènement ''B'' s'est réalisé. Si <math>\scriptstyle \mathbb P(B)\neq 0</math> alors la probabilité de ''A'' sachant ''B'' est définie par<ref name="Jacod16">{{Harvsp|Jacod|Protter|2003|p=16}}</ref> :
:<math>\mathbb P(A|B)=\frac{\mathbb P(A\cap B)}{\mathbb P(B)}</math>.
Plus mathématiquement, <math>\scriptstyle \mathbb P(\cdot|B)</math> est une nouvelle [[mesure de probabilité]], elle permet de définir des [[Espérance conditionnelle|espérances conditionnelles]] ou des [[Loi de probabilité#Loi conditionnelle|lois conditionnelles]]. De manière plus générale, il est possible de définir la probabilité conditionnelle sachant une variable aléatoire, une probabilité conditionnelle sachant une [[Tribu (mathématiques)|tribu]], une densité conditionnelle, etc.

Cette formule simple permet de faire le lien entre <math>\scriptstyle \mathbb P(A|B)</math> et <math>\scriptstyle \mathbb P(B|A)</math> par le très utile [[théorème de Bayes]]<ref name="Sinai44"/> :
:<math>\mathbb P(A|B) = \frac{\mathbb P(B | A) \mathbb P(A)}{\mathbb P(B)}</math>.

[[Image:Probability tree diagram.svg|thumb|alt=arbre de probabilité|Exemple d'[[arbre de probabilité]].]]
De même que la remarque précédente, il est possible de donner d'autres versions du théorème de Bayes par un conditionnement utilisant des variables aléatoires, des tribus ou par l'intermédiaire de lois de probabilité.

Il est possible de décomposer la probabilité d'un évènement en probabilités conditionnelles sachant toutes les situations possibles. C'est le rôle de la [[formule des probabilités totales]]<ref name="Sinai44">{{Harvsp|Sinaï|1992|p=44}}</ref> : pour une [[Partition (mathématiques)|partition]] d'évènements <math>\scriptstyle B_1,B_2,\dots,B_n</math>, possiblement infinie, 
:<math>\mathbb P(A)=\mathbb P(A|B_1)\mathbb P(B_1)+\mathbb P(A|B_1)\mathbb P(B_1)+\dots+\mathbb P(A|B_n)\mathbb P(B_n)</math>.
Une marnière de représenter cette formule est un [[arbre de probabilité]], chaque branche représente un cas possible.

;Exemple
Reprenons l'exemple des deux dés. Considérons les deux évènements <math>\scriptstyle A_i</math> : « le résultat du premier lancer est i », ''B'' : « le résultat de la somme des deux lancers est 7 » et ''C'' : « le résultat du premier lancer est pair ». Il est facile de calculer les probabilités : <math>\scriptstyle \mathbb P(A_i)=1/6</math>, <math>\scriptstyle \mathbb P(B|A_i)=1/6</math> et <math>\scriptstyle \mathbb P(C)=1/2</math>. La formule des probabilités totales permet d'obtenir :
:<math>\scriptstyle \mathbb P(B)=\sum_{i=1}^6 \mathbb P(B|A_i)\mathbb P(A_i)=\sum_{i=1}^6 \frac{1}{6}.\frac{1}{6}=\frac{1}{6}</math> et <math>\scriptstyle \mathbb P(B|C)=\mathbb P(B|A_2)\mathbb P(A_2)+\mathbb P(B|A_4)\mathbb P(A_4)+\mathbb P(B|A_4)\mathbb P(A_4)=\frac{1}{12}</math>.
Le théorème de Bayes permet d'obtenir la probabilité d'avoir eu un résultat pair au premier lancer sachant que la somme des deux résultats est de 7 :
:<math>\scriptstyle\mathbb P(C|B)=\frac{\frac{1}{2}.\frac{1}{12}}{\frac{1}{6}}=\frac{1}{4}</math>.

=== Lois de probabilité ===
{{Article détaillé|Loi de probabilité}}
Comme précisé dans les sections ci-dessus, le choix de la mesure de probabilité pour l'espace probabilisé peut se faire en donnant directement en donnant les probabilités <math>\scriptstyle \mathbb P(X\in B)</math> d'une variable aléatoire ''X''. Ainsi la mesure de probabilité donnée par<ref name="Le Gall93"/> :
:<math>B\mapsto \mathbb P_X(B)=\mathbb P(X\in B)</math>
[[Image:3 répartitions.gif|thumb|alt=fonctions de répartition|Trois fonctions de répartition de différentes lois de probabilité, une discrète, une continue et une mixte.]]
est appelée la [[loi de probabilité]] de la variable ''X''. Elle décrit complétement le comportement de la variable ''X''. De manière plus générale, une loi de probabilité est une mesure décrivant le comportement aléatoire d'un phénomène dépendant du hasard, c'est-à-dire qu'elle n'est pas toujours définie à partir d'une variable aléatoire. Cependant pour une loi de probabilité donnée, il existe une variable aléatoire dont la loi est la loi de probabilité précédente. La représentation dune loi par une variable aléatoire n'est pas unique, c'est-à-dire que deux variables aléatoires différentes peuvent avoir la même loi. Comme mentionné dans les sections précédentes, il existe des [[loi de probabilité discrète|lois discrètes]], des [[Loi de probabilité absolument continue|lois absolument continues]], mais il existe également des [[Loi de probabilité#Autres cas|lois plus générales]]. Les lois discrètes et les lois absolument continues peuvent s'écrire respectivement sous la forme<ref name="Le Gall94"/> :
:<math>\mathbb P_{\textrm{disc.}}(B)=\sum_{x\in E}p_x \delta_x(B)</math> et <math>\mathbb P_{\textrm{abs. cont.}}(B)=\int_B f(x) \mathrm{d}x</math>

Certaines lois de probabilité sont fréquemment rencontrées en théorie des probabilités car on les retrouve dans de nombreux processus naturels. Les lois discrètes les plus fréquentes sont la [[loi uniforme discrète]], la [[loi de Bernoulli]], ainsi que les lois [[loi binomiale|binomiale]], [[loi de Poisson|de Poisson]] et [[loi géométrique|géométrique]]. Les lois [[loi uniforme continue|uniforme continue]], [[loi normale|normale]], [[loi exponentielle|exponentielle]] et [[loi Gamma|gamma]] sont parmi les plus importantes lois continues.

Plusieurs outils permettent de définir et étudier ces lois. La [[fonction de répartition]], la [[Fonction caractéristique d'une variable aléatoire|fonction caractéristique]], la [[Fonction génératrice des moments|fonction génératrice]], la [[Quantile|fonction quantile]], la [[densité de probabilité]] (pour les lois continues), la [[fonction de masse]] (pour les lois discrètes) en sont les exemples principaux.

=== Espérance et moments ===
{{article détaillé|Espérance mathématique|Moment (mathématiques)}}
L'espérance est une propriété des lois de probabilités mais elle s'écrit plus simplement en utilisant une variable aléatoire. Elle donne la moyenne de la variable aléatoire ''X''. L'espérance de la variable aléatoire ''X'' de loi <math>\scriptstyle\mathbb P_X</math> est donnée par<ref name="Le Gall94"/> :
:<math>\mathbb E[X]=\int_{\Omega}X(\omega)\mathbb P_X(\mathrm{d}\omega)</math>
Cette expression s'écrit de manière plus simple dans le cas des variables discrètes et des variables continues (en reprenant les notation de la section ''[[#Lois de probabilité|Lois de probabilité]]'') : <math>\scriptstyle \mathbb E[X]=\sum_{x\in E} x p(x)</math> pour le cas discret<ref name="Sinai10">{{Harvsp|Sinaï|1992|p=10}}</ref> et <math>\scriptstyle \mathbb E[X]=\int_{E}x f(x) \mathrm{d}x</math> pour le cas continu, si les séries et intégrales convergent.

Il est possible de calculer l'espérance d'une fonction de la variable aléatoire par la formule<ref name="Le Gall95">{{Harvsp|Le Gall|2006|p=95}}</ref> : pour toute fonction <math>\scriptstyle g:E\rightarrow [0,\infty]</math> mesurable
:<math>\mathbb E[g(X)]=\int_E g(x)\mathbb P_X(\mathrm{d}x)</math>.
Lorsque la fonction <math>\scriptstyle g</math> est suffisamment générale, alors <math>\scriptstyle \mathbb E[g(X)]</math> permet de récupérer la loi de ''X''. Pour la [[Fonction caractéristique (théorie des ensembles)|fonction indicatrice]] <math>\scriptstyle g(x)={\bold 1}_B(x)</math>, l'espérance redonne la probabilité : <math>\scriptstyle \mathbb E[g(X)]=\mathbb E[{\bold 1}_B(X))]=\mathbb P(X\in B)</math>. Pour les fonctions <math>\scriptstyle g(x)=x^n</math>, les valeurs <math>\scriptstyle \mathbb E[g(X)]=\mathbb E[X^n]</math> sont les [[Moment (mathématiques)|moments]] de la loi de ''X''.

Ces définitions sont valides pour tout espace de valeurs de la variable aléatoire. Dans le cas multidimensionnel, c'est-à-dire de vecteurs aléatoires réels, la notion de espérance se généralise en vecteur des moyennes et la variance en [[matrice de variance-covariance]] qui donne les variances des coordonnées sur la diagonale et les [[covariance]]s entre coordonnées dans le reste de la matrice<ref name="Bertoin66">{{Harvsp|Bertoin|2000|p=66}}</ref>.

L'espérance et les moments permettent d'obtenir des inégalités<ref name="Bertoin16">{{Harvsp|Bertoin|2000|p=16}}</ref> : sans préciser les conditions d'existence,
*''[[inégalité de Markov]]'' : <math>\mathbb P(|X|\geq t)\leq \frac{\mathbb E[X]}{t}</math>,
*''[[inégalité de Bienaymé-Tchebychev]]'' : <math>\mathbb P(|X-\mathbb E[X]|\geq t)\leq \frac{Var[X]}{t^2}</math>.
Ces inégalités sont très utiles pour estimer la [[Longue traîne|queue]] de la loi d'une variable aléatoire, c'est-à-dire le comportement de la variable aléatoire lorsqu'elle prend des valeurs éloignées de sa moyenne.

=== Convergences et résultats limites ===
{{Article détaillé|Convergence de variables aléatoires|Loi des grands nombres|Théorème central limite}}
Lorsque l'on considère un nombre infini de données aléatoires, elles sont modélisées par une suite (infinie) de variables aléatoires. Il peut être utile d'étudier le comportement limite de cette suite. Plusieurs notions de [[convergence de variables aléatoires|convergences de variables aléatoires]] ont été définies et des théorèmes limites renseignent sur les résultats asymptotiques.
[[Image:Theoreme de la limite centrale.png|thumb|alt=théorème central limite|Une loi discrète (en noir) s'approchera, au sens d'une convergence en loi, de la loi normale (en rouge) par le théorème central limite.]]
Une suite de variables aléatoires <math>\scriptstyle (X_n)_{n\in\N}</math><ref name="Bertoin34">{{Harvsp|Bertoin|2000|p=34}}</ref>{{,}}<ref name="Bertoin35">{{Harvsp|Bertoin|2000|p=35}}</ref> :
*'''converge en loi''' vers une variable aléatoire ''X'' si la suite de leur lois de probabilité <math>\scriptstyle (\mathbb P_{X_n},n\in\N)</math> converge étroitement vers une loi <math>\scriptstyle \mathbb P_X</math>. En particulier dans le cas réel, cette convergence est équivalente à la convergence des fonctions de répartition vers la fonction de répartition de ''X'' en tout point de continuité de cette dernière<ref name="Le Gall132">{{Harvsp|Le Gall|2006|p=132}}</ref>. Cette convergence est également équivalente à la convergence des fonctions caractéristiques, c'est le [[Convergence de variables aléatoires#Convergence en loi|théorème de continuité de Paul Lévy]] <ref name="Le Gall136">{{Harvsp|Le Gall|2006|p=136}}</ref>.
*'''converge en probabilité''' vers une variable aléatoire ''X'' si pour tout <math>\scriptstyle \epsilon >0</math>, <math>\scriptstyle \lim_{n\rightarrow\infty}\mathbb P\left(\left|X_n-X\right|\geq\varepsilon\right)=0</math>. Cette convergence implique la convergence en loi.
*'''converge presque sûrement''' vers une variable aléatoire ''X'' si <math>\scriptstyle \mathbb P(\{\omega/\lim_{n\rightarrow\infty} X_n(\omega)=X(\omega)\})=1</math>. Cette convergence implique les convergences en probabilité et en loi.
*'''converge dans <math>\scriptstyle L^p</math>''' vers une variable aléatoire ''X'' si <math>\scriptstyle \lim_{n\rightarrow\infty}\mathbb E(|X_n-X|)=0</math>. Cette convergence implique la convergence en probabilité.

Donnons quelques théorèmes limites importants :
*[[théorème de Borel-Cantelli]]<ref name="Bertoin33">{{Harvsp|Bertoin|2000|p=33}}</ref> : pour une suite <math>\scriptstyle (A_n,n\in \mathbb N)</math> d'évènements, si <math>\scriptstyle \sum \mathbb P(A_n)</math> converge alors <math>\scriptstyle \mathbb P(\lim \sup A_n)=0</math>. Réciproquement, si les évènements sont indépendants et si <math>\scriptstyle \sum \mathbb P(A_n)</math> diverge alors <math>\scriptstyle \mathbb P(\lim \sup A_n)=1</math>.
*[[loi du zéro un de Kolmogorov]]<ref name="Jacod72">{{Harvsp|Jacod|Protter|2003|p=72}}</ref> (également appelé ''loi du tout ou rien''<ref name="Le Gall127">{{Harvsp|Le Gall|2006|p=127}}</ref>) : pour une suite <math>\scriptstyle (X_n,n\in \mathbb N)</math> de variables aléatoires, notons la tribu asymptotique <math>\scriptstyle \mathcal B_\infty=\cap_{n}\mathcal B_n</math> où <math>\scriptstyle \mathcal B_n=\sigma(X_p,p\geq n)</math>, alors pour tout évènements <math>\scriptstyle B\in\mathcal B_\infty</math>, <math>\scriptstyle \mathbb P(B)=</math>0 ou 1. Intuitivement, un évènement qui ne dépend que d'un comportement limite est de probabilité 0 ou 1. 
*[[loi des grands nombres]] (faible)<ref name="Le Gall120">{{Harvsp|Le Gall|2006|p=120}}</ref> : pour une suite <math>\scriptstyle (X_n,n\in \mathbb N)</math> de variables aléatoires indépendantes, de même loi et de variance finie, alors <math>\scriptstyle (X_1+\dots+X_n)/n</math> converge dans <math>\scriptstyle L^2</math> vers la moyenne de la loi commune <math>\scriptstyle \mathbb E[X]</math>. Les hypothèses de ce théorème peuvent être diminuées pour obtenir cette même convergence dans <math>\scriptstyle L^2</math>. Il est également possible d'obtenir une convergence presque sûre, c'est la [[loi forte des grands nombres]]<ref name="Le Gall129">{{Harvsp|Le Gall|2006|p=129}}</ref>. Intuitivement, ces résultats annoncent que lors d'un grand nombre d'expériences, la moyenne calculées des résultats tend à se rapprocher de la moyenne théorique du phénomène aléatoire.
*[[théorème central limite]]<ref name="Le Gall138">{{Harvsp|Le Gall|2006|p=138}}</ref> : pour une suite <math>\scriptstyle (X_n,n\in \mathbb N)</math> de variables aléatoires indépendantes, de même loi et de variance finie, alors <math>\scriptstyle (X_1+\dots+X_n-n\mathbb E[X_1])/\sqrt{n}</math> converge en loi vers une variable aléatoire de [[loi normale]] <math>\scriptstyle \mathcal N(0,Var(X_1))</math>. Ce théorème possède plusieurs versions : dans le cas où les variables aléatoires sont de [[loi de Bernouilli]] c'est le [[théorème de De Moivre-Laplace]], ce théorème peut s'écrire par l'intermédiaire des fonctions de répartition ou des fonctions caractéristiques. Il existe une version multidimensionnelle de ce théorème central limite pour des [[vecteur aléatoire|vecteurs aléatoires]]<ref name="Bertoin69">{{Harvsp|Bertoin|2000|p=69}}</ref>.
Pour pouvoir utiliser ces théorèmes de convergence dans les applications, notamment informatiques, il est utile de connaître leur vitesse de convergence : c'est l'étude du [[principe de grandes déviations]]<ref name="Bertoin44">{{Harvsp|Bertoin|2000|p=44}}</ref>.

== Calcul stochastique ==
{{Article détaillé|calcul stochastique}}
Le [[calcul stochastique]] est l'étude des phénomènes qui évoluent au cours du temps de manière aléatoire<ref name="Yor15">{{Harvsp|Revuz|Yor|2004|p=15}}</ref>. Le temps peut être modélisé de manière discrète, c'est-à-dire par les valeurs entières : <math>\scriptstyle 0,1,2,\dots </math>, dans ce cas le phénomène est représenté par une suite (infinie) de variables aléatoires : <math>\scriptstyle (X_n,n\geq 0)</math>, c'est une [[marche aléatoire]]. Le temps peut également être modélisé de manière continue c'est-à-dire par des valeurs réelles <math>\scriptstyle t\in \mathbb R_+</math> ou <math>\scriptstyle t\in \mathbb R</math>, il s'agit alors de [[processus stochastique]] <math>\scriptstyle (X_t,t\geq 0)</math>.

=== Marche aléatoire et chaîne de Markov ===
[[image:Drunkard’s walk.svg|thumb|alt=diagramme d'une chaîne de Markov|Diagramme représentant les différents états du système par les points ''-2'', ''-1'', ''0'', ''1'' et ''2'' ; les changements possibles par des flèches et les probabilités associées par les valeurs associées aux flèches.]]
{{article détaillé|Marche aléatoire|Chaîne de Markov}}
[[Image:Walk2d 0.png|thumb|alt=trois marches aléatoires|Trois marches aléatoires (indépendantes) sur le réseau <math>\scriptstyle \mathbb{Z}^2</math> chacune contient 10 000 pas.]]

Parmi les modélisations de phénomènes aléatoires dépendant du temps, certaines l'ont été par un temps discret, c'est-à-dire à valeurs entière : <math>\scriptstyle n\in\mathbb N=\{0,1,2,\dots\}</math>. Un processus <math>\scriptstyle (X_n,n\in\mathbb N)</math> est appelé [[marche aléatoire]]<ref name="Le Gall165">{{Harvsp|Le Gall|2006|p=165}}</ref> partant d'un point <math>\scriptstyle x</math> lorsque la variable  <math>\scriptstyle X_n</math> s'écrit sous la forme d'une somme de ''pas'' aléatoires donné par des variables :
:<math>X_0=x</math> et <math>X_n=x+Y_1+Y_2+\dots+Y_n</math> pour <math>n\geq 1</math>.
L'espace de probabilité et la tribu sur lequel le processus est défini n'est pas trivial, la notion de [[Filtration (mathématiques)|filtration]] a donc été introduite. C'est une suite de tribu prévue pour que la marche aléatoire puisse être définie sur chaque tribu de la suite, le processus est dit ''adaptée''<ref name="Le Gall163">{{Harvsp|Le Gall|2006|p=163}}</ref>.

Un propriété particulière des marches aléatoires est régulièrement utilisée. Une marche aléatoire est appelée [[chaîne de Markov]] si elle possède la [[propriété de Markov]], c'est-à-dire que le ''n''-ième pas ne dépend pas du comportement du processus avant. Autrement dit, le comportement à venir ne dépend que du temps présent et non du temps passé. Plusieurs expressions mathématiques traduisent cette propriété, en voici une courante grâce aux probabilités conditionnelles<ref name="Le Gall191">{{Harvsp|Le Gall|2006|p=191}}</ref> :
:<math>\mathbb P(X_{n+1}=y|X_0,\dots,X_n)=\mathbb P(X_{n+1}=y|X_n)</math>.
La probabilité <math>\scriptstyle \mathbb P(X_{n+1}=y|X_n=x)</math> est appelée la ''probabilité de transition'' de l'état <math>\scriptstyle x</math> à l'état <math>\scriptstyle y</math>. Lorsque le nombre d'états possibles est fini. Toutes ces probabilités sont résumées dans une [[Matrice de transition|matrice de transition]]. Elle représente à elle seule la chaîne de Markov<ref name="Le Gall191"/>. La chaîne de Markov dont les états possibles sont les valeurs entières et telle que les probabilités d'aller vers les plus proches voisins sont identiques est appelée la ''chaîne de Markov simple sur <math>\scriptstyle \mathbb Z</math>''<ref name="Le Gall169">{{Harvsp|Le Gall|2006|p=169}}</ref>.

Les [[récurrence et transience d'une chaîne de Markov]] sont également étudiées. Si une marche aléatoire revient indéfiniment au point de départ elle est dite récurrente, sinon elle est transiente. Les [[temps d'arrêt]] représentent le temps en lequel la marche possède pour la première fois une certaine propriété<ref name="Le Gall167">{{Harvsp|Le Gall|2006|p=167}}</ref>.

Ces notions se généralisent de plusieurs manières<ref name="Le Gall193">{{Harvsp|Le Gall|2006|p=193}}</ref> : les pas peuvent être des vecteurs aléatoires multidimensionnels ; les états possibles peuvent être les points d'un [[Théorie des graphes|graphe]] plus général, ceci introduit, entre autres, la [[Graphe aléatoire|théorie des graphes aléatoires]] et la [[théorie de la percolation]] qui font partie de la [[théorie des systèmes dynamiques]] ; le ''n''-ième pas peut être la somme d'un nombre aléatoire de variables, c'est le cas des [[processus de branchement]].

L'étude du comportement de la marche aléatoire lorsque le temps devient grand amène à considérer des théorème limites sur les processus tels que le [[théorème de Donsker]] ou le [[théorème de Glivenko-Cantelli]] très utilisés en statistique. Apparaissent alors des processus aléatoires dont le temps n'est plus discret mais continu.

=== Processus stochastique et processus de Markov ===
[[image:Wiener process zoom.png|thumb|alt=mouvement brownien|Exemple de processus aléatoire : le mouvement brownien. Un zoom montre que le processus n'admet pas de parties lisses.]]
{{article détaillé|Processus stochastique|Processus de Markov}}
L'introduction des processus aléatoires à temps continu a été possible notamment grâce à l'[[#Axiomatique|axiomatique de Kolmogorov]]. Les processus stochastiques sont des familles de variables aléatoires indexées par un indice réel : <math>\scriptstyle (X_t;t\in \mathbb R_+)</math>. De même que dans le cas du temps discret, les notions de filtration et de processus adapté, permettent de définir mathématiquement le processus. Les théorèmes [[théorème d'extension de Kolmogorov|d'extension de Kolmogorov]] et [[Théorème d'extension de Carathéodory|d'extension de Carathéodory]] permettent de donner l'existence via les [[Loi de probabilité#Loi à valeurs dans un espace de Banach|lois finies dimensionnelles]], c'est-à-dire que le processus est défini par la donnée d'un nombre fini de ses accroissements<ref name="Le Gall220">{{Harvsp|Le Gall|2006|p=220}}</ref>  :
:la loi de <math>(X_{t_1}-X_{t_0},X_{t_2}-X_{t_1},\dots,X_{t_n}-X_{t_{n-1}})</math> peut être donnée par une [[matrice de variance-covariance]].

Des probabilités de transitions sont données par des fonctions du type : <math>\scriptstyle p_{s,t}(x,A)</math> qui donnent la probabilité que le processus soit dans un des états de l'ensemble ''A'' au temps <math>\scriptstyle t</math> sachant qu'au temps <math>\scriptstyle s</math> le processus était en <math>\scriptstyle x</math>, elle doit vérifiée l'[[équation de Chapman-Kolmogorov]]<ref group="a" name="chaumont"/>{{,}}<ref name="Yor80">{{Harvsp|Revuz|Yor|2004|p=80}}</ref> :
:<math>p_{s,t}(x,A)=\int_E p_{s,u}(x,\mathrm dy)p_{u,t}(y,A)</math>, pour tout <math>u\in ]s,t[</math>.

Un exemple important de processus stochastique est le mouvement brownien, il apparait comme limite (en loi) d'une suite de marches aléatoires via le [[théorème de Donsker]]<ref name="Le Gall219">{{Harvsp|Le Gall|2006|p=219}}</ref>, il est également un objet central puisque ses lois finies dimensionnelles sont des lois normales, c'est-à-dire que ses accroissements sont gaussiens. La loi du processus est appelée ''mesure de Wiener''<ref name="Le Gall226">{{Harvsp|Le Gall|2006|p=226}}</ref>. Le mouvement brownien a été beaucoup étudié et nombreux objets mathématiques lui sont liés : [[bruit blanc]], [[mouvement brownien fractionnaire]], [[processus de Lévy]], [[pont brownien]], [[arbre brownien]], [[processus stationnaire]], etc. Le [[processus de Poisson]] est un processus de Markov dont les accroissements sont de [[loi de Poisson]]<ref name="Yor58">{{Harvsp|Revuz|Yor|2004|p=58}}</ref>, ce processus de comptage est un processus de sauts<ref name="Yor115">{{Harvsp|Revuz|Yor|2004|p=115}}</ref>.

Différentes méthodes de définition existent : le [[processus de Feller]] est un processus de Markov dont les probabilités de transition possède une propriété dite de Feller<ref name="Yor90">{{Harvsp|Revuz|Yor|2004|p=90}}</ref>, le [[processus d'Ornstein-Uhlenbeck]] est défini à partir d'une [[équation différentielle stochastique]]<ref name="Yor38">{{Harvsp|Revuz|Yor|2004|p=38}}</ref> (voir la section ci-dessous), les [[processus ponctuels]] sont définis sur des espaces plus généraux, l'espace des excursions par exemple<ref name="Yor481">{{Harvsp|Revuz|Yor|2004|p=481}}</ref>. Une autre manière est l'utilisation de [[Générateur infinitésimal|générateurs infinitésimaux]], c'est une [[fonctionnelle]] sur les fonctions continues qui décrit comment le processus se déplace de points en points. Le générateur infinitésimal d'un processus de Markov ''X'' est l'opérateur ''A'' tel que<ref name="Yor281">{{Harvsp|Revuz|Yor|2004|p=281}}</ref> :
:<math>Af(x)=\lim_{t\rightarrow 0} \frac{1}{t}\left(\mathbb E[f(X_t)|X_0=x]-f(x)\right).</math>

Les processus stochastiques sont utilisés dans de nombreux domaines<ref name="schwartz" group="a"/> : historiquement le mouvement brownien a été utilisé pour modéliser des trajectoires de particules ou pour calculer le [[nombre d'Avogadro]], il est également utilisé pour modéliser des phénomènes tels que les marchés financiers dont les premiers travaux sont dus à [[Louis Bachelier]] ou les travaux en physique par les travaux de [[Sydney Chapman (1888-1970)|Sydney Chapman]]<ref group="a" name="chaumont"/>.

=== Martingales ===
{{article détaillé|Martingale (calcul stochastique)}}
Parmi les processus stochastiques à temps discret et à temps continu, certains possèdent une propriété liée à la [[Filtration (mathématiques)|filtration]] <math>\scriptstyle (\mathcal F_n,n\in\N)</math> sur laquelle ils sont définis. Un processus <math>\scriptstyle (X_n,n\in\N)</math> est appelé une ''[[Martingale (calcul stochastique)|martingale]]'' si<ref name="Le Gall164">{{Harvsp|Le Gall|2006|p=164}}</ref> :
:pour tout <math>n\in\N, \mathbb E[X_{n+1}|\mathcal F_n]=X_n</math>.
Cette définition se généralise pour un processus stochastique en temps continu. Le processus est une ''sur-martingale'' si <math>\scriptstyle \mathbb E[X_{n+1}|\mathcal F_n]\leq X_n</math> et une ''sous-martingale'' si <math>\scriptstyle \mathbb E[X_{n+1}|\mathcal F_n]\geq X_n</math>. Intuitivement la valeur moyenne du processus à un temps futur ''n+1'' connaissant le passé est égal à la valeur présente du processus. C'est une représentation du bénéfice dans un jeu équitable, c'est de cette correspondance que provient le nom [[martingale]]. Une sous-martingale correspond à un jeu favorable et une sur-martingale à un jeu défavorable.

Les martingales ont donc une moyenne constante en tout temps ainsi qu'en certains temps aléatoires : les [[temps d'arrêt]], c'est ce qu'annonce le [[théorème d'arrêt de Doob]]<ref name="Le Gall169">{{Harvsp|Le Gall|2006|p=169}}</ref>.

Les bonnes propriétés des martingales permettent d'obtenir des inégalités<ref name="Yor54">{{Harvsp|Revuz|Yor|2004|p=54}}</ref> ainsi que des résultats de convergence<ref name="Le Gall171">{{Harvsp|Le Gall|2006|p=171}}</ref>.

=== Formule d'Itô et équations différentielles stochastiques ===
{{Article détaillé|Lemme d'Itô|Équation différentielle stochastique}}
Une [[intégrale stochastique]] est soit l'intégration d'un processus aléatoire par rapport à une mesure (non aléatoire)<ref group="a" name="chaumont"/>, soit l'intégration d'une fonction (localement bornée) par rapport à un processus stochastique (semi-martingale continue)<ref name="Yor141">{{Harvsp|Revuz|Yor|2004|p=141}}</ref>. Dans le cas où la fonction est [[Fonction étagée|étagée]], l'intégrale se définit simplement par une formule du type : 
:<math>\int f(t)\mathrm dX_t = \sum_{i=0}^n f_i (X_{t_{i+1}}-X_{t_{i}})</math>.
De manière plus générale, l'intégrale se définit à partir d'un objet appelé [[crochet de martingale]]<ref name="Yor138">{{Harvsp|Revuz|Yor|2004|p=138}}</ref>. L'intégrale <math>\scriptstyle Y_t=\int f(t)\mathrm dX_t</math> s'écrit alors de manière plus simple avec la notation : <math>\scriptstyle \mathrm dY_t=f(t)\mathrm dX_t</math>.

La [[Lemme d'Itô|formule d'Itô]] dans sa formule générale la plus courante s'écrit sous la forme<ref group="a" name="chaumont"/> : pour une fonction <math>\scriptstyle (t,x)\mapsto \varphi(t,x)</math> [[Fonction de classe C1|de classe C1]] en <math>\scriptstyle t</math> et [[Fonction de classe C2|de classe C2]] en <math>\scriptstyle x</math> :
:<math>\mathrm d\varphi(t,X_t)=B(t,X_t)\frac{\partial}{\partial x}\varphi(t,X_t) \mathrm d \beta_t + \left(\frac{\partial}{\partial t}\varphi(t,X_t) + A(t,X_t)\frac{\partial}{\partial x}\varphi(t,X_t) + \frac{1}{2}B^2(t,X_t)\frac{\partial^2}{\partial x^2}\varphi(t,X_t) \right)\mathrm dt</math>
où <math>\scriptstyle \beta</math> est un mouvement brownien et ''X'' est un processus stochastique solution de l'équation différentielle stochastique :
:<math>\mathrm d X_t = A(t,X_t)\mathrm d t + B(t,X_t)\mathrm d \beta_t</math>.



Pour faire une analogie avec la physique, <math>\mu(X(t))</math> est la vitesse moyenne au point X(t) et <math>\sigma</math> est lié au coefficient de diffusion (voir à ce propos l'exemple donné dans [[lemme d'Itô]]). Le [[lemme d'Itô]] et l'[[intégrale d'Itô]] permettent alors de passer de ces équations stochastiques à des équations aux dérivées partielles classiques ou à des équations intégrales. Par exemple en utilisant le lemme d'Itô on obtient pour la probabilité de se trouver à l'instant t au point x:

:<math> \frac{\partial p(x,t)}{\partial t}=\frac{\sigma(x)^2}{2} \frac{\partial^2 p (x,t)}{\partial x^2} +\mu(x)\frac{\partial p(x,t)}{\partial x}</math>

Ce lemme est particulièrement important car il permet de faire le lien entre l'étude d'équations stochastiques et les [[équations aux dérivées partielles]] qui relèvent de l'[[Analyse (mathématiques)|analyse]]. Ce lemme permet entre autres d'obtenir les [[équation de Fokker-Planck]] en physique et de traiter le mouvement brownien par des [[équations aux dérivées partielles]] classiques ou de modéliser les cours de la bourse en [[Mathématiques financières]].

== Notes et références ==
;Notes et traductions
{{Références|group="b"}}
;Ouvrages
{{Références|colonnes=3}}
;Articles et autres sources
{{Références|group="a"}}

== Voir aussi ==
=== Bibliographie ===
*{{ouvrage|langue=fr|prénom1=Jean|nom1=Bertoin|lien auteur1=Jean Bertoin|titre=Probabilités : cours de licence de mathématiques appliquées|année=2000|pages totales=79|lire en ligne=http://www.proba.jussieu.fr/cours/bertoin.pdf}}
*{{ouvrage|langue=fr|prénom1=Joseph |nom1=Bertrand|lien auteur1=Joseph Bertrand|titre=Calcul Des Probabilités (copie d'un ouvrage de 1923)|numéro d'édition=3 |éditeur=American Mathematical Soc.|année=1972|pages totales=332|lire en ligne=http://books.google.fr/books?id=NfpxYC4FFmkC&printsec=frontcover&hl=fr#v=onepage&q&f=false}} {{plume}}
*{{ouvrage|langue=fr|prénom1=Nicolas|nom1=Bouleau|lien auteur1=Nicolas Bouleau|titre=Probabilités de l'ingénieur|éditeur=Hermann|lien éditeur=Hermann (éditions)|année=1986|pages totales=387}}
*{{ouvrage|langue=fr|prénom1=Antoine-Augustin |nom1=Cournot|lien auteur1=Antoine-Augustin Cournot|titre=Exposition de la théorie des chances et des probabilités|numéro d'édition=|éditeur=Hachette|lien éditeur=Hachette Livre|lieu=Paris|année=1843|pages totales=448|lire en ligne=http://books.google.fr/books?id=_fk3AAAAMAAJ&printsec=frontcover&hl=fr#v=onepage&q&f=false}} {{plume}}
*{{ouvrage|langue=en|prénom1=Jean |nom1=Jacod |prénom2=Philip E.|nom2= Protter|lien auteur1=Jean Jacod|lien auteur2=Philippe Protter|titre=Probability Essentials|éditeur=Springer|lien éditeur=Springer Science+Business Media|année=2003|pages totales=254|lire en ligne=http://books.google.fr/books?id=OK_d-w18EVgC&printsec=frontcover&hl=fr#v=onepage&q&f=false}}
*{{ouvrage|langue=fr|prénom1=Pierre-Simon de |nom1=Laplace|lien auteur1=Pierre-Simon de Laplace|titre=Théorie analytique des probabilités |numéro d'édition=2|éditeur=Courcier|lieu=Paris|année=1814|pages totales=506|lire en ligne=http://books.google.fr/books?id=6MRLAAAAMAAJ&printsec=frontcover&hl=fr#v=onepage&q&f=false}} {{plume}}
*{{ouvrage|langue=fr|prénom1=Jean-François|nom1=Le Gall|lien auteur1=Jean-François Le Gall|titre=Intégration, Probabilités et Processus aléatoires|sous-titre=cours de l'[[École normale supérieure (Ulm)|ENS]]|année=2006|pages totales=248|lire en ligne=http://www.dma.ens.fr/~legall/IPPA2.pdf}} {{plume}}
*{{ouvrage|langue=fr|prénom1=Adolphe|nom1=Quetelet|lien auteur1=Adolphe Quetelet|titre=Théorie des probabilités|éditeur=A. Jamar|lien éditeur=Alexandre Jamar|lieu=Bruxelles|année=1853|pages totales=104|lire en ligne=http://books.google.fr/books?id=HPNaAAAAQAAJ&printsec=frontcover&hl=fr#v=onepage&q&f=false}} {{plume}}
*{{ouvrage|langue=fr|prénom1=Daniel|nom1=Revuz|lien auteur1=Daniel Revuz|titre=Probabilités|éditeur=Hermann|lien éditeur=Hermann (éditions)|année=1997|pages totales=301}}
*{{ouvrage|langue=en|prénom1=Daniel|nom1=Revuz|lien auteur1=Daniel Revuz|prénom2=Marc|nom2=Yor|lien auteur2=Marc Yor|titre=Continuous martingales and Brownian motion|numéro d'édition=3|éditeur=Springer|lien éditeur=Springer Science+Business Media|année=2004|volume=293|pages totales=606|lire en ligne=http://books.google.fr/books?id=1ml95FLM5koC&printsec=frontcover&hl=fr#v=onepage&q&f=false}} {{plume}}
*{{ouvrage|langue=en|prénom1=Iakov |nom1=Sinaï|lien auteur1=Iakov Sinaï|titre=Probability theory |sous-titre=An introductory course|éditeur=Springer|lien éditeur=Springer Science+Business Media|année=1992|pages totales=138|passage=|isbn=3-540-53348-6|lire en ligne=http://books.google.fr/books?id=A4T-fE7FiLUC&printsec=frontcover&hl=fr#v=onepage&q&f=false}} {{plume}}

=== Articles connexes ===

* [[Probabilité]]
* [[Axiomes des probabilités]]
* [[Loi de probabilité]]
* [[Interconnexions entre la théorie des probabilités et les statistiques]]

{{Palette|Probabilités et statistiques}}
{{Portail|probabilités et statistiques}}

{{DEFAULTSORT:Theorie des probabilites}}
[[Catégorie:Probabilités]]
[[Catégorie:Théorie|Probabilités]]

{{Lien AdQ|ka}}
{{Lien BA|zh}}

[[af:Waarskynlikheidsleer]]
[[ar:نظرية الاحتمال]]
[[az:Ehtimal nəzəriyyəsi]]
[[be:Тэорыя імавернасцей]]
[[be-x-old:Тэорыя імавернасьцяў]]
[[bg:Теория на вероятностите]]
[[ca:Teoria de la probabilitat]]
[[cs:Teorie pravděpodobnosti]]
[[da:Sandsynlighedsregning]]
[[de:Wahrscheinlichkeitstheorie]]
[[el:Θεωρία πιθανοτήτων]]
[[en:Probability theory]]
[[eo:Probablokalkulo]]
[[es:Teoría de la probabilidad]]
[[et:Tõenäosusteooria]]
[[eu:Probabilitate teoria]]
[[fa:نظریه احتمالات]]
[[fi:Todennäköisyysteoria]]
[[gl:Teoría da probabilidade]]
[[he:תורת ההסתברות]]
[[hi:प्रायिकता सिद्धांत]]
[[hr:Teorija vjerojatnosti]]
[[hu:Valószínűség-számítás]]
[[hy:Հավանականությունների տեսություն]]
[[id:Peluang (matematika)]]
[[is:Líkindafræði]]
[[it:Teoria della probabilità]]
[[ja:確率論]]
[[jv:Téori probabilitas]]
[[ka:ალბათობის თეორია]]
[[kaa:İtimallıqlar teoriyası]]
[[kk:Ықтималдық теориясы]]
[[ko:확률론]]
[[lt:Tikimybių teorija]]
[[lv:Varbūtību teorija]]
[[mk:Теорија на веројатноста]]
[[mn:Магадлалын онол]]
[[ms:Teori kebarangkalian]]
[[nl:Kansrekening]]
[[nn:Sannsynsrekning]]
[[no:Sannsynlighetsteori]]
[[os:Уæвæны теори]]
[[pl:Teoria prawdopodobieństwa]]
[[pt:Teoria das probabilidades]]
[[ro:Teoria probabilităților]]
[[ru:Теория вероятностей]]
[[si:සම්භාවිතා වාදය]]
[[simple:Probability theory]]
[[sk:Teória pravdepodobnosti]]
[[sl:Verjetnostni račun]]
[[sq:Teoria e probabilitetit]]
[[sr:Теорија вероватноће]]
[[su:Téori probabilitas]]
[[sv:Sannolikhetsteori]]
[[ta:நிகழ்தகவுக் கோட்பாடு]]
[[tg:Назарияи эҳтимолият]]
[[th:ทฤษฎีความน่าจะเป็น]]
[[tk:Ähtimallyk teoriýasy]]
[[tr:Olasılık kuramı]]
[[uk:Теорія ймовірностей]]
[[ur:نظریۂ احتمال]]
[[vi:Lý thuyết xác suất]]
[[yi:טעאריע פון משמעותדיקייט]]
[[zh:概率论]]