[[Fichier:Face detection example openCV.jpg|thumb|alt=Un exemple de [[détection de visage]] par la méthode de Viola et Jones, les 7 visages présents sur l'image sont correctement détectés, sans fausses alarmes.|Un exemple de [[détection de visage]] par la méthode de Viola et Jones.]]

La '''Méthode de Viola et Jones'''  est une méthode de [[détection d'objet]] dans une [[image numérique]], proposée par les chercheurs Paul Viola et Michael Jones en 2001. Elle fait partie des toutes premières méthodes capables de détecter efficacement et en temps réel des objets dans une image. Inventée à l'origine pour [[détection de visage|détecter des visages]], elle peut également être utilisée pour détecter d'autres types d'objets comme des [[voiture]]s ou des [[avion]]s. La méthode de Viola et Jones est l'une des méthodes les plus connues et les plus utilisées, en particulier pour la détection de visages et la [[détection de personne]]s.

En tant que procédé d'[[apprentissage supervisé]], la méthode de Viola et Jones nécessite de quelques centaines à plusieurs milliers d'exemples de l'objet que l'on souhaite détecter, pour entraîner un [[Classification automatique|classifieur]]. Une fois son apprentissage réalisé, ce classifieur est utilisé pour détecter la présence éventuelle de l'objet dans une image en parcourant celle-ci de manière exhaustive, à toutes les positions et dans toutes les tailles possibles.

Considérée comme étant l'une des plus importantes méthodes de détection d'objet, la méthode de Viola et Jones est notamment connue pour avoir introduit plusieurs notions reprises ensuite par de nombreux chercheurs en [[vision par ordinateur]], à l'exemple de la notion d'[[image intégrale]] ou de la méthode de [[classification automatique|classification]] construite comme une cascade de classifieurs [[boosting|boostés]].

Cette méthode bénéficie d'une implémentation sous [[licence BSD]] dans [[OpenCV]], une [[bibliothèque logicielle|librairie]] très utilisée en [[vision par ordinateur]].

== Historique ==

Paul Viola et Michael Jones, alors au ''{{lang|en|Cambridge Research Laboratory}}'' de la société américaine [[Compaq]]<ref>{{en}} {{Lien web | url = http://research.microsoft.com/en-us/um/people/viola/ | titre = Page personnelle de Paul Viola | consulté le = 8 octobre 2010 }}.</ref>, publient la méthode qui porte leur nom pour la première fois le {{date|13|juillet|2001}} dans le [[journal scientifique]] [[International Journal of Computer Vision|{{lang|en|International Journal of Computer Vision}}]] (IJCV)<ref name=ijcv01>{{article|langue=en|prénom1=Paul|nom1=Viola |prénom2=Michael|nom2=Jones|lien auteur1=|titre=Robust Real-time Object Detection |périodique=IJCV|lien périodique=IJCV |volume=|numéro=|jour=|mois=|année=2001|pages=|issn=|url texte=http://research.microsoft.com/~viola/Pubs/Detect/violaJones_IJCV.pdf|consulté le= 8 octobre 2010}}.</ref>. Les deux auteurs publient ensuite deux autres articles sur la méthode : une version moins détaillée, présentée à la [[Conference on Computer Vision and Pattern Recognition|{{lang|en|Conference on Computer Vision and Pattern Recognition}}]] (CVPR) en décembre 2001<ref name=cvpr01>
{{article|langue=en|prénom1=Paul|nom1=Viola|lien auteur1=|prénom2=Michael|nom2=Jones| titre=Rapid Object Detection using a Boosted Cascade of Simple Features |périodique=IEEE CVPR|lien périodique=CVPR |volume=|numéro=|jour=|mois=|année=2001|pages=|issn=|url texte=http://research.microsoft.com/en-us/um/people/viola/Pubs/Detect/violaJones_CVPR2001.pdf |consulté le=8 octobre 2010}}.</ref> et une version révisée en 2004, toujours dans IJCV<ref name=ijcv04>{{article|langue=en|prénom1=Paul|nom1=Viola|lien auteur1=|prénom2=Michael|nom2=Jones |titre=Robust Real-time Face Detection |périodique=IJCV|lien périodique=IJCV|volume=|numéro=|jour=|mois=|année=2004|pages=137-154|issn=|url texte=|consulté le=}}.</ref>.

Les [[caractéristique (vision par ordinateur)|caractéristique]]s extraites par cette méthode sont inspirées des travaux de Papageorgiou, Oren et Poggio, datant de 1998<ref name=Papageorgiou>{{article|langue=en|prénom1=C.|nom1=Papageorgiou|prénom2=M.|nom2=Oren|prénom3=T.|nom3=Poggio|lien auteur1=|titre=A General Framework for Object Detection |périodique=International Conference on Computer Vision |lien périodique=International Conference on Computer Vision |volume=|numéro=|jour=|mois=|année=1998 |pages=|issn=|url texte=|consulté le=}}.</ref>{{,}}<ref name=ijcv01/>, qui utilisent des caractéristiques construites à partir d'[[ondelette de Haar|ondelettes de Haar]]. La méthode s'inspire également de précédents travaux de Paul Viola et Kinh Tieu dans un autre domaine, celui de la [[recherche d'image par le contenu]], en reprenant l'idée de sélection de caractéristiques par [[AdaBoost]]<ref>{{article|langue=en|prénom1=K.|nom1=Tieu |prénom2=P.|nom2=Viola |lien auteur1=|titre=Boosting image retrieval |périodique=IEEE CVPR|lien périodique=Conference on Computer Vision and Pattern Recognition|volume=|numéro=|jour=|mois=|année=2000 |pages=|issn=|url texte=|consulté le=}}.</ref>{{,}}<ref name=ijcv01/>. Parmi les nombreuses méthodes de[[ détection de visage]]s publiées à l'époque<ref>{{article|langue=en|prénom1=M.-H.|nom1=Yang|prénom2=D. J.|nom2=Kriegman|prénom3=N.|nom3=Ahuja|lien auteur1=|titre=Detecting faces in images: A survey |périodique=IEEE Transactions on Pattern Analysis and Machine Intelligence|lien périodique=IEEE Transactions on Pattern Analysis and Machine Intelligence|volume=24|numéro=1|jour=|mois=|année=2002|pages=34–58|issn=|url texte=|consulté le=}}.</ref>, Viola et Jones considèrent en particulier celle de Rowley-[[Takeo Kanade|Kanade]]<ref name=Rowley/> : en raison de ses excellents résultats et de sa rapidité, ils la prennent comme référence pour les comparaisons<ref name=ijcv01/>. À performances équivalentes, Viola et Jones notent que la détection par leur méthode est 15 fois plus rapide que le détecteur de Rowley-Kanade<ref name=ijcv01/>.

La méthode, considérée comme l'une des plus efficaces en détection de visage, devient rapidement un standard dans ce domaine<ref name=Szeliski>[[#Sze10|Szeliski (2010)]], {{p.|656}}.</ref>. Les travaux de Viola et Jones sont parmi les plus utilisés et les plus cités par les chercheurs, et de nombreuses améliorations sont ainsi proposées<ref name=Szeliski/>{{,}}<ref name=Brubaker>{{article|langue=en|prénom1=S. Charles |nom1=Brubaker|prénom2=Matthew D.|nom2=Mullin|prénom3=James M.|nom3=Rehg|lien auteur1=|titre=Towards Optimal Training of Cascaded Detectors |périodique=ECCV|lien périodique=ECCV|volume=|numéro=|jour=|mois=|année=2006 |pages=|issn=|url texte=|consulté le=}}.</ref>. Leurs travaux sont également étendus à d'autres types d'objets que les visages et la méthode devient ainsi un standard en [[détection d'objet]]. La méthode est par ailleurs reconnue comme étant celle ayant eu le plus d'impact dans le domaine de la détection de visage dans les [[années 2000]]<ref>{{article|langue=en|prénom1=Cha|nom1=Zhang |prénom2=Zhengyou|nom2=Zhang|lien auteur1=|titre=A Survey of Recent Advances in Face Detection |périodique=Microsoft Research |lien périodique=Microsoft Research |volume=|numéro=|jour=|mois=|année=2010 |pages=|issn=|url texte=http://research.microsoft.com/apps/pubs/default.aspx?id=132077|consulté le=}}.</ref>.

== Éléments de la méthode ==
La méthode de Viola et Jones est une approche basée apparence<ref name=Szeliski653>[[#Sze10|Szeliski (2010)]] {{p.|653}}.</ref>, qui consiste à parcourir l'ensemble de l'image en calculant un certain nombre de [[caractéristique (vision par ordinateur)|caractéristique]]s dans des zones rectangulaires qui se chevauchent. Elle a la particularité d'utiliser des caractéristiques très simples mais très nombreuses. Une première innovation de la méthode est l'introduction des [[image intégrale|images intégrale]]s, qui permettent le calcul rapide de ces caractéristiques. Une deuxième innovation importante est la sélection de ces caractéristiques par [[boosting]], en interprétant les caractéristiques comme des classifieurs. Enfin, la méthode propose une architecture pour combiner les classifieurs boostés en un processus en cascade, ce qui apporte un net gain en temps de détection.

La méthode, en tant que méthode d'[[apprentissage supervisé]], est divisée en deux étapes : une étape d'apprentissage du classifieur basé sur un grand nombre d'exemples positifs (c'est-à-dire les objets d'intérêt, par exemple des visages) et d'exemples négatifs, et une phase de détection par application de ce classifieur à des images inconnues.

=== Caractéristiques ===
==== Description ====
[[Fichier:VJ featureTypes.svg|thumb|right|Un exemple des types de [[caractéristique (vision par ordinateur)|caractéristique]]s utilisées par Viola et Jones.]]
Plutôt que de travailler directement sur les valeurs de pixels, et pour être à la fois plus efficace et plus rapide, Viola et Jones proposent d'utiliser des [[caractéristique (vision par ordinateur)|caractéristique]]s, c'est à dire une représentation synthétique et informative, calculée à partir des valeurs des pixels. Viola et Jones définissent des caractéristiques très simples, les [[caractéristiques pseudo-Haar]]<ref name=ijcv01/>, qui sont calculées par la différence des sommes de pixels de deux ou plusieurs zones rectangulaires adjacentes. La figure ci-contre donne des exemples des caractéristiques proposées par Viola et Jones à 2, 3 ou 4 rectangles, dans lesquelles la somme de pixels sombres est soustraite de la somme des pixels blancs. Leur nom vient de leur similitude avec les [[ondelette de Haar|ondelettes de Haar]], précédemment proposées comme caractéristiques par Papageorgiou<ref name=Papageorgiou/> et dont se sont inspirés Viola et Jones<ref name=ijcv01/>.

Pour calculer rapidement et efficacement ces caractéristiques sur une image, les auteurs proposent également une nouvelle méthode, qu'ils appellent « [[image intégrale]] ». C'est une représentation sous la forme d'une image, de même taille que l'image d'origine, qui en chacun de ses points contient la somme des pixels situés au-dessus de lui et à sa gauche. Plus formellement, l'image intégrale <math>ii</math> au point <math>(x,y)</math> est définie à partir de l'image <math>i</math> par<ref name=ijcv01/> :
:<math>ii(x,y) = \sum_{x' \le x,\ y' \le y} i(x',y')</math>
Grâce à cette représentation, une caractéristique formée de deux zones rectangulaires peut être calculée en seulement 6 accès à l'image intégrale, et donc en un temps constant quelle que soit la taille de la caractéristique<ref name=ijcv01/>.

==== Calcul ====
Les caractéristiques sont calculées à toutes les positions et à toutes les échelles dans une fenêtre de détection de petite taille, typiquement de {{nobr|24 × 24}} [[pixel]]s<ref name=ijcv01/> ou de {{nobr|20 × 15}} pixels<ref name=VJPeople>{{article|langue=en|prénom1=P.|nom1=Viola|prénom2=M.|nom2=Jones|prénom3=D.|nom3=Snow|lien auteur1=|titre=Detecting Pedestrians using Patterns of Motion and Appearance|périodique=IJCV|lien périodique=IJCV|volume=63|numéro=2|jour=|mois=|année=2005|pages=153-161|issn=|url texte=|consulté le=}}.</ref>. Un très grand nombre de caractéristiques par fenêtre est ainsi généré, Viola et Jones donnant l'exemple d'une fenêtre de taille {{nobr|24 × 24}} qui génère environ {{formatnum:160000}} caractéristiques.

En phase de détection, l'ensemble de l'image est parcouru en déplaçant la fenêtre de détection d'un certain pas dans le sens horizontal et vertical (ce pas valant 1 pixel dans l'algorithme original<ref name=ijcv01/>). Les changements d'échelles se font en modifiant successivement la taille de la fenêtre de détection<ref group="note">Les méthodes alternatives recourent principalement à la construction d'une [[Pyramide (traitement d'image)|pyramide d'images]].</ref>. Viola et Jones utilisent un facteur multiplicatif de {{formatnum:1.25}}, jusqu'à ce que la fenêtre couvre la totalité de l'image.

Finalement, et afin d'être plus robuste aux variations d'illumination, les fenêtres sont normalisées par la [[Variance (statistiques et probabilités)|variance]]<ref name=ijcv01/>.

La conséquence de ces choix techniques, notamment le recours aux [[image intégrale|images intégrales]], est un gain notable en efficacité, les caractéristiques étant évaluées très rapidement quelle que soit la taille de la fenêtre.

=== Sélection de caractéristiques par boosting ===
Le deuxième élément clé de la méthode de Viola et Jones est l'utilisation d'une méthode de [[boosting]] afin de sélectionner les meilleures caractéristiques. Le boosting est un principe qui consiste à construire un classifieur « fort » à partir d'une combinaison pondérée de classifieurs « faibles », c'est-à-dire donnant en moyenne une réponse meilleure qu'un tirage aléatoire. Viola et Jones adaptent ce principe en assimilant une caractéristique à un classifieur faible, en construisant un classifieur faible qui n'utilise qu'une seule caractéristique. L'apprentissage du classifieur faible consiste alors à trouver la valeur seuil de la caractéristique qui permet de mieux séparer les exemples positifs des exemples négatifs. Le classifieur se réduit alors à un couple (caractéristique, seuil).

L'algorithme de boosting utilisé est en pratique une version modifiée d'[[AdaBoost]], qui est utilisée à la fois pour la sélection et pour l'apprentissage d'un classifieur « fort ». Les classifieurs faibles utilisés sont souvent des [[arbre de décision|arbres de décision]]. Un cas remarquable, fréquemment rencontré, est celui de l'arbre de profondeur 1, qui réduit l'opération de classification à un simple seuillage.

L'algorithme est de type [[itératif]], à nombre d'itérations déterminé. À chaque itération, l'algorithme sélectionne une caractéristique, qui sera ajoutée à la liste des caractéristiques sélectionnées aux itérations précédentes, et le tout va contribuer à la construction du classifieur fort final. Cette sélection se fait en entraînant un classifieur faible pour toutes les caractéristiques et en élisant celle de ces dernières qui génère l'erreur la plus faible sur tout l'ensemble d'apprentissage. L'algorithme tient également à jour une [[distribution de probabilité]] sur l'ensemble d'apprentissage, réévaluée à chaque itération en fonction des résultats de classification. En particulier, plus de poids est attribué aux exemples difficiles à classer, c'est à dire ceux dont l'erreur est élevée. Le classifieur « fort » final construit par AdaBoost est composé de la somme pondérée des classifieurs sélectionnés.

Plus formellement, on considère un ensemble de <math>n</math> images <math>(x_1, \ldots, x_n)</math> et leurs étiquettes associées <math>(y_1, \ldots, y_n)</math>, qui sont telles que <math>y_i=0</math> si l'image <math>x_i</math> est un exemple négatif et <math>y_i=1</math> si <math>x_i</math> est un exemple de l'objet à détecter. L'algorithme de boosting est constitué d'un nombre <math>T</math> d'itérations, et pour chaque itération <math>t</math> et chaque [[caractéristique (vision par ordinateur)|caractéristique]] <math>j</math>, on construit un classifieur faible <math>h_j</math>. Idéalement, le but est d'obtenir un classifieur <math>h</math> qui prédise exactement les étiquettes pour chaque échantillon, c'est-à-dire <math>y_i = h(x_i)</math>  <math>\forall i \in \{1\ldots n\}</math>. En pratique, le classifieur n'est pas parfait et l'erreur engendrée par ce classifieur est donnée par :
:<math>\epsilon_j=\sum_{i=1}^n w_i \left| h_j(x_i)-y_i \right|</math>,

les <math>w_i</math> étant les poids associés à chaque exemple et mis à jour à chaque itération en fonction de l'erreur obtenue à l'itération précédente. On sélectionne alors à l'itération <math>t</math> le classifieur <math>h_t</math> présentant l'erreur la plus faible : <math>\epsilon_t=\min_j(\epsilon_j)</math>.

Le classifieur fort final <math>h(x)</math> est construit par seuillage de la somme pondérée des classifieurs faibles sélectionnés :
:<math>h(x)=\begin{cases} 1 & \displaystyle \text{si }  \sum_{t=1}^T \alpha_t h_t(x) \ge \frac{1}{2}\sum_{t=1}^T \alpha_t  \\ 0 & \text{sinon} \end{cases}</math>
Les <math>\alpha_t</math> sont des coefficients calculés à partir de l'erreur <math>\epsilon_t</math>.

=== Cascade de classifieurs ===
[[Fichier:VJ cascade (fr).svg|thumb|upright=2|Illustration  de l'architecture de la cascade : les fenêtres sont traitées séquentiellement par les classifieurs, et rejetées immédiatement si la réponse est négative (''F'').]]
La méthode de Viola et Jones est basée sur une approche par [[recherche exhaustive]] sur l'ensemble de l'image, qui teste la présence de l'objet dans une fenêtre à toutes les positions et à plusieurs échelles. Cette approche est cependant extrêmement coûteuse en calcul. L'une des idées-clés de la méthode pour réduire ce coût réside dans l'organisation de l'algorithme de détection en une cascade de classifieurs. Appliqués séquentiellement, ces classifieurs prennent une décision d'acceptation — la fenêtre contient l'objet et l'exemple est alors passé au classifieur suivant —, ou de rejet — la fenêtre ne contient pas l'objet et dans ce cas l'exemple est définitivement écarté —. L'idée est que l'immense majorité des fenêtres testées étant négatives (c.-à-d. ne contiennent pas l'objet), il est avantageux de pouvoir les rejeter avec le moins possible de calculs. Ici, les classifieurs les plus simples, donc les plus rapides, sont situés au début de la cascade, et rejettent très rapidement la grande majorité des exemples négatifs<ref name=ijcv01/>. Cette structure en cascade peut également s'interpréter comme un [[arbre de décision]] dégénéré, puisque chaque noeud ne comporte qu'une seule branche<ref name=ijcv01/>.

En pratique, la cascade est constituée d'une succession d'étages<ref group="note">On utilise parfois le terme de « couche » pour désigner un étage.</ref>, chacune étant formée d'un classifieur fort appris par [[AdaBoost]]. L'apprentissage du classifieur de l'étage <math>n</math> est réalisé avec les exemples qui ont passé l'étage <math>n-1</math> ; ce classifieur doit donc faire face à un problème plus difficile : plus on monte dans les étages, plus les classifieurs sont complexes<ref name=ijcv01/>.

Le choix du nombre <math>K</math> d'étages est fixé par l'utilisateur ; dans leur méthode originale, Viola et Jones utilisent <math>K=32</math> étages. L'utilisateur doit également spécifier le [[Vrai positif|taux de détection]] minimal <math>d_i</math> et le taux de [[fausse alarme]] maximal <math>f_i</math> à atteindre pour l'étage <math>i</math>. Le taux de détection de la cascade est alors donné par :
:<math>D=\prod_{i=1}^K d_i</math>
et le taux de fausse alarme par :
:<math>F=\prod_{i=1}^K f_i</math>
En pratique, les taux <math>d_i</math> et <math>f_i</math> sont les mêmes pour tous les étages. Indirectement, ces taux déterminent également le nombre de caractéristiques utilisées par les classifieurs forts à chaque étage : les  itérations d'Adaboost continuent jusqu'à ce que le taux de fausse alarme cible soit atteint. Des caractéristiques/classifieurs faibles sont ajoutés jusqu'à ce que les taux cibles soient atteints, avant de passer ensuite à l'étage suivant.

Pour atteindre des taux de détection et de fausse alarme corrects en fin de cascade, il est nécessaire que les classifieurs forts de chaque étage aient un bon taux de détection ; ils peuvent par contre avoir un taux de fausses alarmes élevé. Si l'on prend l'exemple d'une cascade de 32 étages, pour obtenir une performance finale <math>D=0.9</math> et <math>F=10^{-6}</math>, chaque classifieur fort doit atteindre <math>d_i=0,997</math>, mais peut se permettre <math>f_i=0,65</math> (i.e. <math>0,65^{32}=10^{-6}</math> et <math>0,997^{32}=0,9</math>). Chaque étage ajouté diminue donc non seulement le nombre de fausses alarmes, mais aussi le taux de détection.

Plusieurs chercheurs font remarquer que cette idée de filtrer rapidement les exemples négatifs les plus simples n'est pas nouvelle<ref>{{article|langue=en|prénom1=H.|nom1=Schneiderman|lien auteur1=|titre=Feature-centric Evaluation for Efficient Cascaded Object Detection|périodique=IEEE CVPR|lien périodique=CVPR|volume=|numéro=|jour=|mois=|année=2004 |pages=|issn=|url texte=|consulté le=}}.</ref>{{,}}<ref name=Bourdev/>. Elle existe dans d'autres méthodes sous forme d'[[heuristique]]s, comme la détection de la couleur chair<ref>{{article|langue=en|prénom1=H.|nom1=Schneiderman|prénom2=T. |nom2=Kanade |lien auteur1=|titre=Object detection using the statistics of parts |périodique=IJCV |lien périodique=IJCV |volume= |numéro= |jour= |mois= |année=2002 |pages=|issn=|url texte=|consulté le=}}.</ref>{{,}}<ref name=Feraud>{{article|langue=en |prénom1=R.|nom1=Féraud|prénom2=O.|nom2=Bernier|prénom3=J.|nom3=Viallet |prénom4=M.|nom4=Collobert|lien auteur1=|titre=A fast and accurate face detector based on neural networks |périodique=IEEE Transactions on Pattern Analysis and Machine Intelligence|lien périodique=IEEE Transactions on Pattern Analysis and Machine Intelligence|volume=23|numéro=1|jour=|mois=janvier |année=2001 |pages=|issn=|url texte=|consulté le=}}.</ref> ou une étape de pré-classification<ref name=Feraud/>.

== Étapes clés ==
=== Apprentissage ===
L'apprentissage est réalisé sur un très large ensemble d'images positives (c'est-à-dire contenant l'objet) et négatives (ne contenant pas l'objet). Plusieurs milliers d'exemples sont en général nécessaires. Cet apprentissage comprend :
* Le calcul des [[caractéristiques pseudo-Haar]] sur les exemples positifs et négatifs ;
* L'entraînement de la cascade : à chaque étage de la cascade, un classifieur fort est entraîné par AdaBoost. Il est construit par ajouts successifs de classifieurs faibles entraînés sur une seule caractéristique, jusqu'à l'obtention de performances conformes aux taux de détection et de fausse alarme souhaités pour l'étage.

=== Détection ===
La détection s'applique sur une image de test, dans laquelle on souhaite déceler la présence et la localisation d'un objet. En voici les étapes :
* parcours de l'ensemble de l'image à toutes les positions et échelles, avec une fenêtre de taille {{nobr|24 × 24}} pixels, et  application de la cascade à chaque sous-fenêtre, en commençant par le premier étage :
** calcul des caractéristiques pseudo-Haar utilisées par le classifieur de l'étage courant,
** puis calcul de la réponse du classifieur,
** passage ensuite à l'étage supérieur si la réponse est positive, à la sous-fenêtre suivante sinon,
** et enfin l'exemple est déclaré positif si tous les étages répondent positivement ;
* fusion des détections multiples : l'objet peut en effet générer plusieurs détections, à différentes positions et échelles ; cette dernière étape fusionne les détections qui se chevauchent pour ne retourner qu'un seul résultat.

== Performances ==
[[Fichier:Viola jones performances.svg|center|right|alt=Courbe [[Receiver Operating Characteristic|ROC]] du détecteur de Viola et Jones sur le corpus MIT+CMU. La courbe varie de 78 à 94% de bonnes détections, pour un taux de fausse alarme correspondant de 10 à 422 (nombre de fausses alarmes total sur toutes les images du corpus).|Courbe [[Receiver Operating Characteristic|ROC]] du détecteur de Viola et Jones sur le corpus MIT+CMU.]]
Viola et Jones ont testé leur algorithme sur la base de visages [[Massachusetts Institute of Technology|MIT]]+[[Université Carnegie Mellon|CMU]], constituée de 130 images contenant 507 visages de face<ref name=Rowley>{{article|langue=en |prénom1=H.|nom1=Rowley|prénom2=S. |nom2=Baluja |prénom3=T. |nom3=Kanade |lien auteur1=|titre=Neural network-based face detection|périodique=IEEE Transactions on Pattern Analysis and Machine Intelligence|lien périodique=IEEE Transactions on Pattern Analysis and Machine Intelligence |volume=20|numéro=|jour=|mois=|année=1998|pages=22–38|issn=|url texte=http://www.cmucam.org/raw-attachment/wiki/viola-jones/rowley-ieee.pdf|consulté le=}}.</ref>. Ils présentent leur résultat sous la forme d'une courbe ''[[Receiver Operating Characteristic]]'' (ROC), qui donne le taux de détection correct en fonction du nombre de [[fausse alarme|fausses alarmes]] total sur toutes les images du corpus. À titre d'exemple, pour 50 fausses alarmes, ils obtiennent un taux de détection de {{unité|88.8|%}}.

Viola et Jones comparent également les performances de leur méthode aux détecteurs de visages existants, notamment celui de Rowley-Kanade<ref name=Rowley/>. Ils constatent que les résultats sont globalement proches des autres détecteurs, quoique légèrement inférieures aux résultats de Rowley-Kanade pour un faible nombre de fausses alarmes, et légèrement supérieurs pour un nombre de fausses alarmes élevées<ref name=ijcv01/>.

La rapidité de détection, pour sa part, dépend directement du nombre de caractéristiques évaluées, donc du contenu de l'image. Sur un [[Compatible PC|PC]] [[Pentium III]] cadencé à 700 [[Mhz]], les auteurs rapportent un temps de traitement moyen de {{formatnum:0.067}} secondes pour une image de taille {{nobr|384 × 288}} pixels, correspondant à débit moyen de 15 images par seconde, assez proche des exigences du traitement vidéo en temps réel (soit 25 images par seconde). Au final, sur la base de visages MIT+CMU, leur détecteur est 15 fois plus rapide que celui de Rowley-Kanade et 600 fois plus rapide que celui de Schneiderman-Kanade, pour des taux de détection et de fausse alarme comparables<ref name=ijcv01/>.

== Limitations et extensions ==

[[Fichier:Haar features Lienhart.svg|thumb|alt=Illustration des caractéristiques pseudo-Haar proposées par Lienhart : 4 caractéristiques de bords, 8 de lignes, et 2 de centre-pourtour.|L'extension des {{Lien|lang=en|fr=caractéristiques pseudo-Haar|trad=Haar-like features}} proposée par Lienhart<ref name=Lienhart/>.]]

De très nombreuses améliorations ont été proposées par la suite, visant à améliorer le paramétrage de la méthode, ou à en combler un certain nombre de limitations.

L'une des premières améliorations est apportée par Lienhart et Maydt en 2002<ref name=Lienhart>{{article|langue=en|prénom1=Rainer |nom1=Lienhart |prénom2=Jochen |nom2=Maydt|lien auteur1=|titre=An Extended Set of Haar-like Features for Rapid Object Detection |périodique=IEEE ICIP|lien périodique=ICIP |volume=|numéro=|jour=|mois=|année=2002|pages=|issn=|url texte=|consulté le=}}.</ref>. Ils proposent d'étendre l'ensemble de {{Lien|lang=en|fr=caractéristiques pseudo-Haar|trad=Haar-like features}} utilisé de 4 à 14 caractéristiques. De même, ils introduisent des caractéristiques « de biais » (tournées de 45°), ainsi qu'une méthode pour les calculer basée sur une extension des [[image intégrale|images intégrales]]<ref name=Lienhart/>.

D'autres types de caractéristiques ont également été utilisées en remplacement des caractéristiques de Haar : les [[histogrammes de gradients orientés]]<ref>{{article|langue=en|prénom1=Qiang |nom1=Zhu |prénom2=Shai |nom2=Avidan |prénom3=Mei C. |nom3=Yeh |prénom4=Kwang T. |nom4=Cheng |lien auteur1=|titre=Fast Human Detection Using a Cascade of Histograms of Oriented Gradients |périodique=IEEE CVPR|lien périodique=CVPR |volume=|numéro=|jour=|mois=|année=2006 |pages=1491-1498|issn=|url texte=|consulté le=}}.</ref>, les [[motif binaire local|motifs binaires locaux]] ou la covariance de région<ref>{{article|langue=en|prénom1=O. |nom1=Tuzel |prénom2=F. |nom2=Porikli |prénom3=P.|nom3=Meer |lien auteur1=|titre=Human Detection via Classification on Riemannian Manifolds |périodique=IEEE CVPR|lien périodique=CVPR |volume=|numéro=|jour=|mois=|année=2007 |pages=1–8,|issn=|url texte=|consulté le=}}.</ref>. Les chercheurs ont également proposé d'utiliser des variantes de l'algorithme de [[boosting]], notamment  [[RealBoost]], qui produit un indice de confiance à [[nombre réel|valeurs réelles]], en plus de la classification<ref>{{article|langue=en |prénom1=Jerome|nom1=Friedman |prénom2=Trevor|nom2=Hastie |prénom3=Robert|nom3=Tibshirani |lien auteur1=|titre=Additive logistic regression: a statistical view of boosting|périodique=Annals of Statistics|lien périodique=|volume=28|numéro=|jour=|mois=|année=2000|pages=|issn=|url texte=|consulté le=}}.</ref>. Plusieurs travaux ont ainsi montré la supériorité de RealBoost sur [[AdaBoost]] dans le cadre de l'algorithme de Viola et Jones<ref name=Brubaker/>{{,}}<ref>{{article|langue=en |prénom1=Bo |nom1=Wu |prénom2=Haizhou|nom2=Ai |prénom3=Chang|nom3=Huang |prénom4=Shihong |nom4=Lao |lien auteur1=|titre=Fast rotation invariant multi-view face detection based on real adaboost|périodique=IEEE International Conference on Automatic Face and Gesture Recognition |lien périodique=|volume=|numéro=|jour=|mois=|année=2004|pages=79–84|issn=|url texte=|consulté le=}}.</ref>
<!--<ref>{{article|langue=en|prénom1=P. |nom1=Viola |prénom2=M.|nom2=Jones |lien auteur1=|titre=Fast and robust classification using asymmetric adaboost and a detector cascade |périodique=NIPS |lien périodique=NIPS |volume=|numéro=|jour=|mois=|année=2002 |pages=|issn=|url texte=|consulté le=}}.</ref>.-->

Viola et Jones étendent en 2003 leur système à la [[détection de piéton]]s dans des vidéos, en incluant une information de mouvement en plus de l'information d'apparence<ref name=VJPeople/>.

Une des limitations de la méthode est son manque de robustesse à la [[rotation]], et sa difficulté à apprendre plusieurs vues d'un même objet. En particulier, il est difficile d'obtenir un classifieur capable de détecter à la fois des visages de face et de profil. Viola et Jones ont proposé une amélioration qui permet de corriger ce défaut<ref>{{article|langue=en|prénom1=M.|nom1=Jones |prénom2=P. |nom2=Viola |lien auteur1= |titre=Fast Multi-view Face Detection |périodique=IEEE CVPR |lien périodique=CVPR |volume=|numéro=|jour=|mois=|année=2003 |pages=|issn=|url texte=|consulté le=}}.</ref>, qui consiste à apprendre une cascade dédiée à chaque orientation ou vue, et à utiliser lors de la détection un [[arbre de décision]] pour sélectionner la bonne cascade à appliquer. Plusieurs autres améliorations ont été proposées par la suite pour apporter une solution à ce problème<ref>{{Chapitre | éditeur=Dunedin |collection= |série= |titre=Toward an Efficient Implementation of a Rotation Invariant Detector using Haar-Like Features |titre ouvrage=Proceedings of the 2009 IEEE/RSJ international conference on Intelligent robots and systems|auteurs ouvrage=|titre vo=|ref=|volume=|titre volume=|auteur=A. L. C. Barczak|prénom=|nom=|auteurs=|trad=|langue=en|lieu=Nouvelle-Zélande|année=2005|mois=|jour=|publi=|pages=|format=|isbn=|issn=|présentation en ligne=|lire en ligne=http://pixel.otago.ac.nz/ipapers/07.pdf|partie=|numéro=|chap=|passage=31-36|id=|commentaire=}}.</ref>{{,}}<ref name=Kolsch/>.

Une autre limitation importante de la méthode de Viola et Jones concerne le temps d'apprentissage de la cascade, compris généralement entre plusieurs jours et plusieurs semaines de calcul<ref name=ijcv01/>{{,}}<ref name=Szeliski658>[[#Sze10|Szeliski (2010)]], {{p.|658}}.</ref>, ce qui limite sévèrement les possibilités de tests et de choix des paramètres<ref name=Zhang>{{article|langue=en|prénom1=C. |nom1= Zhang|prénom2=P. |nom2= Viola|lien auteur1=|titre=Multiple instance pruning for learning efficient Cascade detectors |périodique=Neural Information Processing Systems |lien périodique=|volume=|numéro=|jour=|mois=|année=2007 |pages=|issn=|url texte=|consulté le=}}.</ref>.

Un des problèmes majeurs de la méthode proposée par Viola et Jones est qu'il n'existe pas de méthode optimale pour choisir les différents paramètres régissant l'algorithme : le nombre d'étages, leur ordre ou les taux de détection et de fausses alarmes pour chaque étage doivent être choisis par [[Apprentissage#Apprentissage par essais et erreurs|essais et erreurs]]<ref name=Brubaker/>{{,}}<ref name=Bourdev>{{article|langue=en|prénom1=L. |nom1= Bourdev|prénom2=J. |nom2= Brandt|lien auteur1=|titre=Robust Object Detection via Soft Cascade |périodique=CVPR |lien périodique=CVPR |volume=|numéro=|jour=|mois=|année=2005 |pages=236-243|issn=|url texte=|consulté le=}}.</ref>. Plusieurs méthodes sont proposées pour déterminer certains de ces seuils de manière automatique<ref name=Brubaker/>{{,}}<ref name=Bourdev/>{{,}}<ref>{{article|langue=en|prénom1=J. |nom1= Sun|prénom2=J. |nom2= Rehg|prénom3=A. |nom3= Bobick|lien auteur1=|titre=Automatic cascade training with perturbation bias |périodique=IEEE CVPR|lien périodique=CVPR |volume=|numéro=|jour=|mois=|année=2004 |pages=|issn=|url texte=|consulté le=}}.</ref>.

Un reproche également fait à la méthode concerne la perte d'information subie au passage d'un étage à l'autre de la cascade, perte due à l'effet couperet des décisions d'acceptation ou de rejet prises à chaque étage. Certains chercheurs proposent la solution de garder l'information contenue dans la somme pondérée des classifieurs faibles, par exemple le « {{lang|en|boosting chain}} » de Xiao<ref>{{article|langue=en|prénom1=R. |nom1= Xiao|prénom2=L. |nom2=Zhu |prénom3=H.-J. |nom3= Zhang|lien auteur1=|titre=Boosting Chain Learning for Object Detection |périodique=ICCV|lien périodique=ICCV|volume=|numéro=|jour=|mois=|année=2003 |pages=709-715 |issn=|url texte=|consulté le=}}.</ref>. Une modification plus radicale de structure est proposée par Bourdev et sa notion de cascade souple, qui consiste essentiellement à supprimer le concept d'étages, en formant un seul classifieur fort, donc une seule somme, et en permettant de prendre une décision à chaque évaluation de classifieur faible et de s'affranchir de la contrainte des taux de détection et de fausses alarmes cibles<ref name=Bourdev/>.

== Applications ==
[[Fichier:Face detection.jpg|thumb|alt=Illustration d'une [[détection de visage]] avec la méthode de Viola et Jones, par la librairie [[OpenCV]]. 3 visages sur 4 sont détectés, le 4ème est manqué, étant de profil.|[[Détection de visage]] avec la méthode de Viola et Jones, par la librairie [[OpenCV]]. 3 visages sur 4 sont détectés.]]

La méthode de Viola et Jones a essentiellement été appliquée à la [[détection de visage]] et à la [[détection de personne]], principalement en raison des nombreuses applications pratiques qu'offrent ces deux domaines, notamment en [[vidéosurveillance]], en indexation d'images et de vidéo ou pour les [[interface homme-machine|interfaces homme-machine]] multimodales<ref>{{article|langue=en|prénom1=Reinlien|nom1=Hsu|prénom2=Anil K.|nom2=Jain|lien auteur1=|titre=Face detection in color images |périodique=IEEE Transactions on Pattern Analysis and Machine Intelligence |lien périodique=IEEE Transactions on Pattern Analysis and Machine Intelligence |volume=24|numéro=5|jour=|mois=mai|année=2002 |pages=696-706|issn=|url texte=|consulté le=}}.</ref>. Un exemple d'application grand public de la méthode est donné par les [[Appareil photographique numérique|appareils photographiques numériques]], où elle sert à effectuer la [[mise au point]] automatique sur les visages. Combinée avec le standard [[JPEG 2000]], la méthode peut également servir à [[compression d'image|compresser]] les visages avec un [[Taux de compression de données|taux de compression]] plus faible que le reste de l'image, afin de préserver les détails des visages<ref>{{Chapitre|éditeur=|collection=|série=|titre=JPEG 2000 and Region of Interest Coding|titre ouvrage=DICTA2002: Digital Image Computing Techniques and Applications|auteurs ouvrage=|titre vo=|ref=|volume=|titre volume=|auteur=|prénom=|nom=|auteurs=Andrew P. Bradley et Fred W. M. Stentiford|trad=|langue=en|lieu=Melbourne |année=2002|mois=|jour=|publi=|pages=|format=|isbn=|issn=|présentation en ligne=|lire en ligne=http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.19.3350&rep=rep1&type=pdf|partie=|numéro=|chap=|passage=21-22|id=|commentaire=}}.</ref>. Les [[constructeurs automobiles]] s'intéressent également à la méthode pour concevoir des systèmes de sécurité capables de détecter automatiquement les autres usagers de la route, en particulier les piétons<ref>{{Chapitre|éditeur=|collection=|série=|titre=Real-time visual detection of vehicles and pedestrians with new efficient adaBoost features|titre ouvrage=Workshop on Planning, Perception and Navigation for Intelligent Vehicles |auteurs ouvrage=|titre vo=|ref=|volume=|titre volume=|auteur=|prénom=|nom=|auteurs=Fabien Moutarde, Bogdan Stanciulescu et Amaury Breheret|trad=|langue=en|lieu=Nice|année=2008 |mois=|jour=|publi=|pages=|format=|isbn=|issn=|présentation en ligne=|lire en ligne=http://hal.archives-ouvertes.fr/docs/00/32/08/88/PDF/MINESparisTech_vehiclesAndPedestriansDetectionIROS2008_FINAL.pdf |partie=|numéro=|chap=|passage=|id=|commentaire=}}.</ref>. Des recherches ont également montré que l'efficacité de la méthode ne se limite pas au [[Lumière visible|domaine visible]], mais qu'elle s'étend également au domaine [[infrarouge]]<ref>{{article|langue=en |prénom1=Li |nom1= Zhang|prénom2=Bo |nom2= Wu|prénom3=R. |nom3= Nevatia|lien auteur1=|titre=Pedestrian Detection in Infrared Images based on Local Shape Features |périodique=CVPR |lien périodique=CVPR |volume=|numéro=|jour=|mois=|année=2007 |pages=1-8|issn=|url texte=|consulté le=}}.</ref>.

La méthode de Viola et Jones a également été utilisée pour détecter d'autres types d'objets, par exemple des [[main]]s, pour la commande gestuelle d'une [[interface homme-machine]]<ref name=Kolsch>{{article|langue=en|prénom1=M. |nom1=Kölsch |prénom2=M. |nom2=Turk |lien auteur1=|titre=Analysis of Rotational Robustness of Hand Detection with a Viola-Jones Detector |périodique=ICPR |lien périodique=ICPR |volume=3|numéro=|jour=|mois=|année=2004 |pages=|issn=|url texte=http://www.google.fr/url?sa=t&source=web&cd=1&ved=0CBgQFjAA&url=http%3A%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fdownload%3Fdoi%3D10.1.1.129.1816%26rep%3Drep1%26type%3Dpdf&rct=j&q=%22Analysis%20of%20Rotational%20Robustness%20of%20Hand%20Detection%20with%20a%20Viola-Jones%20Detector%22&ei=c6ywTMqNA4uRjAeGk7VF&usg=AFQjCNEefk8g9kjwgOS5ewsaKD0Hjds7Tg&sig2=-uHYoFZRh-8RQtLoSqYRAw |consulté le=}}.</ref>, des [[voiture]]s dans des [[image satellite|images satellites]] pour la création de [[système d'information géographique|systèmes d'information géographique]] débarrassés de toute présence visuelle d'automobiles<ref>{{Chapitre|éditeur=|collection=|série=|titre=Recognizing cars in aerial imagery to improve orthophotos|titre ouvrage=International symposium on Advances in geographic information systems, [[Association for Computing Machinery|ACM]]|auteurs ouvrage=|titre vo=|ref=|volume=|titre volume=|auteur=|prénom=|nom=|auteurs=F. Leberl, H. Bischof, H. Grabner et S. Kluckner|trad=|langue=en|lieu=|année=2007|mois=|jour=|publi=|pages=|format=|isbn=|issn=|présentation en ligne=|lire en ligne=http://www.asprs.org/publications/proceedings/portland08/0048.pdf|partie=|numéro=|chap=|passage=1–9|id=|commentaire=}}.</ref>, ou pour l'évaluation et le suivi du trafic routier<ref>{{article|langue=en |prénom1=L. |nom1=Eikvil |prénom2=L. |nom2=Aurdal |prénom3=H. |nom3=Koren |lien auteur1=|titre=Classification-based vehicle detection in high-resolution satellite images |périodique=ISPRS Journal of Photogrammetry and Remote Sensing |lien périodique=|volume=64|numéro=1 |jour=|mois=janvier |année=2009 |pages=65–72|issn=|url texte=http://publications.nr.no/RTS_NRcopy.pdf |consulté le=}}.</ref>.

La méthode a également été évaluée pour la détection d'[[avion]]s dans des images de basse résolution à partir d'une caméra embarquée dans un véhicule aérien, pour l'évitement de collisions<ref>{{article|langue=en|prénom1=Stavros |nom1= Petridis|prénom2=Christopher |nom2= Geyer |prénom3=Sanjiv |nom3= Singh |lien auteur1=|titre=Learning to detect aircraft at low resolutions |périodique=ICVS |lien périodique=|volume= 5008/2008  |numéro=|jour=|mois=|année=2008 |pages=474-483 |issn=|url texte=|consulté le=}}.</ref>. Des applications militaires existent aussi pour la détection de cibles (chars, avions) dans des images aériennes ou satellitaires<ref>{{ouvrage|langue=|prénom1=Xavier |nom1=Perrotton |lien auteur1=|titre=Détection automatique d’objets dans les images numériques |sous-titre=application aux images aériennes |numéro d'édition=|éditeur=Télécom ParisTech|lien éditeur=Télécom ParisTech |lieu= (thèse)|jour=|mois=|année=2009|volume=|tome=|pages totales=|passage=|isbn=|lire en ligne= |consulté le=}}.</ref>.

== Implémentations ==

Il existe de nombreuses implémentations du détecteur de Viola et Jones, la plus utilisée étant celle en [[C++]] présente dans la libraire de [[vision par ordinateur]] [[OpenCV]], publiée sous [[licence BSD]]. Des implémentations ont été développées pour des environnements ou plates-formes spécifiques, notamment pour une exécution dans des [[navigateurs Web]] en utilisant le langage de script [[ActionScript]] du logiciel multimédia [[Adobe Flash|Flash]]<ref>{{Chapitre|éditeur= IEEE Computer Society |collection=|série=|titre=Real-Time Viola-Jones Face Detection in a Web Browser|titre ouvrage= Proceedings of the 2009 Canadian Conference on Computer and Robot Vision |auteurs ouvrage=|titre vo=|ref=|volume=|titre volume=|auteur=|prénom=|nom=|auteurs=Theo Ephraim, Tristan Himmelman et Kaleem Siddiqi|trad=|langue=en |lieu= |année=2009 |mois=|jour=|publi=|pages= |format=|isbn= 978-0-7695-3651-4 |issn=|présentation en ligne=|lire en ligne=|partie=|numéro=|chap=|passage=321-328|id=|commentaire=}}.</ref>. Des implémentations matérielles ont également été développées sur [[Application Specific Integrated Circuit|ASIC]]<ref>{{Chapitre|éditeur=|collection=|série=|titre=A Parallel Architecture for Hardware Face Detection |titre ouvrage=IEEE Computer Society Annual Symposium on VLSI: Emerging VLSI Technologies and Architectures (ISVLSI'06) |auteurs ouvrage=|titre vo=|ref=|volume=|titre volume=|auteur=|prénom=|nom=|auteurs=T. Theocharides, N. Vijaykrishnan et M. J. Irwin|trad=|langue=en |lieu= Karlsruhe |année=2006 |mois=|jour=|publi=|pages= |format=|isbn=0-7695-2533-4 |issn=|présentation en ligne=|lire en ligne=|partie=|numéro=|chap=|passage=452-453|id=|commentaire=}}.</ref>, [[Circuit logique programmable|FPGA]]<ref>{{Chapitre|éditeur=|collection=|série=|titre=Parallelized architecture of multiple classifiers for face detection |titre ouvrage= Proceedings of the 2009 20th IEEE International Conference on Application-specific Systems, Architectures and Processors |auteurs ouvrage=|titre vo=|ref=|volume=|titre volume=|auteur=|prénom=|nom=|auteurs=Junguk Cho, Bridget Benson, Shahnam Mirzaei	et Ryan Kastner |trad=|langue=en|lieu=|année=2009 |mois=|jour=|publi=|passage=|format=|isbn=|issn=|présentation en ligne=|lire en ligne=http://cseweb.ucsd.edu/~b1benson/publications/asap09.pdf |partie=|numéro=|chap=|passage=75-82|id=|commentaire=}}.</ref> et sur [[processeur graphique|GPU]]<ref name=Hefenbrock>{{Chapitre|éditeur=|collection=|série=|titre=Accelerating Viola-Jones Face Detection to FPGA-Level using GPUs |titre ouvrage= 18th IEEE Annual International Symposium on Field-Programmable Custom Computing Machines |auteurs ouvrage=|titre vo=|ref=|volume=|titre volume=|auteur=|prénom=|nom=|auteurs=Daniel Hefenbrock, Jason Oberg, Nhat Tan Nguyen Thanh, Ryan Kastner et Scott B. Baden |trad=|langue=en |lieu= Charlotte (USA) |année=2010 |mois=|jour=|publi=|pages=|format=|isbn=978-0-7695-4056-6 |issn=|présentation en ligne=|lire en ligne=http://cseweb.ucsd.edu/groups/hpcl/scg/papers/2010/fccm_10.pdf |partie=|numéro=|chap=|passage=11-18 |id=|commentaire=}}.</ref>. L'utilisation de l'architecture parallèle de ces derniers permet un net gain de temps de détection par rapport à l'implémentation OpenCV traditionnelle<ref name=Hefenbrock/>.

Enfin, les implémentations les plus courantes sont celles rencontrées dans les [[Appareil photographique numérique|appareils photographique numérique]] pour la mise au point automatique par la détection de visage<ref name=Ren>{{Chapitre|éditeur=|collection=|série=|titre=Real-time optimization of Viola -Jones face detection for mobile platforms |titre ouvrage=Circuits and Systems Workshop: System-on-Chip - Design, Applications, Integration, and Software |auteurs ouvrage=|titre vo=|ref=|volume=|titre volume=|auteur=|prénom=|nom=|auteurs=Jianfeng Ren, N. Kehtarnavaz et L. Estevez |trad=|langue=en|lieu=Dallas |année=2008 |mois=|jour=|publi=|pages=|format=|isbn=|issn=|présentation en ligne=|lire en ligne=|partie=|numéro=|chap=|passage=1-8 |id=|commentaire=}}.</ref>. Elles nécessitent des optimisations particulières pour faire face à la faible puissance de calcul de ce type de matériel<ref name=Ren/>.

== Notes et références ==
; Notes
{{Références|groupe=note}}
; Références
{{Références}}

=== Bibliographie ===
*{{en}} {{ouvrage|id=Sze10|auteur=Richard Szeliski|titre=[http://szeliski.org/Book Computer Vision: Algorithms and Applications]|éditeur=[[Springer]]|année=2010|isbn=}} {{plume}}

== Voir aussi ==
=== Articles connexes ===
* [[Détection de visage]]
* [[Détection d'objet]]

=== Lien externe ===
* [http://www.youtube.com/watch?v=WVY9MLzAWfA Une démonstration de détection de visage avec la méthode de Viola et Jones]

{{portail|Imagerie numérique}}
{{Article de qualité|oldid=59491514|date=27 novembre 2010}}

{{DEFAULTSORT:Methode de Viola et Jones}}
[[Catégorie:Vision artificielle]]

[[en:Viola-Jones object detection framework]]