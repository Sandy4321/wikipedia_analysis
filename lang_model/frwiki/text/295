Un '''circuit asynchrone''' est un [[circuit électronique]] [[électronique numérique|numérique]] qui n'utilise pas de [[signal d'horloge]] global pour synchroniser ses différents éléments. À la place, ceux-ci peuvent communiquer localement en indiquant quand des données sont disponibles. On utilise parfois l'adjectif '''auto-séquencé'''.

Bien qu'ils aient vu le jour presque en même temps que les circuits synchrones, de tels circuits sont minoritaires en 2012 et depuis le début de l'histoire de l'électronique : la plupart des processeurs fabriqués sont synchronisés par une [[signal d'horloge|horloge]]. Ils sont néanmoins envisagés comme une alternative possible aux circuits synchrones, entre autres pour diminuer la consommation d'énergie et s'adapter aux changements de la technologie en s'affranchissant des problèmes liés à la distribution du signal d'horloge.
﻿[[Fichier:Pipeline sync-async.svg|thumb|Principe du pipeline synchrone, en haut, où les données avancent au rythme de l'horloge, et du pipeline asynchrone, en bas, où les étages communiquent localement]]

== Histoire ==
{{section en travaux|auteur=Topeil|date=mars 2012}}
L'histoire des circuits asynchrones est jalonnée de nombreuses réalisations majeures, la création d'ordinateurs ou de processeurs complets constituant une étape marquante. Elles ne doivent pas faire oublier néanmoins les avancées théoriques et, récemment, le développement d'outils de synthèse et de vérification qui les ont permises.

Tout comme dans les autres branches de l'électronique numérique, la recherche continue encore bien que le concept ait été exprimé dès les années 50. Certains présagent l'utilisation généralisée de techniques asynchrones, particulièrement avec d'autres technologies, telles que les ordinateurs quantiques ou les réseaux de neurones, mais de telles prédictions n'ont pas été réalisées par le passé.

=== Les débuts : circuits indépendants de la vitesse et automates finis ===
La théorie des circuits asynchrones débute avec les travaux de [[David A. Huffman]] sur l'implémentation d'[[Automate fini|automates finis]] en 1953<ref name="eHist">{{PDF}} {{ouvrage|titre=The Early History of Asynchronous Circuits and Systems|prénom1=Charles L.|nom1=Leitz|année=2009|mois=Mai|jour=20|lire en ligne=http://asyncsymposium.org/async2009/slides/seitz-async2009.pdf|langue=en}}</ref>, bien que certains ordinateurs asynchrones<ref name="listeordis">{{PDF}} {{ouvrage|titre=Asynchronous Circuit Design|sous-titre=Lecture 1: Introduction, Preface and Chapter 1|langue=en|prénom1=Chris J.|nom1=Myers|lire en ligne=http://www.async.ece.utah.edu/book/lectures/lec1.pdf}}</ref>, comme l'[[ILLIAC]], aient déjà vu le jour. Le concept de circuit asynchrone tel que nous le concevons<ref group=note>Construit de manière modulaire en utilisant un protocole de communication entre les éléments</ref> remonte à la fin des années 50, quand les circuits « indépendants de la vitesse » reposant sur un protocole double-rail trois états sont introduits par David Muller<ref>{{harvsp|Sparsø, Furber|2001|p=23|réf=asyncdesign}}</ref>. Dès 1962, un ordinateur basé sur ce principe est construit, l'[[ILLIAC|ILLIAC II]].

=== L'essor des micropipelines et les premiers microprocesseurs ===
En 1988, Ivan Sutherland invente le concept de ''{{langue|en|micropipeline}}'', implémentation élégante d'un protocole deux-phases à données groupées. Celui-ci est ensuite sans cesse amélioré, grâce à d'autres implémentations ou à l'utilisation de protocoles à quatre phases.

Cette période voit également l'apparition du premier microprocesseur asynchrone<ref>{{harvsp|Vivet|2001|p=32|réf=Aspro}}</ref>, Caltech Asynchronous Processor, conçu à [[Caltech]] par l'équipe d'Alain Martin en 1989. Il utilise des circuits quasi-insensibles aux délais générés à partir de code CHP et possède une architecture [[Reduced instruction set computer|RISC]]<ref>{{PDF}} {{ouvrage|titre=The Design of an Asynchronous Microprocessor|prénom1=Alain J.|nom1=Martin|prénom2=Steven M.|nom2=Burns|prénom3=T. K.|nom3=Lee|prénom4=Drazen|nom4=Borkovic|prénom5=Pieter J.|nom5=Hazewindus|année=1989|langue=en|lire en ligne=http://authors.library.caltech.edu/26709/1/postscript.pdf}}</ref>.

Il est suivi par les différentes versions de l'[[AMULET (processeur)|AMULET]], basées sur les micropipelines, qui reprennent l'[[architecture ARM]]. La deuxième version introduit les micropipelines à quatre phases<ref name="fourphase"/>. Un autre microprocesseur QDI de [[Caltech]], le MiniMIPS, est conçu et testé à la fin des années 90. Il est considéré comme particulièrement performant<ref>{{harvsp|Vivet|2001|p=34|réf=Aspro}}</ref>. D'autres sont conçus dans des universités de par le monde comme l'Aspro (RISC et QDI), en 2001 à [[Institut National Polytechnique de Grenoble|Grenoble]]<ref>Sujet de la thèse {{harvsp|Vivet|2001|réf=Aspro}}</ref>.

=== Les premières commercialisations ===
A la fin des années 1990, des applications commerciales recommencent à voir le jour : de nombreuses entreprises commencent à utiliser des circuits basés sur une approche asynchrone ou à faire des recherches en ce sens. Parmi elles, [[Philips]] fait figure de précurseur en mettant en oeuvre des outils de synthèse de circuits asynchrones utilisant le langage Tangram ; la société commence à produire des [[microcontrôleur|microcontrôleurs]] [[Intel 8051|80C51]] asynchrones dès 1998<ref name="80C51">{{PDF}} {{ouvrage|titre=An Asynchronous Low-Power 80C51 Microcontroller|année=1998|prénom1=Hans|nom1=van Gageldonk|langue=en|lire en ligne=http://alexandria.tue.nl/extra3/proefschrift/boeken/9802299.pdf}}</ref>. Des chercheurs de [[Sun Microsystems]], [[Intel]] et [[IBM]] prennent aussi part à cet engouement<ref name="entreprises">{{PDF}} {{ouvrage|titre=The Status of Asynchronous Design in Industry|langue=en|mois=juin|année=2004|numéro d'édition=3|prénom1=D. A.|nom1=Edwards|prénom2=W. B.|nom2=Tom|lire en ligne=http://www.bcim.lsbu.ac.uk/ccsv/ACiD-WG/AsyncIndustryStatus.pdf}}</ref>. De nombreuses start-ups voient le jour pour exploiter les avantages de ces circuits, comme Theseus Logic, Fulcrum<ref name="entreprises"/> ou plus tard Tiempo, Green Array Inc...

=== Les avancées récentes ===
La recherche autour des circuits asynchrones se poursuit durant les années 2000 : de nouvelles implémentations de pipelines sont proposées tant multi-rails, comme LP2/1 en 2000<ref>{{pdf}} {{ouvrage|titre=High-Throughput Asynchronous Pipelines for Fine-Grain Dynamic Datapaths|prénom1=Montek|nom1=Singh|prénom2=Steven M.|nom2=Nowick|langue=en|année=2000|mois=avril|lire en ligne=http://www.cs.unc.edu/~montek/pubs/singh-nowick-async2000.pdf}}</ref>, qu'à données groupées, comme <small>MOUSETRAP</small> en 2007<ref>{{pdf}} {{ouvrage|titre=MOUSETRAP: High-Speed Transition-Signaling Asynchronous Pipelines|prénom1=Montek|nom1=Singh|prénom2=Steven M.|nom2=Nowick|langue=en|lire en ligne=http://www.cs.unc.edu/~montek/pubs/mousetrap-tvlsi-jun-2007.pdf|mois=Juin|année=2007|commentaire=Publié dans ''IEEE Transactions on Very Large Scale Integration Systems'', volume 15}}</ref> ; les protocoles dits ''{{langue|en|single-track}}'', utilisant un même fil pour la requête et l'acquittement, apparaissent<ref>Apparemment présenté pour la première fois dans {{ouvrage|titre=Single-Track Handshake Signaling with Application to Micropipelines and Handshake Circuits|année=1996|commentaire=Non trouvé en accès libre|prénom1=Kees|nom1=van Berkel|prénom2=Arjan|nom2=Bink|langue=en}}<!-- I hate IEEE --></ref>, avec des implémentations comme STFB<ref>{{pdf}}  {{ouvrage |prénom1=Marcos |nom1=Ferretti |prénom2=Peter A. |nom2=Beerel |titre=Single-Track Asynchronous Pipeline Templates Using 1-of-N Encoding |langue=en |lire en ligne=http://www.date-conference.com/proceedings/PAPERS/2002/DATE02/PDFFILES/10B_2.PDF|éditeur=University of Southern California}}</ref> et GasP<ref>{{pdf}} {{ouvrage|titre=GasP: A Minimal FIFO Control|prénom1=Ivan E.|nom1=Sutherland|prénom2=Scott|nom2=Fairbanks|langue=en|lire en ligne=http://www.cs.unc.edu/~montek/teaching/spring-04/sutherland-gasp-async2001.pdf|éditeur=Sun Microsystems Laboratories}}</ref>.

==Caractéristiques==
Les circuits asynchrones possèdent plusieurs propriétés potentiellement intéressantes<ref>Ces avantages sont décrits dans de nombreux articles relatifs à l'électronique asynchrone, comme {{harvsp|Vivet|2001|p=16-18|réf=Aspro}},{{harvsp|Sparsø, Furber|2001|p=3-4|réf=asyncdesign}} et {{harvsp|Hauck|1995|p=1-2|réf=overview}}</ref> : ils sont particulièrement prometteurs dans des domaines où la fiabilité est requise et pour des circuits à basse consommation, voire pour leur vitesse, bien qu'aucune méthode de conception ne possède tous ces avantages simultanément : il existe de très nombreuses façons de les concevoir, chacune avec ses avantages et ses problèmes.

===Consommation d'énergie===
Un [[signal d'horloge]] change d'état en permanence<ref group=note>Une optimisation pour les circuits synchrones, appelée {{lang|en|[[clock gating]]}}, consiste à l'arrêter ou à le ralentir lorsque le circuit est inactif ''pour une longue période''</ref>, ce qui consomme de l'énergie. A contrario, les circuits asynchrones ne sont actifs que lorsque des données sont disponibles. Dans le cas contraire, aucun transistor ne commute et la seule puissance consommée est due à leurs courants de fuite<ref group=note>Il s'agit de la distinction entre consommation dite ''dynamique'' et ''statique'' : la première, consommation d'un circuit qui change d'état, est due au chargement des fils, aux fuites et aux courts-circuits lors des commutations ; la seconde, consommation d'un circuit stable, n'est due qu'au fait que les transistors ne sont pas parfaits et présentent des fuites, et est généralement bien plus faible</ref>, ce qui en fait des candidats crédibles pour des circuits à basse consommation, ou lorsque la charge de travail évolue rapidement<ref>{{harvsp|Vivet|2001|p=16-18|réf=Aspro}}</ref>.

Cependant, pour assurer la communication entre les éléments, ils utilisent aussi plus de transistors et plus de fils pour une même quantité de données que leurs équivalents synchrones, ce qui peut compenser les gains énergétiques et augmente la taille des puces.

Des implémentations ont néanmoins montré des gains substantiels, avec une efficacité énergétique quatre fois supérieure à un équivalent synchrone pour une implémentation de microcontrôleur 80C51<ref name="80C51"/>, ou des performances proches des autres processeurs ARM du moment pour les processeurs [[AMULET (processeur)|AMULET]].

===Fiabilité===
Selon la méthodologie de conception employée, il est possible de créer des circuits utilisant peu d'hypothèses temporelles (insensibles ou quasi-insensibles aux délais par exemple) : ces circuits auront un comportement correct même si les propriétés physiques du circuit évoluent (à cause de la température, de la tension d'alimentation ou d'un changement de technologie de fabrication<ref>{{harvsp|Vivet|2001|p=19-20|réf=Aspro}} et {{harvsp|Hauck|1995|p=2|réf=overview}}</ref>).

Les circuits asynchrones sont sensibles à tous les changements d'états des fils, et non à des signaux stabilisés échantillonnés lors de commutations de l'horloge<ref>{{harvsp|Davis et Nowick|1997|p=13-17|réf=intro}}</ref> : on parle d''''aléas''' pour désigner les variations indésirables des signaux<ref>{{harvsp|Dinh-Duc|2003|p=15-19|réf=synQDI}}</ref>. De tels problèmes sont à prendre en compte à la conception<ref name="synaléas>{{harvsp|Dinh-Duc|2003|p=9|réf=synQDI}}</ref>. Cela leur donne aussi des comportements différents des circuits synchrones en cas d'erreurs ou de [[Parasite (électricité)|parasites]]. De plus, certains protocoles asynchrones (focalisés sur la performance plutôt que la fiabilité) font de nombreuses suppositions sur le comportement des circuits (principalement sur les délais) qui ne sont pas faciles à réaliser en pratique ou peuvent être infirmées par des variations de taille et de performance des transistors.

La conception d'un circuit synchrone demande quant à elle une connaissance précise des délais des portes, mais un délai trop élevé pourra être compensé par une diminution de la fréquence d'horloge<ref>{{harvsp|Vivet|2001|p=28|réf=Aspro}}</ref>, au prix d'une baisse de la vitesse globale du circuit. Un autre problème récurrent est le phénomène de [[Signal_d'horloge#Gigue_d.27horloge|gigue d'horloge]], et en général le problème de la distribution du signal d'horloge dans les circuits, qui compliquent la montée en fréquence et dont la correction nécessite l'utilisation de techniques complexes, parfois énergivores<ref>{{harvsp|Davis et Nowick|1997|p=3-5|réf=intro}}</ref>.

===Vitesse===
En [[électronique numérique]], la vitesse peut-être caractérisée de deux manières différentes : la [[lag (informatique)|latence]], qui correspond au temps que met une donnée pour être traitée par le circuit, et le [[Débit_binaire|débit]], qui est le nombre de données traitées par unité de temps.

D'une part, les circuits permettant de passer des données d'un élément à l'autre peuvent introduire une [[lag (informatique)|latence]] supplémentaire pour traiter les signaux de requête et d'acquittement, chaque élément comprenant généralement plusieurs [[Bascule (circuit logique)|bascules et verrous]] pour cela.

Par contre, la [[lag (informatique)|latence]] comme le [[Débit_binaire|débit]] ne sont pas limités par un [[signal d'horloge]] global, et ne sont pas forcément constants selon les parties du circuit ou les données en entrée. Par exemple, pour des circuits logiques tels que les [[Additionneur|additionneurs]]<ref>Des additionneurs et des multiplieurs utilisant ce principe sont décrits dans {{harvsp|Vivet|2001|p=159-171|réf=Aspro}} ; c'est une technique largement utilisée pour la propagation des retenues, comme on peut le voir dans {{pdf}} {{ouvrage |titre=Minimal Energy Asynchronous Dynamic Adders |prénom1=Ilya |nom1=Obridko |prénom2=Ran |nom2=Ginosar |langue=en |année=2006 |lire en ligne=http://webee.technion.ac.il/~ran/papers/Low%20Energy%20Adders%20Obridko%20Ginosar%20TR.pdf |éditeur=Israel Institute of Technology |pages=16 |commentaire=Une version raccourcie de cet article a été acceptée pour publication par la revue ''IEEE Trans. On VLSI'' en 2006}}</ref>, certaines implémentations asynchrones peuvent renvoyer le résultat dès qu'il est calculé (ici, la retenue), alors qu'un circuit synchrone doit toujours attendre jusqu'au signal d'horloge suivant (qui doit être suffisamment tard pour que les calculs soient terminés même dans le pire des cas). Ils permettent donc de bonnes implémentations en temps moyen de calcul, bien que le pire des cas puisse être bien plus long<ref>{{harvsp|Vivet|2001|p=14-15|réf=Aspro}}</ref>.

===Simplicité de conception===
Il est facile d'utiliser ensemble des circuits asynchrones différents (même utilisant des protocoles différents, en ajoutant un élément traduisant de l'un à l'autre), car aucun élément n'a besoin d'être commun, au contraire de l'horloge des circuits synchrones. Il est même possible de les interfacer avec des circuits synchrones, et d'interfacer des circuits synchrones entre eux par des liaisons asynchrones<ref>{{pdf}} {{ouvrage|titre=Practical Design of Globally-Asynchronous Locally-Synchronous Systems|prénom1=Jens|nom1=Muttersbach|prénom2=Thomas|nom2=Villiger|prénom3=Wolfgang|nom3=Fichtner|langue=en|éditeur=Swiss Federal Institute of Technology|lire en ligne=http://eecourses.technion.ac.il/048878/048878papers/Muttersbach-GALS-Async00.pdf}}</ref>. Cette modularité est un avantage pour l'interfaçage avec d'autres éléments<ref>{{harvsp|Davis et Nowick|1997|p=5|réf=intro}}</ref>{{,}}<ref name="modular">{{harvsp|Vivet|2001|p=20-21|réf=Aspro}}</ref>, mais aussi pour la conception en général, qui s'en trouve facilitée<ref name="modular" /> et peut-être faite avec des [[Langage de haut niveau|langages de haut niveau]].

La suppression de l'horloge et d'une base de temps globale simplifie grandement le processus, en évitant de devoir prendre en compte les délais et la distribution du signal d'horloge à toutes les échelles lors de la phase de conception<ref>{{harvsp|Vivet|2001|p=16|réf=Aspro}}</ref>, mais elle introduit d'autres problèmes qui doivent être pris en compte par les outils ou par le concepteur.

===Émissions électromagnétiques===
Du fait que les différents éléments ne sont pas synchronisés, les émissions électromagnétiques sont réduites tandis que la consommation électrique est lissée<ref name="conso">{{harvsp|Vivet|2001|p=18-19|réf=Aspro}}</ref> : cela peut-être exploité pour se prémunir de [[Analyse de consommation (cryptographie)|certaines attaques exploitant celles-ci]]<ref>{{pdf}} {{Article |titre=Delay Insensitive Encoding and Power Analysis: A Balancing Act|prénom1=Konrad J. |nom1=Kulikowski |prénom2=Ming |nom2=Su |prénom3=Alexander |nom3=Smirnov |prénom4=Alexander |nom4=Taubin |prénom5=Mark G. |nom5=Karpovsky |prénom6=Daniel |nom6=MacDonald |langue=en |périodique= ASYNC |année=2005 |passage=116-125 |éditeur=IEEE |lire en ligne=http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.64.920&rep=rep1&type=pdf}}</ref>, car il est alors plus difficile de capter des  l'activité du circuit à partir de ses émissions ou de sa consommation. Cette propriété peut être exploitée dans tout environnement où les émissions électromagnétiques doivent être minimisées<ref name="conso"/>, par exemple au voisinage d'une antenne.

Un circuit synchrone, a contrario, a tendance à émettre des ondes harmoniques de sa fréquence d'horloge et à présenter des pics de puissance consommée à chaque front d'horloge.

==Protocoles de communication==
Il existe de nombreux moyens de réaliser une interface asynchrone entre deux éléments, mais on présentera ici surtout les principaux, avec une communication à sens unique impliquant un émetteur et un destinataire et où l'envoi des données est signalé par une requête, notée '''req''', et leur réception par un acquittement, noté '''ack'''. Un échange se déroule comme suit : lorsque ses données sont prêtes, l'émetteur les copie en sortie et en informe le destinataire via une requête ; celui-ci, lorsqu'il peut accepter les données, c'est-à-dire quand il a transmis ou utilisé les données précédentes, les copie puis renvoie un acquittement pour signifier qu'il n'en a plus besoin. L'émetteur peut alors envoyer de nouvelles données.

===Protocoles===
On distingue deux familles de [[Protocole de communication|protocoles]]<ref>{{harvsp|Vivet|2001|p=8-10|réf=Aspro}}</ref> selon la façon dont les événement, tels que les requêtes et les acquittements, sont codés :
* soit ils correspondent à une transition quelconque, c'est-à-dire un changement de valeur sur un fil, de '''1''' à '''0''' ou de '''0''' à '''1'''. On parle de protocole à deux phases, de « ''{{lang|en|half-handshake}}'' » ou de codage NRZ (''{{lang|en|Non-return-to-zero}}'') : l'émetteur envoie les données et émet une requête, que le destinataire traite avant d'envoyer l'acquittement.
* soit l’émetteur et le destinataire remettent les signaux de requête et d'acquittement à leur état initial après avoir signalé la transmission et la réception des données par des transitions. On parle de protocole à quatre phases, de « ''{{lang|en|full-handshake}}'' » ou de codage RZ (''{{lang|en|Return-to-zero}}'') : après l'envoi des données et de la requête, puis leur réception et l'acquittement, l'émetteur ramène le signal de requête à son état initial, puis le destinataire fait de même avec le signal d'aquittement. Malgré une apparente complexité, ce protocole permet des implémentations souvent plus simples et rapides que le protocole à deux phases<ref name="fourphase">{{pdf}} {{ouvrage |titre=Four-Phase Micropipeline Latch Control Circuit |prénom1=Stephen B. |nom1=Furber |prénom2=Paul |nom2=Day |langue=en |lire en ligne=http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=A82C3B3430D2507A018CBAF817EC29E1?doi=10.1.1.41.8360&rep=rep1&type=pdf}}</ref>.

Des protocoles plus complexes sont aussi utilisés. Très fréquemment, la requête est codée sur les mêmes fils que les données, ce qui donne les codage sur plusieurs fils présenté dans la section suivante. Certains protocoles, moins répandus, n'ont pas de fil séparé pour l'acquittement et utilisent un ou des fils sur lesquel l'émetteur comme le destinataire peuvent agir<ref>De tels protocole ont été proposés pour différents codages. Pour un codage sur plusieurs rails, une implémentation est donnée dans cet article : {{pdf}} {{ouvrage |prénom1=Marcos |nom1=Ferretti |prénom2=Peter A. |nom2=Beerel |titre=Single-Track Asynchronous Pipeline Templates Using 1-of-N Encoding |langue=en |lire en ligne=http://www.date-conference.com/proceedings/PAPERS/2002/DATE02/PDFFILES/10B_2.PDF|éditeur=University of Southern California}}. Pour un codage à données groupées : {{pdf}} {{ouvrage|titre=GasP: A Minimal FIFO Control|prénom1=Ivan E.|nom1=Sutherland|prénom2=Scott|nom2=Fairbanks|langue=en|lire en ligne=http://www.cs.unc.edu/~montek/teaching/spring-04/sutherland-gasp-async2001.pdf|éditeur=Sun Microsystems Laboratories}}</ref> : de cette manière, il n'y a que deux phases (envoi puis remise à zéro), et moins de fils de communication. D'autres protocoles ont été proposés : basé sur des impulsions, c'est à dire une remise à zéro précoce des fils<ref>{{PDF}} {{ouvrage|titre=Asynchronous Pulse Logic|prénom1=Mika|nom1=Nyström|jour=14|mois=Mai|année=2001|langue=en|éditeur=California Institute of Technology|commentaire=Thèse présentée en 2001 en vue de l'obtention d'un doctorat de [[université de Californie|Berkeley]]|lire en ligne=http://authors.library.caltech.edu/26921/0/tr_main.ps}}</ref>, ou supprimant les [[Bascule (circuit logique)|bascules]]<ref group=note>On en trouve différents exemples dans la littérature, bien qu'ils ne possèdent pas toutes les propriétés des autres circuits asynchrones et que de tels ''{{lang|en|wave pipelines}}'' soient aussi utilisés en synchrone</ref>{{,}}<ref>{{pdf}} Par exemple {{ouvrage|titre=Fault Tolerant Clockless Wave Pipeline Design|langue=en|prénom1=T.|nom1=Feng|prénom2=B.|nom2=Jin|prénom3=J.|nom3=Wang|prénom4=N.|nom4=Park|prénom5=Y.B.|nom5=Kim|prénom6=F.|nom6=Lombardi|lire en ligne=http://www.ece.neu.edu/groups/hpvlsi/publication/FAULT_CKLESS_ACMCF.pdf}} et {{ouvrage|titre=Asynchronous Wave Pipelines for High Throughput Dynamic Datapaths|langue=en|prénom1=O.|nom1=Hauck|prénom2=S. A.|nom2=Huss|éditeur=Darmstadt University of Technology|lire en ligne=http://www.iss.tu-darmstadt.de/publications/downloads/hauck98b.pdf}}</ref>.

===Codage des données===
[[Fichier:Protocole 3 états.svg|thumb|Les états et les transitions pour le codage trois états]]
[[Fichier:Protocole 4 états.svg|thumb|Les états et les transitions pour le codage quatre états|alt=4 états, 00, 01, 10 et 11, deux codant le 0 et deux le 1, de telle manière qu'il soit toujours possible d'atteindre l'un des deux en ne changeant que l'un des deux bits]]

Dans les circuits asynchrones, il existe de nombreux moyens de coder les données. Le codage le plus évident, similaire à celui des circuits synchrones, utilise un fil pour un [[bit]]<ref group=note>Parfois, pour des raisons de performances ou de fiabilité, on code néanmoins sur deux fils, codant le bit et son complémentaire</ref> ; en asynchrone, on l'appelle « codage à données groupées ». Cependant, comme toute transmission de données asynchrone s'accompagne d'une requête permettant de la signaler, une autre technique est de coder ensemble les données et la requête, comme par exemple dans les codages « double-rail », sur deux fils, qui sont très utilisés.

====Codage à données groupées====
Dans ce protocole, un ou plusieurs fils transportent les données, avec un fil par [[bit]]. Un fil ('''Req''') est destiné à la requête de l'émetteur indiquant que les données sont prêtes, et un autre ('''Ack''') à la réponse du destinataire. De tels circuits sont conçus en utilisant un modèle où certains délais sont considérés comme bornés<ref group=note>Car sinon les données pourraient ne pas être valides alors même que la requête serait arrivée</ref>.

On parle souvent de ''{{langue|en|micropipelines}}'' pour désigner les circuits utilisant ce codage, avec soit deux soit quatre<ref name="fourphase"/> phases. À l'origine, ce terme fait référence à un pipeline asynchrone utilisant un protocole deux phases données groupées<ref>{{pdf}} Le premier type de {{langue|en|micropipeline}} est introduit par Ivan Sutherland, et est entre autres décrit dans {{article |titre=Micropipelines |prénom1=Ivan E. |nom1=Sutherland |périodique=Communications of the ACM |mois=juin |année=1989 |volume=32 |numéro=6 |pages=19 |langue=en |lire en ligne=http://f-cpu.seul.org/new/micropipelines.pdf }}</ref>.

====Codage sur plusieurs fils====
Ici, il n'y a pas de fil séparé destiné à l'envoi de la requête, qui est implicite<ref>Le fil d'acquittement est présent, sauf protocole particulier</ref>{{,}}<ref>{{harvsp|Vivet|2001|p=10-11|réf=Aspro}}</ref>. De manière générale, il existe des codages complexes dits ''m parmi n'', dont on n'utilise surtout qu'un cas particulier dit ''double rail'', avec deux fils. Dans ces codages, une donnée est représentée par m transitions parmi n fils, et le destinataire peut considérer que les données sont valides dès lors que m transitions ont eu lieu, ce qui rend le codage lui-même insensible aux délais<ref>{{harvsp|Dinh-Duc|p=11|réf=synQDI}}</ref>. Un tel codage est approprié tant pour un protocole à quatre phases, où on remet tous les fils à leur état initial après chaque échange, que pour un protocole à deux phases. Bien sûr, d'autres codages sont possibles, mais peu usités.

Les deux protocoles double-rail sont largement répandus. Le protocole à quatre phases, aussi dit ''codage trois-états'', est le plus populaire. Il comporte une valeur invalide (typiquement 00), et deux valeurs signifiantes (01 codant 0 et 10 codant 1 par exemple), l'état 11 étant inutilisé. L'émetteur repasse par l'état invalide à chaque envoi de données. Pour signifier que le destinataire a remarqué le changement de valeur, une réponse est émise à chaque fois, y compris au passage par l'état invalide, ce qui permet au signal d'acquittement de revenir aussi à son état initial. Dans le protocole à deux phases, dit aussi ''codage quatre-états'', tous les états sont signifiants, mais deux codes correspondent à chaque valeur d'un bit, ce qui permet bien de changer d'état à chaque nouvelle donnée<ref group=note>On appelle aussi ce codage LEDR pour {{Citation étrangère|lang=en|Level Encoded Dual-Rail}}</ref>.

==Conception de circuits asynchrones==
=== Hypothèses de conception ===
Les circuits asynchrones regroupent en fait plusieurs classes de circuits<ref>{{harvsp|Vivet|2001|p=21-24|réf=Aspro}}, {{harvsp|Hauck|1995|p=3-22|réf=overview}} et {{harvsp|Sparsø, Furber|2001|p=25|réf=asyncdesign}}}</ref> ayant des propriétés différentes, selon les hypothèses faites à la conception. En effet, la communication locale des circuits asynchrones peut permettre de s'affranchir de certaines contraintes de temps, les éléments indiquant eux-mêmes la disponibilité des données. Ces propriétés s'échelonnent de l'insensibilité aux délais (on parle de circuits {{abréviation|'''DI'''|Delay-insensitive|en}}), où le circuit est correct quels que soient les délais des portes et des fils, au modèle des délais bornés, où les délais ont une limite connue. Deux classes de circuits intermédiaires sont utilisées : quasi-insensibles aux délais ({{abréviation|'''QDI'''|Quasi-delay-insensitive|en}}) et indépendants de la vitesse ({{abréviation|'''SI'''|Speed-independent|en}}).

Il ne faut cependant pas oublier que les délais sont parfois plus complexes que de simples retards, que les signaux sont en réalité des tensions, et non des valeurs binaires, et que les portes elles-mêmes sont forcément implémentées en utilisant un modèle de délais bornés.

==== Circuits insensibles aux délais ====
De tels circuits fonctionnent correctement quels que soient les délais dans les fils et les portes. Ils ne sont cependant pas réalisables avec des portes logiques simples (les seules portes logiques à une sortie utilisables sont les [[Porte C|portes C]] et l'inverseur)<ref name="lims">{{pdf}} {{ouvrage |titre=The Limitations to Delay Insensitivity in Asynchronous Circuits |prénom1=Alain J.|nom1=Martin |pages=20 |année=1990 |mois=janvier |langue=en |lire en ligne=http://www.dtic.mil/cgi-bin/GetTRDoc?AD=ADA447737&Location=U2&doc=GetTRDoc.pdf}}, cité dans {{harvsp|Sparsø, Furber|2001|p=25|réf=asyncdesign}} et {{harvsp|Hauck|1995|p=13|réf=overview}}</ref>, et ne sont donc pas souvent utilisés en pratique. Ce modèle est cependant utilisable avec des portes plus complexes, elles-mêmes implémentées suivant d'autres hypothèses.

==== Circuits quasi-insensibles aux délais ====
Ces circuits ajoutent simplement l'hypothèse, pour la conception, qu'il est possible d'obtenir des « fourches isochrones », c'est-à-dire une séparation d'un fil en plusieurs possédant exactement le même délai, supposition qui est réalisable en pratique<ref group=note>Du fait que les portes suivant la fourche ont elles-mêmes un délai, ce qui permet de ne le vérifier qu'approximativement. Voir {{harvsp|Vivet|2001|p=23|réf=Aspro}}</ref>, mais présente certains risques<ref>{{pdf}} {{ouvrage|titre=Beware the isochronic fork|langue=en|prénom1=Kees|nom1=van Berkel|année=1991|mois=Janvier|lire en ligne=http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=380B231B55BB4F45F6E4B72D4D273D44?doi=10.1.1.72.3108&rep=rep1&type=pdf|commentaire=Publié dans la revue ''Integration, the VLSI Journal'', volume 13, en Juin 1992<!--même si Elsevier ne mérite pas cette citation-->}}</ref>. C'est un modèle de conception largement utilisé.

==== Circuits indépendants de la vitesse ====
On peut aussi considérer les délais dans les fils comme étant négligeables. Cela se vérifie difficilement dans les systèmes actuels<ref name="SI1">{{harvsp|Vivet|2001|p=23-24|réf=Aspro}} et {{harvsp|Hauck|1995|p=21-22|réf=overview}}</ref>, c'est pourquoi on peut leur préférer des circuits conçus comme quasi-insensibles aux délais. Cependant, les deux hypothèses sont en fait très proches<ref name="SI1" />, le cas indépendant de la vitesse revenant à considérer toutes les fourches comme isochrones.

==== Circuits à délais bornés ====
Comme l'indique leur nom, les délais dans les portes et les fils sont supposés connus ou bornés par une durée connue. On les appelle parfois circuits de [[David Albert Huffman|Huffman]]. C'est le principe de conception en électronique synchrone, où les impulsions d'horloge se font à intervalle suffisamment long pour que les signaux se soient propagés et stabilisés dans tout le circuit. En électronique asynchrone, ce modèle est aussi utilisé, tout d'abord pour concevoir la structure interne de nombreuses portes, mais également dans les {{langue|en|micropipelines}}<ref>{{harvsp|Hauck|1995|p=10-11|réf=overview}}</ref>, ou pour obtenir des circuits particulièrement performants<ref group=note>C'est le cas de presque tous les circuits simulés dans {{harvsp|Shojaee, Gholipour, Nourani|2006|réf=pipelinecomp}}</ref>.

Ce modèle est aussi utilisé pour la conception de portes complexes (des [[Automate fini|automates finis]])<ref>{{harvsp|Hauck|1995|p=3-10|réf=overview}}</ref>. On peut en simplifier la conception en restreignant le nombre d'entrées qui sont autorisées à changer simultanément. On parle de {{citation|mode fondamental}} lorsque les entrées ne changent que si la ou les sorties ont atteint un état stable<ref>{{PDF}} {{ouvrage|titre=Digital Principles and Design|sous-titre=Chapter 18, Lesson 1: Fundamental Mode Sequential Circuits|lire en ligne=http://www.dauniv.ac.in/downloads/Digitalsystems_PPTs/DigDesignCh18L01.pdf|année=2006|prénom1=Raj|nom1=Kamal|langue=en}}</ref>.

=== Mise en œuvre ===
On utilise souvent le modèle du [[Pipeline (électronique)|{{lang|en|pipeline}}]]<ref group=note>Pour l'électronique synchrone comme asynchrone, le {{lang|en|pipeline}} est un moyen d'augmenter les performances, mais aussi la traduction « directe » du fait que des calculs sont effectués de manière séquentielle</ref>{{,}}<ref>{{harvsp|Davis et Nowick|1997|p=35|réf=intro}} et {{harvsp|Sparsø, Furber|2001|p=279|réf=asyncdesign}}</ref>, où les données progressent de [[Bascule (circuit logique)|bascule]] en bascule. Les pipelines asynchrones ont la propriété d'être élastiques<ref>{{harvsp|Vivet|2001|p=15|réf=Aspro}}</ref>, c'est à dire qu'ils peuvent contenir un nombre variable<ref group=note>Mais bien sûr fini</ref> de données ; celles-ci se propagent indépendamment des données qui les suivent. Pour simplifier la création d'éléments asynchrones, plusieurs portes de base sont utilisées dont la [[porte C]] de Muller, des portes équivalentes aux [[Fonction_logique|portes combinatoires]] telles que des [[Fonction OU|portes OU]], des multiplexeurs ou des [[Additionneur|additionneurs]], des portes « arbitres » permettant de gérer l'accès simultané à un sous-circuit, ou des fourches et des convergences<ref>{{harvsp|Dinh-Duc|p=59-65|réf=synQDI}}</ref> permettant la création de pipelines non linéaires. Le caractère modulaire des circuits asynchrones permet ensuite de combiner facilement des portes utilisant un même protocole.

Les implémentations varient bien sûr selon le protocole utilisé, mais aussi selon les propriétés recherchées (faible latence, débit élevé, fiabilité, déterminisme, sécurité, faible consommation). Par exemple, en utilisant un codage double-rail, les portes signalent elles-mêmes quand des données sont prêtes, voire renvoient un résultat sans attendre que toutes les entrées soient disponibles<ref name="earlyoutput">{{harvsp|Brej|2002|réf=Brej2002}} et {{harvsp|Brej|2005|réf=Brej2005}}</ref> (par exemple une porte OU si une entrée vaut 1). Un codage à données groupées n'utilisera par contre qu'un seul fil par [[bit]], et on réutilise souvent<ref group=note>Comme par exemple dans les {{langue|en|micropipelines}}</ref> des portes issues de la [[Fonction_logique|logique combinatoire]], comme pour les circuits synchrones ; il est alors nécessaire d'adapter le délai imposé au signal de requête aux délais des portes, bien qu'il soit possible là aussi de créer des portes à délai variable<ref group=note>On trouve de nombreux exemples de telles portes dans la littérature, y compris en électronique synchrone</ref>.

=== Comparaison des protocoles et des implémentations ===

===Automatisation de la conception et langages===
Comme les seules choses qui importent dans un circuit asynchrone sont les interactions entre les éléments, on peut concevoir les circuits par [[Compilateur|compilation]] de langages de haut niveau reflétant la [[Parallélisme (informatique)|concurrence]]<ref name="langages">{{harvsp|Sparsø, Furber|2001|p=123|réf=asyncdesign}}, {{harvsp|Vivet|2001|p=43-53|réf=Aspro}}</ref>, ou par une description de son comportement par un graphe similaire aux [[Réseau de Petri|réseaux de Petri]]<ref>{{harvsp|Sparsø, Furber|2001|p=86-114|réf=asyncdesign}}, {{harvsp|Vivet|2001|p=27-28|réf=Aspro}} et {{harvsp|Hauck|1995|p=22-28|réf=overview}}</ref>, générant ainsi un [[automate fini]].

Différentes méthodologies et outils de synthèse ont été développés<ref>{{harvsp|Dinh-Duc|p=29-39|réf=synQDI}}</ref>, tant dans le milieu académique (Balsa<ref>{{harvsp|Dinh-Duc|p=30-31|réf=synQDI}}</ref>, {{citation|Caltech}}<ref>{{harvsp|Dinh-Duc|p=31-33|réf=synQDI}}</ref>, Minimalist<ref>{{harvsp|Dinh-Duc|p=37-39|réf=synQDI}}</ref>{{,}}<ref>{{PDF}} {{ouvrage|titre=MINIMALIST: An Environment for the Synthesis, Verification and Testability of Burst-Mode Asynchronous Machines|lire en ligne=http://www1.cs.columbia.edu/async/publications/minimalist-tech-report.pdf|prénom1=Robert M.|nom1=Fuhrer|prénom2=Steven M.|nom2=Nowick|prénom3=Michael|nom3=Theobald|prénom4=Niraj K.|nom4=Jha|prénom5=Bill|nom5=Lin|prénom6=Luis|nom6=Plana|année=1999|mois=juin|jour=26|langue=en}}</ref>, Petrify<ref>{{harvsp|Dinh-Duc|p=35-37|réf=synQDI}}</ref>) que dans l'industrie (Tangram<ref>{{harvsp|Dinh-Duc|p=29-30|réf=synQDI}}</ref>, Null Convention Logic<ref>{{harvsp|Dinh-Duc|p=33-35|réf=synQDI}}</ref>{{,}}<ref>{{PDF}} {{ouvrage|titre=NULL Convention Logic{{TM}}|éditeur=Theseus Logic Inc.|année=1997|prénom1=Karl M.|nom1=Fant|prénom2=Scott A.|nom2=Brandt|langue=en|lire en ligne=http://users.soe.ucsc.edu/~sbrandt/papers/NCL2.pdf}}</ref>). Parmi les langages utilisés, beaucoup sont dérivés du langage [[Communicating_sequential_processes|CSP]], comme CHP et [[Occam (langage)|Occam]]. Certains, mais pas tous, ont été développés spécifiquement pour la conception de circuits asynchrones. On peut aussi utiliser des langages de description matérielle plus classiques, comme [[Verilog]] ou [[VHDL]], qui ne sont pas spécifiquement destinés à la conception de circuits asynchrones<ref>{{harvsp|Vivet|2001|réf=Aspro}} présente une méthode de conception utilisant une traduction de [[CHP]] vers [[VHDL]].</ref>.

===Problèmes liés à la conception===
La conception de circuits asynchrones souffre d'un manque d'outils dédiés<ref>{{lien web|url=http://www.eetimes.com/discussion/cole-bin/4024444/Will-Self-timed-Asynchronous-Logic-Rescue-CPU-Design-|titre=Will Self-timed Asynchronous Logic Rescue CPU Design?|auteur=Bernard Cole|année=2002|jour=24|mois=août}}</ref>, les principaux [[Langage de description de matériel|langages de description de matériels]] ciblant la conception de circuits synchrones, bien qu'il soit possible de les utiliser pour créer des circuits asynchrones.

Une autre limitation tient à la formation, qui est généralement focalisée sur l'électronique synchrone, l'électronique asynchrone étant moins répandue<ref>{{harvsp|Davis et Nowick|1997|p=2|réf=intro}}</ref> et souvent vue comme moins efficace ou plus complexe.

Enfin, les problèmes de fiabilités dus entre autres à des contraintes temporelles sont aussi présents dans les circuits asynchrones, et peuvent être particulièrement graves puisque les temps de propagation ne sont pas réglables comme avec une horloge : les outils de conception doivent le prendre en compte. Ils sont surtout présents dans des circuits faisant beaucoup d'hypothèses temporelles (comme le modèle de délais bornés), et ne peuvent alors être évités que par des [[Simulateur logique|simulations]] et des tests.

== Notes et références ==
=== Notes ===
<references group=note/>

=== Références ===
{{Références|colonnes=2}}

==Voir aussi==
===Articles connexes===
*[[Processeur asynchrone]]
===Bibliographie===
* {{pdf}} {{ouvrage |titre=Une méthodologie de conception de circuits intégrés quasi-insensibles aux délais |sous-titre=Application à l'étude et à la réalisation d'un processeur RISC 16-bit asynchrone |prénom1=Pascal |nom1=Vivet |jour=21 |mois=juin |année=2001 |lire en ligne=http://hal.inria.fr/docs/00/04/54/03/PDF/tel-00002974.pdf |id=Aspro |commentaire=Thèse présentée en 2001 en vue de l'obtention d'un doctorat de l'[[INPG]]}}
* {{pdf}} {{ouvrage|titre=Synthèse automatique de circuits asynchrones QDI|prénom1=Anh-Vu|nom1=Dinh-Duc|jour=14|mois=mars|année=2003|langue=fr|commentaire=Thèse présentée en 2003 en vue de l'obtention d'un doctorat de l'[[INPG]]|lire en ligne=http://tel.archives-ouvertes.fr/docs/00/04/53/78/PDF/tel-00002937.pdf|id=synQDI}}
* {{pdf}} {{ouvrage|titre=Synthèse Logique de Circuits Asynchrones Micropipeline|prénom1=Amine|nom1=Rezzag|jour=13|mois=décembre|année=2004|langue=fr|commentaire=Thèse présentée en 2004 en vue de l'obtention d'un doctorat de l'[[INPG]]|lire en ligne=http://tima.imag.fr/publications/files/th/2006/lsm_204.pdf|id=synMP}}
* {{pdf}} {{article |titre=Asynchronous Design Methodologies: An Overview |prénom1=Scott |nom1=Hauck |mois=janvier |année=1995 |langue=en
|périodique=[[Proceedings of the IEEE]] |volume=83 |numéro=1 |passage=69-93
|lire en ligne=http://www.ee.washington.edu/people/faculty/hauck/publications/AsynchArt.pdf |id=overview}}
* {{pdf}} {{ouvrage |titre=An Introduction to Asynchronous Circuit Design |prénom1=Al |nom1=Davis |prénom2=Steven M. |nom2=Nowick |jour=19 |mois=septembre |année=1997 |langue=en |lire en ligne=http://www.cs.utah.edu/~ald/pubs/ald-nowick-tr-intro.pdf |id=intro |commentaire=Dans l'introduction du document, les auteurs affirment que : {{citation|L'intention de cette monographie est de présenter à la fois une introduction au domaine de la conception de circuits numériques asynchrones et un survol de l'état de l'art en 1997.}} }}
* {{pdf}} {{Ouvrage |langue=en | titre  = Principles of asynchronous circuit design - A systems perspective |prénom1= Jens |nom1= Sparsø |directeur1=oui |prénom2= Steve|nom2= Furber |directeur2=oui | éditeur = Kluwer Academic Publishers | année= 2001 |pages=337|lire en ligne=http://owlhouse.csie.nctu.edu.tw/~dannim/AsynCD/principles_of_ASYNC.pdf|commentaire=Les chapitres 1 à 8, qui sont beaucoup cités, sont aussi publiés indépendamment : {{ouvrage |titre=Asynchronous circuit design|sous-titre=A tutorial |langue=en |prénom1=Jens |nom1=Sparsø |année=2006 |lire en ligne=http://www2.imm.dtu.dk/pubdb/views/edoc_download.php/855/pdf/imm855.pdf}}|id=asyncdesign}}
* {{pdf}} {{ouvrage |titre=The Design and Implementation of an Asynchronous Microprocessor |langue=en |nom1=Paver |prénom1=Nigel Charles |année=1994 |lire en ligne=ftp://ftp.cs.man.ac.uk/pub/apt/theses/npaver_phd.pdf |id=asyncproc |commentaire=Thèse présentée en 1994 en vue de l'obtention d'un doctorat de l'[[université de Manchester]]}}
* {{pdf}} {{ouvrage |prénom1=Charlie |nom1=Brej |titre=Asynchronous Early Output and Early Acknowledge Dual-Rail Protocols |année=2002 |mois=octobre |langue=en |lire en ligne=http://brej.org/papers/mphil.pdf |id=Brej2002 |commentaire=Thèse présentée en 2002 en vue de l'obtention d'un doctorat de l'[[université de Manchester]] }}
* {{pdf}} {{ouvrage |prénom1=Charlie |nom1=Brej |titre=Early Output Logic and Anti-Tokens |année=2005 |mois=septembre |langue=en |lire en ligne=http://brej.org/papers/thesis.pdf |id=Brej2005 |commentaire=Thèse présentée en 2005 en vue de l'obtention d'un doctorat de l'[[université de Manchester]]}}
* {{pdf}} {{ouvrage|titre=Comparative study of asynchronous pipeline design methods|jour=26|mois=janvier|année=2006|langue=en|prénom1=K.|nom1=Shojaee|prénom2=M.|nom2=Gholipour|prénom3=A.|nom3=|prénom4=M.|nom4=Nourani|id=pipelinecomp|lire en ligne=http://www.jstage.jst.go.jp/article/elex/3/8/163/_pdf|commentaire=Simulation des performances de divers pipelines asynchrones, publiée dans ''IEICE Electronics Express'', volume 3, en Avril 2006}}
{{Portail|électronique}}

[[Catégorie:Électronique numérique]]

[[de:Asynchroner Schaltkreis]]
[[en:Asynchronous circuit]]
[[fi:Asynkroninen piiri]]
[[ko:비동기 회로]]
[[ru:Асинхронная логика]]
[[zh:非同步電路]]