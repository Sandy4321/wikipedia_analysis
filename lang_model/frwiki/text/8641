{{Voir homonymes|Automatic}}
L’'''automatique''' fait partie des [[sciences de l'ingénieur]]. Il s’agit de la science des systèmes. Plus précisément, cette discipline traite de la modélisation, de l’analyse, de l’identification et de la commande des systèmes dynamiques. Elle inclut donc la [[cybernétique]] au sens étymologique du terme, et a pour fondements théoriques les [[mathématiques]], la [[théorie du signal]] et l’[[informatique théorique]]. L’automatique permet de contrôler un système en respectant un cahier des charges (rapidité, dépassement, stabilité …).

Les hommes de l’art en automatique se nomment [[automaticien]]s.

Un exemple simple est celui du régulateur de vitesse d’une automobile, il permet de maintenir le véhicule à une vitesse constante prédéterminée par le conducteur, indépendamment des perturbations (pente de la route, résistance du vent...).

L’automatique est une science de l’ingénieur, et n’est pas à confondre avec les [[automatisme (organe)|automatismes]], qui sont les objets que l’automatique permet de concevoir pour procéder à l'automatisation d'un système (automates, régulateurs, etc.).

== Histoire de l'automatique ==

La préhistoire de l’automatique remonte au moins à l’époque romaine. Les Romains, en effet, régulaient le niveau d’eau des aqueducs grâce à un système de valves. Au dix-septième siècle, Dutch, [[Christian Huygens| Huygens]] et [[Robert Hooke|Hooke]] ont pu analyser le problème de contrôle de vitesse grâce à un système d'horloges. Le [[régulateur à boules]] de Watt (datant de 1769) compte parmi les premiers régulateurs. Parmi d’autres pionniers de l’automatique, il convient d’évoquer l’astronome [[George Biddell Airy|Airy]] (vers 1840) et, bien entendu, les mathématiciens [[Adolf Hurwitz|Hurwitz]] et [[Edward Routh|Routh]] (auteurs du [[Polynôme de Hurwitz|critère de stabilité qui porte leur nom]], datant de la fin du dix-neuvième siècle) ainsi que [[Aleksandr Lyapunov|Lyapunov]], qui présente en 1892 sa thèse fondamentale sur la stabilité des équations différentielles.
Puis commence ce qu’on peut cette fois appeler l’histoire de l’automatique, avec les fameux chercheurs des [[laboratoires Bell]] (fondés en 1925): [[Harold Stephen Black|Black]] et Nichols, qui ont conçu leur  [[Diagramme de Black|célèbre diagramme]], [[Harry Nyquist|Nyquist]] qui, le premier sans doute, a compris le problème de stabilité que posent les systèmes bouclés<ref>H. Nyquist, ''Regeneration Theory'', Bell Syst. Tech. J., 11, 126-147, 1932</ref>, enfin et surtout [[Hendrik Wade Bode|Bode]]. Ce dernier est très connu par son [[Diagramme de Bode|diagramme]], mais son œuvre maîtresse est son livre ''Network Analysis and Feedback Amplifier Designer''<ref>{{harvsp|Bode|1975}}</ref>, édité juste après la seconde guerre mondiale (et réédité depuis), qui marque la maturité de l’automatique fréquentielle.
Il faut mentionner aussi les pionniers de l’automatique à temps discret : l’Américain [[Claude Shannon|Shannon]], lui aussi chercheur aux [[laboratoires Bell]], le Russe [[leonid Tsypkin|Tsypkin]], Jury enfin, auteur du critère correspondant à celui de Routh-Hurwitz mais pour les systèmes à temps discret. Une découverte fondamentale est le [[Théorème d'échantillonnage de Nyquist-Shannon|théorème de l'échantillonnage]], attribué par de nombreux auteurs à Nyquist et Shannon, mais auquel il faut aussi associer, entre autres [[Edmund Taylor Whittaker|Whittaker]] et {{Lien  |fr   = Kotelnikov  |lang = en | trad = Vladimir Kotelnikov}}.
Dans les années 1950, d’autres approches de l’automatique se préparent : en Russie avec [[Lev Pontriaguine|Pontryagin]] et ses collaborateurs, aux États-Unis avec [[Richard Bellman|Bellman]]. Pontryagin conçoit le Principe du Maximum pour la commande optimale. Il s’agit d’une extension du [[Calcul des variations]], avec « variations fortes » qui permettent d’obtenir une condition de maximum à la place de l’égalité d’Euler. Bellman invente la [[programmation dynamique]], d’où il déduit l’{{Lien  |fr   = équation d’Hamilton-Jacobi-Bellman  |lang = en | trad = Hamilton–Jacobi–Bellman equation}}, généralisation de l’[[Équations de Hamilton-Jacobi|l’équation d’Hamilton-Jacobi]] du Calcul des variations.
Les découvertes qui viennent d’être évoquées jouent bien sûr un rôle essentiel dans la théorie de la commande optimale, mais elles ont également conduit à la notion de [[Représentation d'état|représentation d’état]]. C’est [[Rudolf Kalman|Kalman]] qui, en 1960, a fait la théorie (presque) complète de ces systèmes dans le cas linéaire. Il a notamment mis en évidence les notions fondamentales de [[commandabilité]] et d’[[observabilité]]. La même année (son "annus mirabilis"), il faisait la théorie de la [[commande LQ|commande optimale linéaire quadratique]] (par application des résultats de Pontryagin et de Bellman) et sa « version duale », le [[filtre de Kalman]] qui généralise le {{Lien  |fr   = filtre de Wiener  |lang = en | trad = Wiener filter}}. Puis quelques mathématiciens, dont Kushner, développent la commande optimale stochastique<ref>{{harvsp|Fleming|Rishel|1975}}</ref>.
S’ouvre alors une nouvelle ère de l’automatique, avec des travaux de nature algébrique (pour les systèmes linéaires) ou relevant de la géométrie différentielle (dans le cas des systèmes non linéaires). Un livre célèbre de Wonham, dont la première édition date de 1974 (mais qui a été plusieurs fois réédité), marque l’apogée de cette période<ref>{{harvsp|Wonham|1985}}</ref>.
Vers la fin des années 1970 est apparue la problématique de la commande robuste, qui était complètement occultée dans une approche uniquement algébrique. Nous en arrivons à la période contemporaine. Faisant partie des pionniers de la théorie de la robustesse, Doyle a montré en 1978 qu’une [[Commande LQG|commande linéaire quadratique gaussienne (LQG)]] pouvait n’avoir aucune propriété de robustesse. Le formalisme [[Hinfini|H-infini]] s’est avéré utile pour formaliser les problèmes de commande robuste<ref>{{harvsp|Zhou|Doyle|Glover|1995}}</ref>. Il a été rapidement associé à des techniques d’optimisation convexe fondées sur des [[Inégalité matricielle linéaire|« inégalités matricielles linéaires » (LMI)]] qui ont pu conduire à des méthodes de synthèse (parfois excessivement) complexes.
Enfin, depuis le début des années 1990 se développe une nouvelle approche de l’automatique linéaire, beaucoup plus générale, fondée sur la théorie des [[Module sur un anneau|modules]] (plus précisément, des {{Lien  |fr   = D-modules  |lang = en | trad = D-module}}) et l’{{Lien  |fr   = analyse algébrique  |lang = en | trad = Algebraic analysis}} (branche des mathématiques fondée sur les idées de [[Alexandre Grothendieck|Grothendieck]], puis développée par [[Mikio Satō|Satō]], {{Lien  |fr   = Kashiwara  |lang = en | trad = Masaki Kashiwara}} et, pour ce qui concerne les systèmes d'équations différentielles, [[Bernard Malgrange|Malgrange]]<ref>B. Malgrange, ''Systèmes différentiels à coefficients constants'', Séminaire Bourbaki 1962-1963</ref>). On peut évoquer ici l’approche « behaviorale » de Willems, ainsi que les travaux de [[Michel Fliess|Fliess]], d’Oberst, ainsi que de leurs divers collaborateurs et émules<ref>{{harvsp|Polderman|Willems|1998}} et {{harvsp|Bourlès|Marinescu|2011}}</ref>.

== Généralités, concepts ==

[[Fichier:Reponse echelon PID.JPG|Consigne (en noir) et réponse (en bleu) d’un système asservi avec un régulateur PID|thumb]]
On souhaite contrôler la température d’un four. La première tâche consiste à définir le ''système'' « four  ». Celui-ci possède une entrée (le courant fourni à la résistance de chauffage) et une sortie (la température à l’intérieur du four). On ''modélise'' le système sous forme d’équations, qui permettent d’exprimer les relations entre les entrées et les sorties du système, sous la forme d’une [[équation différentielle]] ou d’une [[fonction de transfert]]. On détermine aussi les conditions de ''stabilité'' du système (on ne veut pas que le four se mette à augmenter la température sans s’arrêter).

Les personnes chargées de réguler ce système ont un [[cahier des charges]] à respecter:
* la stabilité (le régulateur ne doit pas rendre le système instable),
* la poursuite (la température du four doit atteindre la température en consigne, on peut spécifier dans le cahier des charges si on a des contraintes de rapidité ou de dépassement),
* le rejet des perturbations (on ouvre la porte du four, la température descend, la température doit rejoindre la température voulue).
* Les coûts et délais de développement.

Après avoir déterminé la solution répondant le mieux aux besoins, on va synthétiser un nouveau système, le « régulateur », celui-ci aura pour entrées la '''consigne''' (c’est-à-dire la température souhaitée à l’intérieur du four) ainsi que la température réelle du four fourni par un ''capteur'' et pour sortie la commande du four, cette sortie est ainsi reliée à l’entrée du système four.

L’ensemble forme ce qu’on appelle un « système asservi ».

Le régulateur peut alors être réalisé sous forme analogique ([[circuit électronique]]) ou numérique ([[microcontrôleur]]). Il existe également des régulateurs dans le commerce qui permettent ces fonctions, où l’automaticien peut choisir la méthode de régulation, ou par exemple entrer les coefficients dans le cadre d’un régulateur Proportionnel-Intégral-Dérivé.

==Les systèmes ==
Un système est une modélisation d’un procédé en fonctionnement. Il possède une ou plusieurs entrées, et une ou plusieurs sorties.
Les entrées du système sont appelées variables exogènes, qui rassemblent les perturbations et les variables manipulées, commandes ou grandeurs de réglage. Elles sont souvent représentées de manière générique par la lettre ''u'' ou ''e''. Elles sont reliées au procédé en tant que tel par un capteur.

Les sorties du système sont appelées variables contrôlées, mesures ou grandeurs réglées. Elles sont souvent représentées de manière générique par la lettre ''y''. Le procédé est relié à la sortie du système par un actionneur.

Dans le cas d’un système échantillonné, les entrées et sortie sont à temps discret, mais le système en-lui même demeure à temps continu. Le système inclut donc un convertisseur numérique-analogique en entrée, un convertisseur analogique-numérique en sortie et une horloge permettant de fixer la fréquence d'échantillonnage.

Il existe une infinité d’exemples de systèmes : des systèmes mécaniques, des systèmes électriques ou des procédés chimiques. La représentation du système ne pourra alors se faire qu’avec de bonnes connaissances dans le domaine physique correspondant.

=== Différents systèmes ===
Les systèmes peuvent être classés en plusieurs catégories.

==== Systèmes à temps continu, à temps discret ====
* [[Système continu|Systèmes à temps continus]] : ce sont les systèmes qui existent naturellement. Pour ces systèmes, le temps <math>t</math> décrit la droite réelle.

* [[Système discret|Systèmes à temps discret]] : ce sont des systèmes pour lequel le temps <math>k</math> est une variable discrète (on se ramène généralement au cas où <math>k</math> décrit l’ensemble des nombres entiers). Sauf exception, ces systèmes n’existent pas à l’état naturel (la majorité des systèmes physiques naturels sont à temps continu), mais étant donné que la plupart des contrôleurs utilisés en automatique sont calculés par des processeurs numériques, il est parfois intéressant de modéliser le système commandé comme un système à temps discret.

* [[Systèmes à événements discrets]] : systèmes dont le fonctionnement peut être modélisé par des événements discrets. Généralement, ces systèmes sont modélisés par des [[réseaux de Petri]], ou par les [[algèbres de dioïdes]]. Des exemples sont les réseaux ferroviaires, ou le fonctionnement d’une chaîne de montage.

* [[Système hybride|Systèmes hybrides]] : systèmes dont la modélisation nécessite l’utilisation des techniques liées aux systèmes continus et aux systèmes à évènements discrets, par exemple : une [[boîte de vitesse]] de voiture.

==== Systèmes monovariables, systèmes multivariables ====
Quatre possibilités existent:
* le système a une entrée et une sortie, c’est un système monovariable ou SISO (Single Input Single Output),
* le système a plusieurs entrées et plusieurs sorties, c’est un système multivariable ou MIMO (Multiple Input Multiple Output),
* le système a une entrée et plusieurs sorties, système SIMO,
* le système a plusieurs entrées et une sortie, système MISO.
Néanmoins, ces deux derniers termes sont peu utilisés.

==== Système invariant (ou stationnaire) ====
Ce sont des systèmes dont les paramètres du modèle mathématique ne varient pas au cours du temps.

==== Systèmes linéaires ou non linéaires ====
{{Loupe|Système linéaire}}
On dit qu’un système est linéaire s'il est régit par un système d'équations différentielles linéaires.

Aucun système n’est strictement linéaire, ne serait-ce que par les saturations (butées physiques, par exemple) qu’il comporte ou encore par les phénomènes d’[[hystérésis]]. Toutefois, un système non linéaire peut être considéré comme linéaire dans une certaine plage d’utilisation. Il faut toujours garder à l’esprit que le système sur lequel on peut travailler n’est qu’un [[modèle mathématique]] de la réalité, et que par conséquent il y a une perte d’information lors du passage au modèle. Bien sûr, il incombe à l’ingénieur de juger la pertinence de son modèle vis-à-vis des objectifs fixés.

Un système peut admettre une représentation linéaire et une autre représentation non linéaire. Par exemple, un système pourra être linéaire en utilisant des coordonnées cartésiennes, et deviendra non linéaire en coordonnées polaires.

=== Représentation des systèmes linéaires invariants ===
Les automaticiens ont l’habitude de représenter graphiquement un système asservi par l’utilisation de [[schémas fonctionnels]].

==== Équation différentielle et fonction de transfert ====
{{Loupe|Fonction de transfert}}
Un système physique se décrit généralement avec des [[Équation différentielle|équations différentielles]] (par exemple le [[Lois du mouvement de Newton#Deuxième loi de Newton ou principe fondamental de la dynamique de translation|principe fondamental de la dynamique]], caractéristique d’un [[Condensateur (électricité)|condensateur]] ou d’une [[Bobine (électricité)|bobine]]…). La [[transformation de Laplace]] permet alors de passer de l’équation différentielle à une fonction de transfert, l'inverse n'étant exact que sous certaines hypothèses, car l'obtention d'une fonction de transfert suppose qu'on travaille à conditions initiales nulles.

Pour un système à temps discret on utilise la [[transformation en Z]].

Ces transformations permettent d’étudier le comportement entrée-sortie du système, mais risquent de faire apparaître des modes cachés, du fait de l’impasse faite sur les conditions initiales.

==== Représentation temporelle ====
{{Loupe|Réponse impulsionnelle|Réponse indicielle}}
On peut s’intéresser au comportement du système lorsqu’on le soumet à certains signaux comme une [[fonction δ de Dirac|impulsion de Dirac]] ou un [[fonction de Heaviside|échelon]]. On peut en déduire un certain nombre de caractéristiques du système.

==== Représentation fréquentielle ====
{{Loupe|Diagramme de Bode|Diagramme de Nyquist|Diagramme de Black}}
[[Fichier:FPBP1.png|thumb|center|600px|Diagramme de Bode d’un filtre passe-bas passif d’ordre 1. En pointillés rouges, l’approximation linéaire.]]
Le diagramme de Bode représente, sur des graphes séparés, le gain et la phase en fonction de la fréquence.

Le diagramme de Nyquist représente la partie imaginaire de la fonction de transfert en fonction de la partie réelle.

Le diagramme de Black représente le gain en fonction de la phase.

==== Représentation d’état ====
{{Loupe|Représentation d'état}}
La représentation d’état est une représentation du système faisant appel au formalisme matriciel. On s’intéresse à des variables internes aux systèmes, appelées variables d’état. On représente alors la dérivée des variables d’état en fonction d’elles-mêmes et de l’entrée, et la sortie en fonction des variables d'état et de l'entrée (ainsi qu’éventuellement de certaines dérivées de l'entrée). La représentation d’état peut se déduire de la fonction de transfert.

De cette représentation on peut déduire le comportement entrée-sortie du système mais aussi un certain nombre d’autres informations comme la [[commandabilité]] ou l’[[observabilité]]. Ces notions ne sont toutefois pas propres à la représentation d’état, car elles sont des caractéristiques intrinsèques d'un système.

La représentation d’état peut aussi représenter un système non linéaire ou instationnaire.

== Stabilité ==

Dans le cas des systèmes linéaires représentés par une [[fonction de transfert]], l’analyse des [[Pôle (mathématiques)|pôles]] permet de conclure sur la stabilité entrée-sortie du système. On rappelle que les pôles d’une fonction sont les complexes <math>p_{0}</math>, <math>p_{1}</math>... qui annulent le dénominateur.
* Dans le cas d’une fonction de transfert continue utilisant la [[transformée de Laplace]], tous les pôles doivent être à partie réelle strictement négative pour que le système soit stable.
* Dans le cas d’une fonction de transfert discrète utilisant la [[transformée en Z]], tous les pôles doivent avoir un [[Module d'un nombre complexe|module]] inférieur à 1 pour que le système soit stable.

Les pôles de la fonction de transfert sont appelés « pôles de transmission ». Si l’on prend pour le système une représentation plus complète que sa fonction de transfert, on peut définir les pôles du système. Par exemple, les pôles d'un système d’état linéaire invariant sont les [[valeur propre (synthèse)|valeurs propres]] de la matrice d’état. Le système est asymptotiquement (ou exponentiellement) stable, si, et seulement si ses pôles appartiennent au demi-plan gauche dans le cas du temps continu, et à l’intérieur du cercle unité dans le cas du temps discret. Ceci reste valable si on considère une représentation intrinsèque du système ([[Module sur un anneau|modules]] de présentation finie sur l’anneau des opérateurs différentiels à coefficients constants) et s’étend, dans une large mesure (en faisant appel à des techniques mathématiques plus complexes, comme la théorie des [[Module sur un anneau|modules]] sur un anneau non commutatif), au cas des systèmes linéaires à coefficients variant en fonction du temps.

En automatique, surtout dès qu’on aborde le cas des systèmes non linéaires, le terme « stabilité » doit être défini précisément car il existe une dizaine de sortes de stabilités différentes. On fait le plus souvent référence à la [[stabilité asymptotique]] ou la {{Lien  |fr   = stabilité exponentielle  |lang = en | trad = Exponential stability}}, ces deux termes étant synonymes dans le cas des systèmes linéaires invariants. La [[Stabilité de Lyapunov|stabilité au sens de Lyapunov]] est un concept également très important.

Dans le cas des systèmes non linéaires, la stabilité est généralement étudiée à l'aide de la [[Stabilité de Lyapunov|théorie de Lyapunov]].

== Identification ==

{{Loupe|Identification de système}}

== Commande en boucle ouverte ==
{{Article détaillé|Contrôle en boucle ouverte}}
La commande peut être calculée en boucle ouverte tel un [[automate programmable industriel]], en ne tenant pas compte des informations que recueillies en temps réel. Cela revient par exemple à conduire une voiture les yeux fermés. Néanmoins, c’est ce type de commande que l’on conçoit lorsqu’on fait de la planification de trajectoire. On ne parle pas de « système asservi » dans un tel cas.

== Asservissement ==
{{Article détaillé|Asservissement (automatique)}}

=== Système bouclé ===

La technique d’automatisation la plus répandue est le contrôle en boucle fermée. Un système est dit en boucle fermée lorsque la sortie du procédé est prise en compte pour calculer l'entrée. Généralement le contrôleur effectue une action en fonction de l’erreur entre la mesure et la consigne désirée. Le schéma classique d'un système linéaire pourvu d'un régulateur linéaire en boucle fermée est le suivant :

<center>[[Image:Schema_boucle_regulation_correcteur.JPG]]</center>

La boucle ouverte du système est composée de deux sous-systèmes : le procédé et le régulateur (ou « correcteur »). La fonction de transfert de ce système en boucle ouverte est donc :

<center><math>H_{BO}(s)=H(s) \cdot C(s)</math></center>

Avec cette architecture on peut recalculer une nouvelle fonction de transfert du système, soit la fonction de transfert en boucle fermée, à l’aide des relations entre les différentes variables :

<math> y(s)=H(s) \cdot u(s)</math><br />
<math> u(s)=C(s) \cdot e(s)</math><br />
<math> e(s)=r(s) - y(s)</math><br />

On obtient alors : <math>y(s) = \left( \frac{H(s)C(s)}{1 + H(s)C(s)} \right) r(s)</math>

La fonction <math> H_{BF}(s) = \frac{H(s)C(s)}{1 + H(s)C(s)} </math> représente la fonction de transfert en boucle fermée. On peut remarquer que pour les systèmes à retour unitaire<math>H_{BF}(s) = \frac{H_{BO}(s)}{1+ H_{BO}(s)} </math> : c’est la formule de Black qui permet de passer d’une fonction de transfert en boucle ouverte (à retour unitaire) à une fonction de transfert en boucle fermée.

Remarques :

* La boucle de retour est le chemin qui part de la sortie et qui revient au comparateur avec le signe "moins". Dans cette boucle, il y a généralement un bloc représentant, dans la plus grande majorité des cas, un capteur. Si ce bloc a comme fonction de transfert "1" (ce qui équivaut à une absence de bloc car la multiplication par 1 ne change rien), on dit que le schéma-bloc est à retour unitaire. La formule précédemment énoncée n'est valable que si le schéma-bloc est à retour unitaire.

*Quel que soit le schéma-bloc (unitaire ou non, avec ou sans perturbation, ...), le dénominateur de la fonction de transfert en boucle fermée est toujours (sauf cas de simplifications pôles/zéros, sources de modes cachés) le numérateur de la fraction rationnelle : <math> 1+ H_{BO}(s)</math>, <math> H_{BO}(s) </math> désignant la fonction de transfert en boucle ouverte c'est-à-dire le produit de tous les blocs de la boucle, y compris ceux de la boucle de retour.

 
L'étude de cette fonction de transfert en boucle fermée  <math>H_{BF}(s)</math> est un des éléments qui permettent l'analyse fréquentielle et temporelle du système bouclé. Il convient d'étudier également la fonction de sensibilité <math> S(s) = \frac{1}{1 + H(s)C(s)} </math> et (notamment pour les questions de stabilité) les deux autres fonctions de transfert <math> C(s)S(s) </math> et  <math> H(s)S(s) </math>.

Le système bouclé est stable si aucune des quatre fonctions de transfert ci-dessus n'a de pôles dans le demi-plan droit fermé (c'est-à-dire axe imaginaire inclus). La stabilité du système bouclé peut s'étudier à partir de la fonction de transfert de la boucle ouverte <math> H_{BO}(s)</math>, ainsi que des pôles de <math> C(s) </math> et de <math> H(s) </math>, grâce au {{Lien  |fr   = Critère de Nyquist  |lang = en | trad = Nyquist stability criterion}}.

=== Exemple de boucle de régulation ===
Reprenons l’exemple du moteur automobile.

On le commande en choisissant l’ouverture du papillon des gaz intégré au système d’injection du moteur. L’ouverture est directement liée à la force appliquée sur le piston donc à l’accélération du véhicule. Disons qu’elles sont proportionnelles (on néglige les pertes et la résistance de l’air sur le véhicule).

On veut maintenir une certaine vitesse, 90 km/h par exemple. Dans ce cas, 90 km/h est la consigne, il faut la comparer à la vitesse réelle donnée par un tachymètre. La différence donne la variation de vitesse à réaliser. On en déduit l’accélération à demander au véhicule. Connaissant le rapport entre l’accélération et l’ouverture du papillon, on calcule l’ouverture à donner au papillon pour s’approcher de la vitesse de consigne. Le compteur de vitesse prend alors la nouvelle valeur de la vitesse pour réitérer l’opération. De cette manière, lorsqu’on approche de la vitesse voulue, l’accélération diminue jusqu’à s’annuler sans brutalité. 

On obtient donc ce schéma.

[[Image:regul_moteur_ess.png]]

En réalité, à cause des pertes, il faut maintenir une certaine accélération entre autres pour lutter contre la résistance de l’air.

=== Les différentes techniques ===
Il existe différentes techniques pour synthétiser les régulateurs. La technique industrielle la plus largement utilisée est le [[régulateur PID]] qui calcule une action Proportionnelle, Intégrale et Dérivée en fonction de l’erreur consigne/mesure. Cette technique permet de satisfaire la régulation de plus de 90% des procédés industriels. La {{Lien  |fr   = commande à modèle interne  |lang = en | trad = Internal model}}, généralisation des régulateurs PI ou PID avec {{Lien  |fr   = prédicteur de Smith  |lang = en | trad = Smith predictor}}, offre beaucoup plus de possibilités et est également répandue<ref>{{harvsp|Morari|Zafiriou|1989}}</ref>.

Des techniques avancées se basent sur la [[commande par retour d'état]] (ou [[Observateur d'état#Commande par retour d'état reconstruit par un observateur de Kalman|commande par retour d'état reconstruit par un observateur]]). On peut aussi utiliser le formalisme du [[régulateur RST]]. Ces types de commande peuvent être conçus par [[placement de pôles]] ou (pour ce qui concerne les systèmes d’état) par minimisation d’un critère quadratique: [[commande LQ]] ou [[Commande LQG|LQG]].

Autres commandes :

* La [[commande prédictive]] se basant sur l'utilisation d'un modèle dynamique du système pour anticiper son comportement futur.
* La [[commande robuste]] permettant de garantir la stabilité par rapport aux perturbations et aux erreurs de modèle. Une commande robuste peut être conçue par minimisation d'un critère (par exemple de nature [[Hinfini|H-infini]]<ref>{{harvsp|Zhou|Doyle|Glover|1995}}</ref>) ou par placement de pôles à condition que le choix des pôles du système bouclé soit judicieux. Encore faut-il souligner que pour un système multivariable, le choix des pôles du système bouclé ne détermine pas le régulateur de façon unique, et que pour un même choix de ces pôles, on peut obtenir des propriétés de robustesse fort différentes<ref>{{harvsp|Bourlès|2010|loc = §8.1.4}}</ref>. Toute commande doit être suffisamment robuste.
* La {{Lien  |fr   = commande adaptative  |lang = en | trad = Adaptive control}} qui effectue une identification en temps réel pour actualiser le modèle du système<ref>{{harvsp|Åström|Wittenmark|2008}}</ref>.
* La [[logique floue]] utilisant un [[réseau de neurones]] ou un [[système expert]].
* Les contrôleurs non linéaires utilisant la théorie de [[Stabilité de Lyapunov|Lyapunov]], les commandes linéarisantes par bouclage et difféomorphisme<ref>{{harvsp|Isidori|1995}}</ref> (en prêtant une attention toute particulière à la méthode de linéarisation de manière à obtenir une bonne robustesse) ou la {{Lien  |fr   = commande par modes glissants  |lang = en | trad = Sliding mode control}}<ref>{{harvsp|Slotine|Li|1990}}</ref>.
* La {{Lien  |fr   = commande par platitude différentielle  |lang = en | trad = Flatness (systems theory)}}<ref>{{harvsp|Ramírez|Agrawal|2004}}</ref>. (en boucle ouverte), qui permet l'inversion de modèle sans passer par l'intégration des équations différentielles, et ainsi de calculer les signaux nécessaires sur les entrées pour garantir les trajectoires voulues en sortie.

{{Autres projets|wiktionary = automatique}}
== Notes et références ==
{{Références}}

==Bibliographie==
=== Ouvrages utilisés pour la rédaction de l'article ===
* {{Ouvrage | prénom1 = Hebertt J. Sira | nom1 = Ramírez | prénom2 = Sunil Kumar | nom2 = Agrawal | titre = Differentially flat systems | éditeur = Marcel Dekker | année = 2004|  isbn=0824754700| pages=467}}
* {{Ouvrage | prénom1 = Karl Johan| nom1 = Åström | prénom2 = Björn | nom2 = Wittenmark| titre = Adaptive control | éditeur = Dover Publications  | numéro d'édition =  2 | année = 2008|  isbn=0486462781| pages=573}}
* {{Ouvrage | prénom1 = Hendrik Wade | nom1 = Bode | lien auteur1 = Hendrik Wade Bode | titre = Network analysis and feedback amplifier designer | éditeur = Huntington| année = 1975|  isbn=0882752421| pages=577}}
* {{Ouvrage | prénom1 = Henri | nom1 = Bourlès | titre = Linear Systems | éditeur = John Wiley & Sons | année = 2010|  isbn=1848211627| pages=544}}
* {{Ouvrage | prénom1 = Henri | nom1 = Bourlès| prénom2 =  Bogdan| nom2 = Marinescu| titre =Linear Time-Varying Systems: Algebraic-Analytic Approach | éditeur = Springer| année = 2011|  isbn=3642197264| pages=638}}
* {{Ouvrage | prénom1 = Wendell Helms| nom1 = Fleming  | prénom2 = Raymond W.| nom2 = Rishel | titre = Deterministic and Stochastic Optimal Control | éditeur = Springer | année = 1975 | isbn=3540901558| pages=222}}
* {{Ouvrage | prénom1 = Alberto | nom1 = Isidori | titre = Nonlinear control systems  | volume = 1  | éditeur =Birkhäuser  | numéro d'édition =  3 | année = 1995 |  isbn=3540199160| pages=549}}
* {{Ouvrage | prénom1 = Manfred | nom1 = Morari| prénom2 =  Evanghelos| nom2 = Zafiriou| titre =Robust Process Control | éditeur =  Prentice-Hall| année = 1989 | isbn=0137821530 | pages=488}}
* {{Ouvrage | prénom1 = Jan Willem| nom1 = Polderman| prénom2 = Jan C.| nom2 = Willems| titre = Introduction to Mathematical Theory: a Behavioral Approach | éditeur = Springer| année = 1998| isbn=0387982663| pages=424}}
* {{Ouvrage | prénom1 = Jean-Jacques E. | nom1 = Slotine| prénom2 = Weiping | nom2 = Li | titre = Applied nonlinear control | éditeur = Prentice Hall | année = 1990 | isbn=0130400491| pages=459}}
* {{Ouvrage | prénom1 = W. Murray | nom1 = Wonham | titre =Linear multivariable control: a geometric approach | éditeur = Springer | année = 1985 | isbn=0387960716| pages=334}}
* {{Ouvrage | prénom1 = Kemin | nom1 = Zhou | prénom2 = John Comstock | nom2 = Doyle | prénom3 = Keith  | nom3= Glover | titre = Robust and optimal control | éditeur = Prentice Hall | année = 1995 | isbn=0134565673| pages=596}}

=== Autres ouvrages sur le sujet ===

* H. Bourlès, ''Systèmes linéaires -- De la modélisation à la commande'', Hermès-Science, 2006 {{ISBN|2746213001}} 
* H.J. Kushner, ''Stochastic Stability and Control'', Academic Press, 1967 {{ISBN|0124301509}}
* H.K. Khalil, ''Nonlinear Systems'', Prentice Hall, 2003 {{ISBN|0131227408}}
* I.D. Landau, ''Identification et commande des systèmes'', Hermès-Science, 1993 {{ISBN|2866013654}}
* P. de Larminat, ''Automatique appliquée'', 2e édition, Hermès-Science, 2009 {{ISBN|2746223813}}
* P. de Larminat, ''Automatique, commande des systèmes linéaires'', Hermès-Science, 2e édition, 1995 {{ISBN|286601359X}} 
* S. Le Ballois, Pascal Codron : ''Automatique : systèmes linéaires et continus'', Dunod {{ISBN|2100497324}}
* P. Prouvost, ''Automatique Contrôle et régulation'', Dunod {{ISBN|2100547771}}

{{Palette Automatique}}
{{Portail électricité et électronique}}

[[Catégorie:Automatique]]

[[ar:هندسة التحكم]]
[[bg:Автоматичен контрол]]
[[ca:Enginyeria de control]]
[[de:Regelungstechnik]]
[[en:Control engineering]]
[[es:Ingeniería de control]]
[[fa:مهندسی کنترل]]
[[hi:नियंत्रण प्रौद्योगिकी]]
[[id:Teknik kendali]]
[[ja:制御工学]]
[[nn:Reguleringsteknikk]]
[[no:Reguleringsteknikk]]
[[pl:Automatyka]]
[[pt:Engenharia de controle e automação]]
[[ru:Теория автоматического управления]]
[[sv:Reglerteknik]]
[[vi:Điều khiển tự động]]
[[zh:自动控制]]