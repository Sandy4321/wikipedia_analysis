{{Infobox Distribution statistiques
|   name       = Binomiale
|   pmf_image   = Binomial distribution pmf.svg
|   pdf_légende = 
|   cdf_image   = Binomial distribution cdf.svg
|   cdf_légende = 
|   parameters = <math>n \geq 0</math> <br /><math>0\leq p \leq 1</math> <br /><math>q=1-p</math>
|   support    = <math>k \in \{0,\dots,n\}\!</math>
|   pmf        = <math>{n\choose k} p^k q^{n-k} \!</math>
|   cdf        = <math>I_{1-p}(n-[ k ], 1+[ k]) \!</math>
|   mean       = <math>np\!</math>
|   median     = <math>[ np]</matH> ou <math>[np]+1</math>
|   mode       = <math>[(n+1)\,p]\!</math>
|   variance   = <math>npq\!</math>
|   skewness   = <math>\frac{q-p}{\sqrt{npq} }\!</math>
|   kurtosis   = <math>3+\frac{1-6pq}{npq}\!</math>
|   entropy    = <math> \frac{1}{2} \ln \left( 2 \pi n e p q \right) + O \left( \frac{1}{n} \right) </math>
|   mgf        = <math>(q + pe^t)^n \!</math>
|   char       = <math>(q + pe^{it})^n \!</math>
}}

En [[mathématiques]], la '''loi binomiale''' de paramètres ''n'' et ''p'' est une [[loi de probabilité]] qui correspond à l'expérience suivante :
: On renouvelle ''n'' fois de manière indépendante une [[épreuve de Bernoulli]] de paramètre ''p'' (expérience aléatoire à deux issues possibles, généralement dénommées respectivement « succès » et « échec », la probabilité d'un succès étant ''p'', celle d'un échec étant ''q'' = 1 - ''p''). On compte alors le nombre de succès obtenus à l'issue des ''n'' épreuves et on appelle X la [[variable aléatoire réelle|variable aléatoire]] indiquant ce nombre de succès.

L'[[Univers (logique)|univers]] X(Ω) désigne l'ensemble des entiers naturels de 0 à ''n''.

La variable aléatoire suit une [[loi de probabilité]] définie par :

:<math>p(k) = \mathbb{P}(\mathrm{X} = k)= {n \choose k} \, p^k q^{n-k}= {n \choose k} \, p^k (1-p)^{n-k}</math>

Cette formule fait intervenir le nombre des [[Combinaison (mathématiques)|combinaisons]] de ''k'' éléments parmi ''n'', généralement noté <math>{n\choose k}</math> ou <math>\mathrm{C}_{n}^{k}</math>. Notons que ce nombre de combinaisons se distingue du nombre des [[arrangement]]s de ''k'' éléments parmi ''n'', <math>\mathrm{A}^k_n = \dfrac{n!}{(n-k)!}</math>, du fait que dans une combinaison l'ordre des éléments n'importe pas. Et comme il y a ''k!'' (prononcer [[factorielle]] ''k'') façons d'ordonner ''k'' éléments, le nombre des combinaisons se déduit du nombre des arrangements par la simple division <math>\dfrac{\mathrm{A}^k_n}{k!}\,</math> et on obtient :

:<math>{n\choose k} =\frac{n!}{k!(n-k)!}</math>

Cette loi de probabilité s'appelle la ''loi binomiale de paramètres n et p'' et se note B(''n, p'').

== Historique ==
[[File:Galton-Brett.svg|vignette|upright=0.75|alt=planche de Galton|La planche de Galton : les empilements de billes rouges correspondent à la fonction de masse de la loi binomiale, la courbe bleue correspond à la densité de la loi normale.]]
La loi binomiale fait partie des plus ancienne lois de probabilités étudiées<ref name="dodge287"/>. Elle est découverte par [[Jacques Bernoulli]] qui y fait référence en 1713 dans son ouvrage [[Ars Conjectandi]]. Entre 1708 et 1718, la [[loi multinomiale]] (généralisation multi-dimensionnelle de la loi binomiale), la [[loi binomiale négative]] ainsi que l'approximation de la loi binomiale par la [[loi de Poisson]], la [[loi des grands nombres]] pour la loi binomiale et une approximation de la [[Queue d'une loi de probabilité|queue]] de la loi binomiale sont découvertes<ref name="hald">{{Harvsp|Hald|2005|p=5}}</ref>.

Grâce à l'expression de sa fonction de masse, la loi binomiale a été utilisée par plusieurs scientifiques pour étudier des phénomènes. C'est le cas d'[[Abraham de Moivre]]<ref name="fuchs" group="a">{{Lien web|langue=fr |url=http://www-irma.u-strasbg.fr/~foata/fuchs/FuchsNormale.pdf |titre=Plaidoyer pour la loi normale |auteur=Aimé Fuchs}}</ref> qui réussit à trouver une approximation de la loi binomiale par la [[loi normale]], il publie d'abord ses résultats en 1733 en latin<ref name="hald485">{{Harvsp|Hald|2005|p=485}}</ref> : ''Approximatio ad Summam Terminorum Binomii <math>\scriptstyle(a+b)^n</math> in Seriem expansi'', puis les traduit pour les publier en 1756 dans ''Doctrine of Chances''. En 1812, [[Pierre-Simon de Laplace]] reprend ces travaux. [[Francis Galton]] crée la [[planche de Galton]] qui permet d'avoir une représentation physique de cette convergence<ref name="fuchs" group="a"/>. En 1909, [[Émile Borel]] énonce et prouve, dans le cas de la loi binomiale, la première version de la [[loi forte des grands nombres]]<ref name="hazewinkel438">{{Harvsp|Hazewinkel|1994|p=438}}</ref>.

Plus récemment, en 1914, McKendrick a démontré que la loi binomiale est la solution d'un processus simple de naissance et d'émigration<ref name="johnson109">{{Harvsp|Johnson|Kemp|Kotz|2005|p=109}}</ref>. D'après les travaux de [[William Feller]] en 1957, la loi peut aussi être vue comme la [[Probabilité stationnaire d'une chaîne de Markov#Convergence vers la loi stationnaire|loi stationnaire]] pour le [[modèle des urnes d'Ehrenfest]]. Cette même année, Haight montre que la loi binomiale est liée à un [[Théorie des files d'attente|problème de file d'attente]]<ref name="johnson109"/>.

La loi binomiale apparait dans de nombreuses applications au XXième siècle<ref name="johnson136">{{Harvsp|Johnson|Kemp|Kotz|2005|p=136}}</ref> : en [[génétique]], en [[biologie animale]], en [[écologie végétale]], pour les [[test (statistique)|tests statistiques]], dans différents modèles physiques tels que des réseaux téléphoniques<ref name="johnson140">{{Harvsp|Johnson|Kemp|Kotz|2005|p=140}}</ref> ou le [[modèle des urnes d'Ehrenfest]], etc

Le nom ''binomiale'' de cette loi provient<ref name="ruegg39"/>{{,}}<ref name="fuchs" group="a"/> de l'écriture de sa fonction de masse (voir ci-dessous) qui contient un [[coefficient binomial]] issu du développement du binôme : <math>\scriptstyle (p+q)^n</math>.

== Définition intuitive ==
La [[loi de Bernoulli]] décrit le comportement d'un évènement aléatoire qui possède deux résultats possibles. Ces deux résultats sont traditionnellement appelés ''succès'' et ''échec''<ref name="gossett310">{{Harvsp|Gossett|2009|p=310}}</ref>. Une telle expérience s'appelle une [[épreuve de Bernoulli]]. Par exemple, lors d'une lancer de [[pile ou face]], on peut considérer qu'obtenir ''face'' est un ''succès'' et obtenir ''pile'' est un ''échec''. Dans ce modèle, la probabilité de ''succès'' est une valeur fixe, c'est-à-dire qui reste constante à chaque renouvellement de l'expérience aléatoire.

On considère la situation où une telle expérience aléatoire (deux résultats possibles et une probabilité fixe) est répétée un nombre de fois de manière indépendante ; notons <math>n</math> ce nombre de fois. Cette répétition indépendante d'épreuves  de Bernoulli s'appelle un [[Épreuve de Bernoulli#Schéma de Bernoulli|schéma de Bernoulli]] ou simplement des [[épreuve de Bernoulli|épreuves de Bernoulli]]<ref name="dodge175">{{Harvsp|Dodge|2007|p=175}}</ref>. La '''loi binomiale''' décrit le nombre de fois où le ''succès'' apparait sur les <math>n</math> expériences effectuées. Le nombre de ''succès'' obtenus étant une valeur aléatoire, la loi binomiale est décrite grâce à la donnée des probabilités que le ''succès''  apparaisse précisément <math>k</math> fois sur les <math>n</math> essais.

En reprenant l'exemple du pile ou face, si on lance <matH>n=</math>cinq fois la pièce, la loi binomiale décrit les probabilités qu'il y ait 0, 1, 2, 3, 4 ou 5 ''succès''. (Ces probabilités sont détaillées dans les sections suivantes de cet article).

== Définition mathématique ==
La '''loi binomiale''' est une [[loi de probabilité#Lois discrètes|loi de probabilité discrète]]<ref name="dodge287"/> à deux paramètres : <math>\scriptstyle n\in \mathbb N^*</matH> et <math>\scriptstyle p\in[0,1]</math>. Il est fréquent d'utiliser également le paramètre <math>\scriptstyle q=1-p</math> pour avoir des expressions plus concises. Plusieurs définitions équivalentes se trouvent pour la loi binomiale.

[[file:Binomial Distribution.PNG|vignette|upright=1.5|alt=fonctions de masse de la loi binomiale| [[diagramme en bâtons|Diagrammes en bâtons]] de trois fonctions de masse de lois binomiales. Les paramètres sont <math>\scriptstyle n=20</math> et <math>\scriptstyle p=0,1</math> (en bleu), <math>\scriptstyle p=0,5</math> (en vert) et <math>\scriptstyle p=0,8</math> (en rouge).]]

{{Théorème|Définition 1<ref>{{Harvsp|Ruegg|1994|p=38}}</ref>{{,}}<ref name="gossett310"/>|La loi binomiale, de paramètres <math>\scriptstyle n</math> et <math>\scriptstyle p</math>, est la [[loi de probabilité]] d'une variable aléatoire <math>\scriptstyle X</math> égale au nombre de succès rencontrés au cours d'une répétition de <math>\scriptstyle n</math> épreuves de Bernoulli, <math>\scriptstyle p</math> étant la probabilité de ''succès'' d'une épreuve de Bernoulli.|style=display:table
}}

{{Théorème|Définition 2<ref name="bogaert50">{{Harvsp|Bogaert|2005|p=50}}</ref>|La loi binomiale, de paramètres <math>\scriptstyle n</math> et <math>\scriptstyle p</math>, est la [[loi de probabilité]] d'une variable aléatoire <math>\scriptstyle X</math> telle que :
:<math>X=Y_1+Y_2+\dots +Y_n,</math>
où <math>\scriptstyle Y_1,Y_2,\dots ,Y_n,</math> sont des [[Indépendance (probabilités)#Cas des variables discrètes|variables aléatoires indépendantes]] de [[loi de Bernoulli]] de même paramètre <math>\scriptstyle p</math>.|style=display:table
}}

{{Théorème|Définition 3<ref name="dodge287">{{Harvsp|Dodge|2007|p=287}}</ref>|La loi binomiale, de paramètres <math>\scriptstyle n</math> et <math>\scriptstyle p</math>, est la [[loi de probabilité#Lois discrètes|loi de probabilité discrète]] d'une variable aléatoire <math>\scriptstyle X</math> dont la [[Fonction de masse (probabilités)|fonction de masse]] est donnée par :
:<math>p_k=\mathbb P(X=k)={n\choose k}p^kq^{n-k}</math> pour <math>\scriptstyle k=0,1,\dots ,n</math>.|style=display:table
}}

La fonction de masse donnée dans la définition 3 a bien un sens puisque la [[formule du binôme de Newton]] donne<ref name="gossett316">{{Harvsp|Gossett|2009|p=316}}</ref> : <math>\scriptstyle \sum_{k=0}^n p_k=\sum_{k=0}^n{n\choose k}p^kq^{n-k}=(p+1-p)^n=1</math>. La définition 2 est l'écriture mathématique de la définition 1<ref name="ruegg39">{{Harvsp|Ruegg|1994|p=39}}</ref>. 

La définition 3 est équivalente des deux autres : on calcule explicitement la probabilité que <math>\scriptstyle k</math> succès apparaissent dans <math>\scriptstyle n</math> essais. Puisque les <math>\scriptstyle n</math> répétitions sont indépendantes, la probabilité d'obtenir <math>\scriptstyle k</math> succès et donc <math>\scriptstyle n-k</math> échecs est : <math>\scriptstyle p^k(1-p)^{n-k}</math>, dans le cas où on ne tient pas compte de la place des résultats<ref name="bogaert50" />{{,}}<ref name="gossett311">{{Harvsp|Gossett|2009|p=311}}</ref>. Il suffit alors de s'intéresser à la place des <math>\scriptstyle k</math> succès et <math>\scriptstyle n-k</math> échecs. C'est-à-dire, combien y a-t-il de manière de placer <math>\scriptstyle k</math> succès parmi <math>\scriptstyle n</math> résultats (sans s'occuper de l'ordre entre les succès) ? C'est le nombre de combinaisons de <math>\scriptstyle k</math> éléments parmi <math>\scriptstyle n</math> éléments<ref>{{Harvsp|Bogaert|2005|p=305}}</ref> donné par le [[coefficient binomial]] : <math>\scriptstyle {n\choose k}</math>. On retrouve alors la fonction de masse de la définition 3.

;Notation
Un variable aléatoire <math>\scriptstyle X</math> qui suit une loi binomiale de paramètres <math>\scriptstyle n</math> et <math>\scriptstyle p</math> est notée<ref name="dodge287"/>{{,}}<ref name="bogaert50"/> : <math>\scriptstyle X\sim b(n,p)</math> ; <math>\scriptstyle X\sim B(n,p)</math> ou <math>\scriptstyle X\sim Bi(n,p)</math>.

;Mesure de probabilité
Puisque la loi binomiale <math>\scriptstyle b(n,p)</math> est une loi discrète, il est possible de la définir grâce à sa [[mesure de probabilité]]<ref name="foata68">{{Harvsp|Foata|Fuchs|Ranchi|2012|p=68}}</ref> :
:<math>\mathbb P = \sum_{k=0}^n {n\choose k}p^kq^{n-k}\delta_k</math> , où <math>\scriptstyle \delta_k</math> est la [[mesure de Dirac]] au point <math>\scriptstyle k</math>.

== Représentation sous la forme d'un arbre ==
{{article détaillé|Arbre de probabilité}}
[[Fichier:Arbre binaire loi binomiale.svg|vignette|Représentation de la loi binomiale sous forme d'un arbre.]]
Puisque la loi binomiale est une suite d'épreuves de Bernoulli, il est possible de la représenter grâce à un [[arbre de probabilité]] : chaque nœud représente une épreuve de Bernoulli, les succès et échecs sont représentés par une branche gauche et une branche droite. Le graphique est donc un [[arbre binaire]] équilibré. Un arbre contenant <math>\scriptstyle n</math> générations correspond à une loi binomiale <math>\scriptstyle b(n,p)</math>.

Si on indique les résultats de chaque épreuve de Bernoulli sur les arêtes de l'arbre, il est possible de visualiser les différentes issues de la loi binomiale<ref name="gossett274">{{Harvsp|Gossett|2009|p=274}}</ref>. Si ce sont les valeurs des probabilités qui sont indiquées sur les arêtes, il est possible de récupérer les probabilités de la loi binomiale<ref name="ruegg23">{{Harvsp|Ruegg|1994|p=23}}</ref> (voir le graphique ci-contre). 

Le graphique est un arbre de probabilité pour lune loi binomiale de paramètre <math>\scriptstyle n = 3</math>. Sur chaque branche, sont indiquées sont les probabilités des différentes issues. Au bout des branches de l'arbre, apparait les probabilités de chaque issue de la loi binomiale <math>\scriptstyle b(3,p)</math>. C'est-à-dire pour les valeurs <math>\scriptstyle k=0, 1, 2</math> ou <math>\scriptstyle 3</matH>, on obtient <math>\scriptstyle \mathbb P(X=0)=q^3</math>, <math>\scriptstyle \mathbb P(X=1)=3pq^2</math>, <math>\scriptstyle \mathbb P(X=2)=3qp^2</math> et <math>\scriptstyle \mathbb P(X=3)=p^3</math>. On retrouve les différents [[Coefficient binomial|coefficients binomiaux]] : <math>\scriptstyle {3 \choose 0} = 1 \text{ ; } {3 \choose 1} = 3 \text{ ; } {3 \choose 2} = 3 \text{ ; } {3 \choose 3} = 1 \text{.}</math>

== Propriétés ==
=== Moments ===
Les moments suivants sont les moments d'une variable aléatoire <math>\scriptstyle X</math> de loi binomiale<ref name="hazewinkel"/>{{,}}<ref name="johnson110">{{Harvsp|Johnson|Kemp|Kotz|2005|p=110}}</ref> <math>\scriptstyle b(n,p)</math> :
* <math>\mu'_1=\mathbb E(X)=np</math> , ([[Espérance mathématique|espérance]]),
* <math>\mu'_2=\mathbb E(X^2)=np+n(n-1)p^2</math>,
* <math>\mu'_3=\mathbb E(X^3)=np+3n(n-1)p^2+n(n-1)(n-2)p^3</math>,
* <math>\mu'_r=\mathbb E(X^r)=\frac{n!}{(n-r)!}p^k\sum_{k=0}^r S(r,k)</math>,
La formule suivante est une [[Suite définie par récurrence|formule de récurrence]] qui permet obtenir les moments : <math>\mu'_{r+1}=pq\left(\frac{n}{q}\mu'_r+\frac{d\mu'_r}{dp}\right)</math>.
* Les moments inverses, c'est-à-dire <math>\scriptstyle \mathbb E( X^{-r})</math>, sont infinis<ref name="johnson111"/>.

;Moments centrés<ref name="johnson110"/>
* <math>\mu_2 = Var(X) = \mathbb E\left((X-np)^2\right)=bp(1-p)=npq</math> , ([[Variance (statistiques et probabilités)|variance]]),
*:cette formule donne l'[[écart type]]<ref name="courtin1G17">{{Harvsp|Courtin|2012|p=1G17}}</ref> : <math>\sigma_{X} = \sqrt{np(1-p)}</math>.
* <math>\mu_3 = \mathbb E\left((X-np)^3\right)=np(1-p)(1-2p)=npq(q-p)</math>.
En 1923, Romanovsky donne une [[Suite définie par récurrence|formule de récurrence]] pour obtenir les moments centrés : <math>\mu_{r+1}=pq\left(nr\mu_{r-1}+\frac{d\mu_r}{dp}\right)</math>.

En 1943, Kendall obtient une formule grâce à la fonction de répartition : <math>\mu_{r}=npq\sum_{k=0}^{r-2}{r-1\choose k}\mu_k - p\sum_{k=0}^{r-2}{r-1\choose k}\mu_{k+1}</math>.

;Déviation moyenne
:La déviation moyenne est donnée par<ref name="johnson111">{{Harvsp|Johnson|Kemp|Kotz|2005|p=111}}</ref> : <math> \mathbb E(|X-np|)=2n{n-1\choose [np]} p^{[np]+1}q^{n-[np]} </math>,
où <math>\scriptstyle [np]</math> est la [[Partie entière et partie fractionnaire|partie entière]] de <math>\scriptstyle np</math>. Des ordres plus élevés ont été étudiés en 1960 par Katti.

;Fréquence de succès
Grâce aux formules précédentes, on obtient les moments de la fréquence de succès<ref name="courtin1G17"/> : <math>\scriptstyle \frac{X}{n}</math> :
*moment d'ordre 1 (ou espérance) de la fréquence de succès : <math>\mathbb E\left(\frac{X}{n}\right)=p</math>,
*moment centré d'ordre 2 (ou variance) de la fréquence de succès : <math>\mathbb E\left((\frac{X}{n}-p)^2\right)=\frac{p(1-p)}{n}=\frac{pq}{n}</math>,
*:cette formule donne l'écart type de la fréquence de succès : <math>\sigma_{X/n} =\sqrt{\frac{p(1-p)}{n}}=\frac{\sqrt{pq}}{\sqrt{n}}</math>,
*moment centré d'ordre 4 de la fréquence de succès : <math>\mathbb E\left((\frac{X}{n}-p)^4\right)=\frac{pq(1-6pq)}{n^3}+3\frac{p^2q^2}{n^2}</math>.

=== Propriétés immédiates et caractérisations ===
;Valeurs descriptives de la loi
*Le [[Asymétrie (statistiques)|coefficient d'asymétrie]] d'une loi binomiale <math>\scriptstyle b(n,p)</math> est <ref name="bogaert329">{{Harvsp|Bogaert|2005|p=329}}</ref> : <math>\scriptstyle\gamma = \frac{q-p}{\sqrt{npq}}</math>. L'[[Asymétrie (statistiques)|asymétrie]] de la loi binomiale <math>\scriptstyle b(n,p)</math> est positive<ref name="johnson114">{{Harvsp|Johnson|Kemp|Kotz|2005|p=114}}</ref> si <math>\scriptstyle p<1/2</math> et négative si <math>\scriptstyle p>1/2</math>. La loi est symétrique si et seulement si <math>\scriptstyle p=1/2</math>.
*La médiane de la loi binomiale est <math>m=\scriptstyle [np]</math> ou <math>m=\scriptstyle [np]+1</math>, <math>\scriptstyle [.]</math> étant la [[Partie entière et partie fractionnaire|partie entière]]. Ces valeurs s'obtiennent grâce à la formule<ref group="a">{{article |langue=en |auteur1=Hamza K.|titre=The smallest uniform upper bound on the distance between the mean and the median of the binomial and Poisson distributions |périodique=Statist. Probab. Lett. |volume=23 |année=1995 |pages=21-25 |lire en ligne=http://www.sciencedirect.com/science/article/pii/016771529400090U# }}</ref> : <math>\scriptstyle |m-np|<\ln(2)</math> (cette borne étant optimale).

;Propriétés de stabilité
*Si <math>\scriptstyle X</math> suit une loi binomiale <math>\scriptstyle b(n,p)</math>, alors<ref name="bogaert50"/> <math>\scriptstyle  Y=n-X</math> suit une loi <math>\scriptstyle b(n,1-p)</math>. Cette symétrie donne les relations suivantes pour la fonction de répartition et pour la fonction de masse<ref name="Mittag515">{{Harvsp|Mittag|Rinne|1993|p=515}}</ref>{{,}}<ref name="Mittag105"/> : <matH>\scriptstyle \mathbb P(X\leq k)=\mathbb P(Y\geq n-k)</math> et <matH>\scriptstyle \mathbb P(X = k)=\mathbb P(Y = n-k)</math>.
*Si les [[Variable aléatoire|variables aléatoires]] <math>\scriptstyle X_1</math> et <math>\scriptstyle X_2</math> sont de lois binomiales respectives <math>\scriptstyle b(n_1,p)</math> et <math>\scriptstyle b(n_2,p)</math>, alors la variable aléatoire <math>\scriptstyle X_1+X_2</math> est de loi binomiale <math>\scriptstyle b(n_1+n_2,p)</math>. Cette propriété peut s'obtenir grâce à l'expression des fonctions caractéristiques ou grâce à l'écriture sous forme de somme de variables de Bernoulli<ref name="johnson115">{{Harvsp|Johnson|Kemp|Kotz|2005|p=115}}</ref>.

;Inégalités
*L'[[inégalité de Bienaymé-Tchebychev]] pour une variable aléatoire <math>\scriptstyle X</math> suivant la loi binomiale <math>\scriptstyle b(n,p)</math> est obtenue grâce aux moments<ref name="courtin1G17"/> :
:<math>\mathbb P\left( \left| \frac{X}{n}-p  \right|>\varepsilon \right) \leq \frac{p(1-p)}{n\varepsilon^2}</math>
*L'[[inégalité de Kolmogorov]] s'écrit pour une somme de variables aléatoires indépendantes. Pour des variables aléatoires indépendantes <math>\scriptstyle X_1,X_2,\dots,X_n</math> de [[loi de Bernoulli]], la somme <math>\scriptstyle Y_k=\sum_{i=1}^k X_i-kn</math> suit une loi binomiale <math>\scriptstyle b(k,p)</math> recentrée, l'inegalité s'écrit alors<ref name="courtin1G16">{{Harvsp|Courtin|2012|p=1G16}}</ref> : 
:<math>\mathbb P\left( \sup\left( \left| Y_k\right|\, ; \, k=1,\dots,n \right)  >\varepsilon \right) \leq \frac{np(1-p)}{\varepsilon^2}</math>

;Caractérisations
*En 1964, un cas particulier d'un théorème de Patil et Seshadri énonce<ref name="johnson135">{{Harvsp|Johnson|Kemp|Kotz|2005|p=135}}</ref> : si la [[Loi de probabilité#Loi conditionnelle|loi conditionnelle]] de <math>\scriptstyle X+Y</math> sachant <math>\scriptstyle X</math> est une [[loi hypergéométrique]] de paramètres <math>\scriptstyle m</math> et <math>\scriptstyle n</math>, alors <math>\scriptstyle X</math> et <math>\scriptstyle Y</math> suivent des lois binomiales de paramètres respectifs <math>\scriptstyle (m,\theta)</math> et <math>\scriptstyle (n,\theta)</math> où <math>\scriptstyle \theta</math> est arbitraire.
*En 1973, Kagan, Linnik et Rao donnent plusieurs caractérisations en considérant des [[Marche aléatoire|marches aléatoires]] à pas binomiaux sur un réseaux avec des [[Propriété de Markov#Temps d'arrêt|temps d'arrêt markoviens]]<ref name="johnson135"/>.
*En 1991, Ahmed démontre qu'une variable aléatoire <math>\scriptstyle X</math> suit une loi binomiale variable aléatoire <math>\scriptstyle b(n,p)</math> [[si et seulement si]]<ref name="johnson135"/> <math>\scriptstyle \mathbb E(X|X>k)=np+qkh_k</math> où <math>\scriptstyle h_k=p_k/\sum_{i=k}^np_i</math>.

=== Fonction de répartition ===
[[File:Fonction repartition binomiale.svg|thumb|Graphique de 3 fonctions de répartition de lois binomiales avec paramètres : <math>\scriptstyle n=20</math> et <math>\scriptstyle p=0.1</math> (en bleu), <math>\scriptstyle p=0.5</math> (en vert) et <math>\scriptstyle p=0.8</math> (en rouge).]]
La [[fonction de répartition]] d'une variable aléatoire <math>\scriptstyle X</math> suivant la loi binomiale <math>\scriptstyle b(n,p)</math> est donnée par<ref name="hazewinkel"/> :
:<math> F(x)=\mathbb P(X\leq x) = \begin{cases} 1 & si\; x\geq n\\ \displaystyle \sum_{k=0}^{[x]}{n\choose k} p^k(1-p)^{n-k}  & si\; 0\leq x < n\\ 0 & si \; x< 0 \end{cases} </math>
où <math>\scriptstyle [x]</math> est la [[Partie entière et partie fractionnaire|partie entière]] de <math>\scriptstyle x</math>.

Même s'il existe une expression de la fonction de répartition, son calcul n'est pas facile<ref name="johnson116">{{Harvsp|Johnson|Kemp|Kotz|2005|p=116}}</ref> dû aux coefficients binomiaux <math>\scriptstyle {n\choose k}</math>, notamment lorsque <math>\scriptstyle n</math> est grand. Il existe alors des tables de valeurs (voir [[#Valeurs de la fonction de répartition|ci-dessous]]). Des théorèmes d'approximation ont été développés<ref name="johnson116"/> pour approcher de manière théorique et calculatoire cette fonction de répartition (voir [[#Convergences et approximations|ci-dessous]]). L'expression suivante provient du lien entre la loi binomiale et la [[loi bêta]]<ref name="hazewinkel"/> (voir [[#Lien avec d'autres lois|ci-dessous]]) : pour <math>\scriptstyle 0\leq x < n</matH>
:<math> F(x)= \frac{1}{B\left( [x]+1,n-[x] \right)} \int_p^1 t^{[x]} (1-t)^{n-[x]-1} dt</math>
où <math>\scriptstyle B</math> est la [[fonction bêta]].
il est alors possible d'écrire la fonction de répartition grâce à la [[Fonction bêta#Fonction bêta incomplète|fonction bêta incomplète]]<ref name="johnson125">{{Harvsp|Johnson|Kemp|Kotz|2005|p=125}}</ref> : 
:<math> F(x)= I_{1-p}(n-[ x ], 1+[ x])</math>.


{{Démonstration/début|titre=Démonstration directe}}
Notons ''S{{ind|k}} = I{{ind|k}}'' cette égalité et démontrons-la [[Raisonnement par récurrence|par récurrence]] sur ''k'', en posant ''q'' = 1 – ''p''.

Initialisation :
:<math>I_0=n \int_0^qt^{n-1} \mathrm{d}t=q^n=S_0.</math>

Hérédité : pour 0 < ''k'' < ''n'',
:<math>S_k-S_{k-1}={n\choose k}q^{n-k}(1-q)^k=\int_0^q{n\choose k}\frac{\rm d}{{\rm d}t}\left(t^{n-k}(1-t)^k\right)~{\rm d}t=I_k-I_{k-1}.</math>
{{Démonstration/fin}}

=== Fonctions caractéristique et génératrice ===
La [[Fonction caractéristique (probabilités)|fonction caractéristique]] d'une variable aléatoire <math>\scriptstyle X</math> suivant la loi binomiale <math>\scriptstyle b(n,p)</math> est donnée par<ref name="courtin1G17"/> :
:<matH>\phi(t)=\mathbb E\left(e^{itX}\right)=\left(q+pe^{it}\right)^n</math>.

La [[fonction génératrice des moments]] d'une variable aléatoire <math>\scriptstyle X</math> suivant la loi binomiale <math>\scriptstyle b(n,p)</math> est donnée par<ref name="hazewinkel">{{Harvsp|Hazewinkel|1994|p=397}}</ref> :
:<math>M(t)=\mathbb E\left(e^{tX}\right)=\left(q+pe^t\right)^n</math>.

On déduit directement la [[Cumulant (statistiques)|fonction génératrice des cumulants]]<ref name="johnson109"/> :
:<math>\ln(M(t))=n\ln\left(q+pe^t\right)</math>,

et la [[fonction génératrice des cumulants factoriels]]<ref name="johnson109"/> :
:<math>\ln\left(\mathbb E(t^X)\right)=n\ln\left(q+pt\right)</math>.

== Lien avec d'autres lois ==
;Loi de Bernoulli
Rappelons que la loi binomiale de paramètres <math>\scriptstyle n\in \mathbb N^*</math> et <math>\scriptstyle p\in [0,1]</math> est la loi de la somme de <math>\scriptstyle n</math> variables aléatoires indépendantes de [[loi de Bernoulli]] de même paramètre <math>\scriptstyle p</math>.

Ainsi, la loi binomiale <math>\scriptstyle b(1,p)</math> est une loi de Bernoulli de paramètre <math>\scriptstyle p</math>.

C'est par cette représentation de nombre de succès et d'échecs dans une suite d'épreuves que la loi binomiale est source de nombreuses applications.

;Lois réciproques
Les lois suivantes ont un lien avec la loi binomiale grâce à leur fonctions de répartition. Lorsque le nombre de succès <matH>\scriptstyle k</math> est fixé, elles donnent la loi du nombre d'épreuves nécessaires (loi binomiale négative) ou la loi du paramètre <math>\scriptstyle p</matH> (lois bêta ou de Fisher). En ce sens, elles peuvent servir de ''lois réciproques''.

*La loi binomiale <math>\scriptstyle b(n,p)</matH> donne le nombre de succès dans une succession de <math>\scriptstyle n</matH> épreuves indépendantes. La '''[[loi binomiale négative]]''', ou loi de Pascal, <math>\scriptstyle Pa(k,p)</matH> est le nombre d'épreuves nécessaires pour obtenir <math>\scriptstyle k</matH> succès<ref name="bogaert54">{{Harvsp|Bogaert|2005|p=54}}</ref>. le terme ''négatif'' provient de l'écriture de la fonction de masse qui contient un coefficient binomial avec un terme négatif<ref group="a" name="morice"/>.
:De plus, si <math>\scriptstyle X</matH> suit une loi <math>\scriptstyle Pa(k,p)</matH> et si <math>\scriptstyle Y</matH> suit une loi <math>\scriptstyle b(n+k,p)</matH> alors<ref name="johnson218">{{Harvsp|Johnson|Kemp|Kotz|2005|p=218}}</ref>{{,}}<ref name="Mittag109">{{Harvsp|Mittag|Rinne|1993|p=109}}</ref>, pour <math>\scriptstyle k</math> entre 0 et <math>\scriptstyle n </math> : 
:<math>\mathbb P(Y\leq k)= 1-I_p(k,n+1) = \mathbb P(X\geq n) </matH>, où <math>\scriptstyle I_p</matH> est la [[Fonction bêta#Fonction bêta incomplète|fonction bêta incomplète]]. Autrement dit : la probabilité qu'il faille moins de <math>\scriptstyle n</matH> épreuves pour avoir <math>\scriptstyle k</matH> succès est égale à la probabilité qu'il y ait au moins <math>\scriptstyle k</matH> succès en <math>\scriptstyle n+k</matH> épreuves.

*Grâce au calcul de la fonction de répartition de la '''[[loi bêta]]''' donnée par la [[Fonction bêta|fonction bêta incomplète]] <math>\scriptstyle I_p</math>, on obtient<ref group="a" name="morice"/>{{,}}<ref name="Mittag105">{{Harvsp|Mittag|Rinne|1993|p=105}}</ref>, pour <math>\scriptstyle k</math> entre 0 et <math>\scriptstyle n </math> : : 
:<math>\mathbb P(Y\leq k)= 1-I_p(k+1,n-k) = \mathbb P(X \geq p)</math> où <math>\scriptstyle X</math> suit une loi bêta de paramètres <math>\scriptstyle k+1,n-k</math> et <math>\scriptstyle Y</math> suit une loi binomiale <math>\scriptstyle b(n,p)</math>.

*La loi binomiale est liée à la '''[[loi de Fisher]]''' par la propriété suivante<ref group="a" name="morice">{{article|auteur=E. Morice|titre=Quelques modèles mathématiques de durée de vie|périodique=Revue de statistique appliquée|tome=14|numéro=1|année=1966|pp=45-126|lire en ligne=http://archive.numdam.org/ARCHIVE/RSA/RSA_1966__14_1/RSA_1966__14_1_45_0/RSA_1966__14_1_45_0.pdf}}, {{p.|68}}</ref>{{,}}<ref name="Mittag116">{{Harvsp|Mittag|Rinne|1993|p=116}}</ref>: si Y suit une loi binomiale <math>\scriptstyle b(n,p)</math> alors, pour <math>\scriptstyle k</math> entre 0 et <math>\scriptstyle n </math> :
:<math>\mathbb P(Y \le k) = \mathbb P(F> \frac{\nu_2}{\nu_1}\cdot\frac{p}{1-p})</math> où <math>\scriptstyle F</math> suit une loi de Fischer de paramètres <math>\nu_1=2(k+1)\, , \, \nu_2=2(n-k)</math>.
:La relation précédente permet de trouver les [[quantile]]s de la loi binomiale<ref name="Mittag116"/>.

; Autres lois
*La '''loi binomiale(doublement) tronquée''' de paramètres <math>\scriptstyle n,p,r_1</math> et <math>\scriptstyle r_2</math> est la loi binomiale <math>\scriptstyle b(n,p)</math> avec <math>\scriptstyle r_1<n-r_2</math> telle que les valeurs dans <math>\scriptstyle [0,r_1[</math> et dans <math>\scriptstyle ]n-r_2,n]</math> sont enlevées<ref name="johnson137">{{Harvsp|Johnson|Kemp|Kotz|2005|p=137}}</ref>. La [[fonction de masse (probabilités)|fonction de masse]] de cette loi est donnée par l'expression : pour <math>\scriptstyle k=r_1,\dots n-r_2</math>
:<math>\mathbb P(X=k)={n\choose k}p^kq^{n-k}/\sum_{i=r_1}^{n-r_2} {n\choose i}p^iq^{n-i}</math>.
:De la même manière il est possible de définir la loi binomiale (simplement) tronquée<ref name="johnson137"/> en omettant uniquement les valeurs entre 0 et <math>\scriptstyle r_1</math> ou entre <math>\scriptstyle n-r_2</math> et <math>\scriptstyle n</math>.

*La '''loi binomiale positive''' ou '''loi binomiale tronquée en 0''' est la loi binomiale <math>\scriptstyle b(n,p)</math> dont on retire la valeur 0. Sa fonction de masse est : <math>\scriptstyle \mathbb P(X=k)={n\choose k}\frac{p^kq^{n-k}}{1-q^n}</math>. De la même manière il est possible de définir la '''loi binomiale négative'''.

*La '''[[loi multinomiale]]''' est la généralisation multi-dimensionnelle de la loi binomiale<ref name="hazewinkel"/> dans le sens où la loi multinomiale modélise une succession d'épreuves dont chacune possède plusieurs issues, pas uniquement succès ou échec. Cette loi multidimensionnelle donne les probabilités du nombre d'apparition des différentes issues dans une succession d'épreuves indépendantes<ref group="a" name="morice"/>. 

*La fonction de masse de la '''[[loi hypergéométrique]]''' de paramètres <math>\scriptstyle A,p=1-q,n</math> est donnée par : <math>p_k=\frac{{k\choose pA}{n-A\choose qA}}{{n\choose A}}</math>. Elle correspond au nombre tirages gagnants dans une expérience de <math>\scriptstyle n</math> tirages simultanés dans une urne contenant <math>\scriptstyle A</math> boules et une proportion de <math>\scriptstyle p</math> boules gagnantes.
:Si le nombre de boules augmente, c'est-à-dire <math>\scriptstyle A</math> tend vers l'infini, et si <math>\scriptstyle p/A</math> tend vers une valeur <math>\scriptstyle p'\in [0,1]</math>, alors la loi hypergéométrique converge vers une loi binomiale<ref name="courtin1G18">{{Harvsp|Courtin|2012|p=1G18}}</ref> <math>\scriptstyle b(n,p')</math>.
:Autrement dit, si la taille de la population (<math>\scriptstyle A</math>) est grande par rapport à la taille de l'échantillon (<math>\scriptstyle n</math>), alors les tirages peuvent être convenablement représentés par une loi binomiale de paramètre <math>\scriptstyle p'</math> égal au pourcentage (<math>\scriptstyle p</math>) d'éléments ayant la caractère étudié.
:De plus, si <math>\scriptstyle X_1</math> et <math>\scriptstyle X_2</math> sont deux variables aléatoires indépendantes de loi binomiale respectives <math>\scriptstyle b(n_1,p)</math> et <math>\scriptstyle b(n_2,p)</math>, alors la loi de <math>\scriptstyle X_1</math> sachant que <math>\scriptstyle X_1+X_2=k</math> est la loi hypergéométrique de paramètres<ref name="johnson115"/> : <math>\scriptstyle k, \frac{n_1}{n_1+n_2}</math> et <math>\scriptstyle n_1+n_2</math>.

== Convergences et approximations ==
Pour de grandes valeurs de ''n'', le calcul de <math>{n \choose k} \, p^k q^{n-k}</math> devient vite pratiquement impossible, sauf si l'on cherche à calculer le logarithme de cette expression au lieu de l'expression elle-même (et à condition d'utiliser l'approximation des factorielles par la [[formule de Stirling]]). On distingue deux cas :

=== Loi des grands nombres ===
{{article détaillé|loi des grands nombres}}
La loi des grands nombres, faible ou forte s'applique à la loi binomiale en tant que somme de variables aléatoires indépendantes de loi de Bernoulli. Pour une variable <math>\scriptstyle X_n</math> de loi binomiale <math>\scriptstyle b(n,p)</math> alors<ref name="courtin1G16"/> :
:<math>\lim_{n\rightarrow +\infty} \mathbb P\left( |\frac{X_n}{n}-p|<\varepsilon\right)=1</math>, pour tout <math>\scriptstyle \varepsilon>0</math>.
Ce théorème appliqué à la loi binomiale peut s'utiliser dans le cas particulier du [[théorème de Bernoulli(probabilité)|théorème de Bernoulli]]. Considérons une situation d'une expérience aléatoire dans laquelle on compte le nombre d'issues ayant une propriété. Notons <math>\scriptstyle A</math> l'ensemble de toutes les issues ayant cette propriété et <math>\scriptstyle \#A</math> le nombre de succès dans l'expérience de <math>\scriptstyle n</math> répétitions. Si la probabilité théorique de l'évènement <math>\scriptstyle A</math> est <math>\scriptstyle p(A)</math>, alors <math>\scriptstyle \#A</math> suit une loi binomiale <math>\scriptstyle b\left(np(A),np(A)(1-p(A))\right)</math>. La loi des grands nombres annonce<ref name="courtin1G16"/> :
:<math>\lim_{n\rightarrow +\infty} \mathbb P\left( |\frac{\#A}{n}-p(A)|<\varepsilon\right)=1</math>, pour tout <math>\scriptstyle \varepsilon>0</math>.

=== Convergence vers la loi de Poisson ===
;Convergence
Considérons une loi binomiale <math>\scriptstyle b(n,p)</math> telle que les paramètres <math>\scriptstyle n</math> et <math>\scriptstyle p</math> sont liés par la formule : <math>\scriptstyle np=\lambda>0</math> où <matH>\scriptstyle \lambda</math> est fixé. Lorsque <math>\scriptstyle n</math> tend vers l'infini, et donc <math>\scriptstyle p</math> tend vers 0, alors<ref name="foata73">{{Harvsp|Foata|Fuchs|Ranchi|2012|p=73}}</ref> : <math>\scriptstyle \lim_{n\rightarrow +\infty} {n\choose k}p^kq^{n-k} = e^{-\lambda}\frac{\lambda^k}{k!}</math>. Autrement dit la probabilité qu'une variable de loi binomiale prenne la valeur <matH>\scriptstyle k</math> converge (lorsque <math>\scriptstyle n</matH> devient grand) vers la probabilité qu'une variable de [[loi de Poisson]] prenne la valeur <math>\scriptstyle k</math>. Le paramètre <math>\scriptstyle p</matH> converge alors vers 0, il correspond donc à un évènement de probabilité très faible, la loi de Poisson est alors appelée loi des évènements rares<ref name="foata73"/>. Par sommation, on obtient alors le résultat<ref name="hald215">{{Harvsp|Hald|2005|p=215}}</ref> :
:<math>\lim_{n\rightarrow +\infty}\mathbb P(X\leq x)=\lim_{n\rightarrow +\infty}\sum_{k=0}^{[x]} {n\choose k}p^kq^{n-k} =  e^{-\lambda}\sum_{k=0}^{[x]}\frac{\lambda^k}{k!}=\mathbb P(Y\leq x)</math>
où <math>\scriptstyle [\cdot]</math> est la partie entière, <math>\scriptstyle X</math> est une variable de loi binomiale et <math>\scriptstyle Y</math> de loi de Poisson <math>\scriptstyle \mathcal P(\lambda)</math>. Cette limite montre la [[convergence en loi]] de la loi binomiale (avec les conditions précédentes) vers la loi de Poisson. Une expression plus détaillée de la convergence peut être donnée par la formule<ref name="johnson121"/>{{,}}<ref name="hazewinkel"/> : <math>\scriptstyle \mathbb P(X\leq x) = e^{-\lambda}\sum_{k=0}^{[x]}\frac{\lambda^k}{k!}+\mathcal O(\frac{1}{n^2})</matH> avec <math>\scriptstyle \lambda = \frac{(2n-[x])p}{2-p}</matH> lorsque <math>\scriptstyle n</math> tend vers l'infini et <matH>\scriptstyle \mathcal O(\cdot)</matH> est le [[Comparaison asymptotique|comparateur asymptotique]].

[[File:Binomiale poisson.svg|vignette|Fonctions de masse d'une loi binomiale <math>\scriptstyle b(60\,;\,0,2)</math> (en rouge) et d'une loi de poisson <math>\scriptstyle \mathcal P(12)</math> (en bleu).]]

En 1953, [[Iouri Prokhorov]] donne une majoration de l'erreur totale d'approximation entre la fonction de répartition d'une loi binomiale <matH>\scriptstyle b(n,p)</math> et une [[loi de Poisson]] <matH>\scriptstyle \mathcal P(np)</math><ref name="johnson123">{{Harvsp|Johnson|Kemp|Kotz|2005|p=123}}</ref> : <matH>\scriptstyle  \sum_{k=0}^{+\infty}\left|{n\choose k}p^kq^{n-k}-\frac{e^{-np}(np)^k}{k!}\right| \leq \min (2np^2,3p) </matH>. Il est également possible de borner le ratio entre les deux fonctions de répartition<ref name="johnson123"/> : <math>\scriptstyle e^{np}\left(1-\frac{k}{n}\right)^k q^n  \leq  \frac{{n\choose k}p^kq^{n-k}}{e^{-np}(np)^k/k!} \leq e^{np} q^{n-k}</math>.

;Approximation
Grâce à la convergence ci-dessus, il est possible d'approcher les probabilités de la loi binomiale par la loi de Poisson. En pratique, le cas s'applique lorsque <math>\scriptstyle n</math> est grand et donc <math>\scriptstyle p</math> petit. Différentes valeurs sont proposées<ref name="johnson121">{{Harvsp|Johnson|Kemp|Kotz|2005|p=121}}</ref>{{,}}<ref name="foata73"/>{{,}}<ref name="Bogaert p348">{{Harvsp|Bogaert|2005|p=348}}</ref>{{,}}<ref name="Mittag106">{{Harvsp|Mittag|Rinne|1993|p=106}}</ref> :
*<math>\scriptstyle p<0,4</math>, lorsque <math>\scriptstyle n=3</math> (ce qui fait <math>\scriptstyle np<1,2</math>),
*<math>\scriptstyle p<0,3</math>, lorsque <math>\scriptstyle n=30</math> (ce qui fait <math>\scriptstyle np<9</math>),
*<math>\scriptstyle p<0,2</math>, lorsque <math>\scriptstyle n=300</math> (ce qui fait <math>\scriptstyle np<60</math>),
*<math>\scriptstyle 0<np<10</math>,
*<math>\scriptstyle p<0,1</math>, lorsque <math>\scriptstyle n\geq 30</math>,
*<math>\scriptstyle np\leq 10</math> et <math>\scriptstyle n\geq 1500 p</math>.
L'idée commune de toutes ces propositions est d'avoir la valeur <math>\scriptstyle np</math> stable lorsque <math>\scriptstyle n</math> est grand et <math>\scriptstyle p</math> petit.

=== Convergence vers la loi normale ===
{{article détaillé|Théorème de de Moivre-Laplace}}
[[File:De moivre-laplace.gif|vignette|alt=convergence de la loi binomiale|Illustration de la convergence de la fonction de masse de la loi binomiale vers la loi normale lorsque <math>\scriptstyle n</math> grandit.]]
;Convergence
Le théorème de de Moivre-Laplace, énoncé en 1733, montre qu'une variable aléatoire de loi binomiale, convenablement renormalisée, [[convergence en loi|converge en loi]] vers une variable aléatoire de [[loi normale]]. Ce résultat peut s'énoncer grâce aux fonctions de répartition des deux lois. Considérons variable aléatoire <math>\scriptstyle X</math> de loi binomiale <math>\scriptstyle b(n,p)</math>, la variable aléatoire <math>\scriptstyle X</math> renormalisée est la variable aléatoire centrée et réduite, c'est-à-dire : <math>\scriptstyle \frac{X-\mathbb E(X)}{\sigma_X}=\frac{X-np}{\sqrt{npq}}</math>.
Si on note <math>\scriptstyle \Phi</math> la fonction de répartition de la loi normale, alors :
:'''Théorème de de Moivre-Laplace :''' pour tout <math>\scriptstyle x\in \mathbb R</math> , <math>\lim_{n\to+\infty}\mathbb{P} \left( \frac{X- np}{\sqrt{npq}}\leq x \right) =\frac{1}{\sqrt{2\pi}}\int_{-\infty}^x e^{-\frac{t^2}{2}}dt = \Phi(x).</math>
Bien qu'[[Abraham de Moivre]] n'ait énoncé ce résultat que dans le cas d'une loi binomiale<ref name="hald492">{{Harvsp|Hald|2005|p=492}}</ref>, cette convergence est généralisée dans le cas d'autres lois, c'est le [[théorème central limite]]. Dans cette convergence permet d'approcher une loi discrète par une loi continue, il est alors utile d'ajouter un coefficient, dit ''correction de continuité'', afin d'améliorer les approximations futures (voir ci-dessous), la convergence précédente peut alors s'écrire sous forme d'[[Équivalent|équivalence]] lorsque <math>\scriptstyle n</math> tend vers l'infini<ref name="ruegg93">{{Harvsp|Ruegg|1994|p=93}}</ref> : pour tout <math>\scriptstyle a,b\in \mathbb R</math>
:<math>\mathbb P\left( a \leq X \leq b\right) \approx \mathbb P\left( \frac{a-\frac{1}{2}-np}{\sqrt{npq}} \leq \frac{X-np}{\sqrt{npq}}\leq \frac{b+\frac{1}{2}-np}{\sqrt{npq}} \right) \operatorname{\sim}_{n\rightarrow +\infty} \Phi\left(\frac{b+\frac{1}{2}-np}{\sqrt{npq}}\right) - \Phi\left(\frac{a-\frac{1}{2}-np}{\sqrt{npq}}\right)</math>.

L'erreur commise par l'approximation est estimée par l'[[inégalité de Berry-Esseen]] dont la constante est régulièrement améliorée, elle fournit une borne de la différence entre les deux fonctions de répartition lorsque <math>\scriptstyle n</math> est grand<ref name="hazewinkel369">{{Harvsp|Hazewinkel|1994|p=369}}</ref>{{,}}<ref group="a">{{article |langue=en |auteur1=Korolev Victor|auteur2=Shevtsova Irina|titre=An improvement of the Berry–Esseen inequality with applications to Poisson and mixed Poisson random sums |périodique=Scandinavian Actuarial Journal |volume=2 |année=2012 |pages=81-105 |lire en ligne=http://www.tandfonline.com/doi/abs/10.1080/03461238.2010.485370#.VD7aaRYe2EM }}</ref>, pour <math>\scriptstyle X</math> une variable aléatoire de loi binomiale <math>\scriptstyle b(n,p)</math> et <math>\scriptstyle Y</math> de loi normale <math>\scriptstyle \mathcal N(0,1)</math> de fonction de répartition notée <math>\scriptstyle \Phi</math> : <math>\scriptstyle \sup_{x\in \mathbb R}\left| \mathbb P\left( \frac{X-np}{\sqrt{npq}}\leq x \right) - \Phi(x) \right| \leq \frac{0,4748}{\sqrt{npq}}</math>. Une expression plus détaillée de la convergence peut être donnée par la formule avec correction de continuité<ref name="hazewinkel"/> : <math>\scriptstyle \mathbb P(X\leq x) = \Phi\left( \frac{x-np+1/2}{\sqrt{npq}} \right)+\mathcal O(\frac{1}{\sqrt{n}})</matH> [[Convergence uniforme|uniformément]] pour toute variable <math>\scriptstyle x</matH>, lorsque <math>\scriptstyle n</math> tend vers l'infini et où <matH>\scriptstyle \mathcal O(\cdot)</matH> est le [[Comparaison asymptotique|comparateur asymptotique]]. D'autres approximations plus fines ont été étudiées<ref name="johnson118">{{Harvsp|Johnson|Kemp|Kotz|2005|p=118}}</ref>, par exemple par [[Pierre-Simon de Laplace]] (1820), [[Iouri Prokhorov]] (1953) ou [[Peizer]] et [[Pratt(mathematicien)|Pratt]] (1968).

;Approximation
Grâce aux théorème de convergence ci-dessus, lorsque <math>\scriptstyle n</math> est grand, les probabilités de la binomiale renormalisée peuvent être approchées par les valeurs des probabilités de la loi normale. il existe plusieurs règles sur les paramètres <math>\scriptstyle n</math> et <math>\scriptstyle p</math> pour que l'approximation soit valable<ref name="johnson117">{{Harvsp|Johnson|Kemp|Kotz|2005|p=117}}</ref>{{,}}<ref name="Mittag106"/> :
*<math>\scriptstyle npq>9</math>,
*<math>\scriptstyle np>9</math> et <math>\scriptstyle p<1/2</math>.
L'influence de ces paramètres sur l'approximation a été finement étudiée dans les années 1990, par exemple<ref name="johnson117"/> : pour <math>\scriptstyle n</math> fixé, l'erreur absolue minimale est atteinte pour <math>\scriptstyle p=1/2</math> ; l'erreur absolue est inférieure à <math>\scriptstyle 0,0212/\sqrt{npq}</math>.

== Tables de la loi binomiale ==
Des tables de la [[fonction de masse (probabilités)|fonction de masse]] et de la [[fonction de répartition]] de la loi binomiale ont été publiée en 1950 par le [[National Bureau of Standards]] puis en 1955 dans ''National of the Computation Laboratory'' et par Rao et al. en 1985<ref>{{Harvsp|Dodge|2007|p=288}}</ref>.

Grâce aux relations de symétrie (voir [[#Propriétés immédiates et caractérisations|ci-dessus]]), il suffit<ref name="Mittag515"/>{{,}}<ref name="Mittag105"/> de donner des tables de valeurs pour <math>\scriptstyle p\leq 0.5</math>.

=== Valeurs de la fonction de masse ===
Les tables de valeurs suivantes<ref name="Bogaert p348" /> donnent les valeurs de la fonction de masse de la loi binomiale <math>\scriptstyle b(n,p)</math> pour différentes valeurs de <math>\scriptstyle n</math>.

:Exemples : Si <math>\scriptstyle X</math> suit une loi <math>\scriptstyle b(10\,;\,0,15)</math>, alors <math>\scriptstyle \mathbb P(X=4)\simeq 0,0401</math>. Si <math>\scriptstyle Y</math> suit une loi <math>\scriptstyle b(10\,;\,0,85)</math>, alors <math>\scriptstyle \mathbb P(Y=4)=\mathbb P(X=6)\simeq 0,0012</math>.

{{boîte déroulante début|align=left|titre=pour <math>\scriptstyle n=5</math>}}
<center>
{| class="wikitable" style="text-align:center" 
!!|<math>k / p</math> 
!| 0,05
!| 0,10
!| 0,15
!| 0,20
!| 0,25
!| 0,30
!| 0,35
!| 0,40
!| 0,50
|----
!| 0
|0,7738
|0,5905
|0,4437
|0,3277
|0,2373
|0,1681
|0,1160
|0,0778
|0,0312
|----
!| 1
|0,2036
|0,3281
|0,3915
|0,4096
|0,3955
|0,3601
|0,3124
|0,2592
|0,1562
|----
!| 2
|0,0214
|0,0729
|0,1382
|0,2048
|0,2637
|0,3087
|0,3364
|0,3456
|0,3125
|----
!| 3
|0,0011
|0,0081
|0,0244
|0,0512
|0,0879
|0,1323
|0,1811
|0,2304
|0,3105
|----
!| 4
|0,0000
|0,0005
|0,0022
|0,0064
|0,0146
|0,0283
|0,0488
|0,0768
|0,1562
|----
!| 5
|0,0000
|0,0000
|0,0001
|0,0003
|0,0010
|0,0024
|0,0053
|0,0102
|0,0312
|----
|}
</center>
{{boîte déroulante fin}}

{{boîte déroulante début|align=left|titre=pour <math>\scriptstyle n=10</math>}}
<center>
{| class="wikitable" style="text-align:center" 
!!|<math>k / p</math> 
!| 0,05
!| 0,10
!| 0,15
!| 0,20
!| 0,25
!| 0,30
!| 0,35
!| 0,40
!| 0,50
|----
!| 0
|0,5987
|0,3487
|0,1969
|0,1074
|0,0563
|0,0282
|0,0135
|0,0060
|0,0010
|----
!| 1
|0,3151
|0,3874
|0,3474
|0,2684
|0,1877
|0,1211
|0,0725
|0,0403
|0,0098
|----
!| 2
|0,0746
|0,1937
|0,2759
|0,3020
|0,2816
|0,2335
|0,1757
|0,1209
|0,0439
|----
!| 3
|0,0105
|0,0574
|0,1298
|0,2013
|0,2503
|0,2668
|0,2522
|0,2150
|0,1172
|----
!| 4
|0,0010
|0,0112
|0,0401
|0,0881
|0,1460
|0,2001
|0,2377
|0,2508
|0,2051
|----
!| 5
|0,0001
|0,0015
|0,0085
|0,0264
|0,0584
|0,1029
|0,1536
|0,2007
|0,2461
|----
!| 6
|0,0000
|0,0001
|0,0012
|0,0055
|0,0162
|0,0368
|0,0689
|0,1115
|0,2051
|----
!| 7
|0,0000
|0,0000
|0,0001
|0,0008
|0,0031
|0,0090
|0,0212
|0,0425
|0,1172
|----
!| 8
|0,0000
|0,0000
|0,0000
|0,0001
|0,0004
|0,0014
|0,0043
|0,0106
|0,0439
|----
!| 9
|0,0000
|0,0000
|0,0000
|0,0000
|0,0000
|0,0001
|0,0005
|0,0016
|0,0098
|----
!| 10
|0,0000
|0,0000
|0,0000
|0,0000
|0,0000
|0,0000
|0,0000
|0,0001
|0,0010
|----
|}
</center>
{{boîte déroulante fin}}

{{boîte déroulante début|align=left|titre=pour <math>\scriptstyle n=20</math>}}
<center>
{| class="wikitable" style="text-align:center" 
!!|<math>k / p</math> 
!| 0,05
!| 0,10
!| 0,15
!| 0,20
!| 0,25
!| 0,30
!| 0,35
!| 0,40
!| 0,50
|----
!| 0
|0,3585
|0,1216
|0,0388
|0,0115
|0,0032
|0,0008
|0,0002
|0,0000
|0,0000
|----
!| 1
|0,3774
|0,2702
|0,1368
|0,0576
|0,0211
|0,0068
|0,0020
|0,0005
|0,0000
|----
!| 2
|0,1887
|0,2852
|0,2293
|0,1369
|0,0669
|0,0278
|0,0100
|0,0031
|0,0002
|----
!| 3
|0,0596
|0,1901
|0,2428
|0,2054
|0,1339
|0,0716
|0,0323
|0,0123
|0,0011
|----
!| 4
|0,0133
|0,0898
|0,1821
|0,2182
|0,1897
|0,1304
|0,0738
|0,0350
|0,0046
|----
!| 5
|0,0022
|0,0319
|0,1028
|0,1746
|0,2023
|0,1789
|0,1272
|0,0746
|0,0148
|----
!| 6
|0,0003
|0,0089
|0,0454
|0,1091
|0,1686
|0,1916
|0,1712
|0,1244
|0,0370
|----
!| 7
|0,0000
|0,0020
|0,0160
|0,0545
|0,1124
|0,1643
|0,1844
|0,1659
|0,0739
|----
!| 8
|0,0000
|0,0004
|0,0046
|0,0222
|0,0609
|0,1144
|0,1614
|0,1797
|0,1201
|----
!| 9
|0,0000
|0,0001
|0,0011
|0,0074
|0,0271
|0,0654
|0,1158
|0,1597
|0,1602
|----
!| 10
|0,0000
|0,0000
|0,0002
|0,0020
|0,0099
|0,0308
|0,0686
|0,1171
|0,1762
|----
!| 11
|0,0000
|0,0000
|0,0000
|0,0005
|0,0030
|0,0120
|0,0336
|0,0710
|0,1602
|----
!| 12
|0,0000
|0,0000
|0,0000
|0,0001
|0,0008
|0,0039
|0,0136
|0,0355
|0,1201
|----
!| 13
|0,0000
|0,0000
|0,0000
|0,0000
|0,0002
|0,0010
|0,0045
|0,0146
|0,0739
|----
!| 14
|0,0000
|0,0000
|0,0000
|0,0000
|0,0000
|0,0002
|0,0012
|0,0049
|0,0370
|----
!| 15
|0,0000
|0,0000
|0,0000
|0,0000
|0,0000
|0,0000
|0,0003
|0,0013
|0,0148
|----
!| 16
|0,0000
|0,0000
|0,0000
|0,0000
|0,0000
|0,0000
|0,0000
|0,0003
|0,0046
|----
!| 17
|0,0000
|0,0000
|0,0000
|0,0000
|0,0000
|0,0000
|0,0000
|0,0000
|0,0011
|----
!| 18
|0,0000
|0,0000
|0,0000
|0,0000
|0,0000
|0,0000
|0,0000
|0,0000
|0,0002
|----
|}
</center>
{{boîte déroulante fin}}


=== Valeurs de la fonction de répartition ===
Les tables de valeurs suivantes<ref>{{Harvsp|Bogaert|2005|p=349}}</ref> donnent les valeurs de la fonctions de répartition de la loi binomiale <math>\scriptstyle b(n,p)</math> pour différentes valeurs de <math>\scriptstyle n</math>.

:Exemples : Si <math>\scriptstyle X</math> suit une loi <math>\scriptstyle b(10\,;\,0,15)</math>, alors <math>\scriptstyle \mathbb P(X\leq 4)\simeq 0,9901</math>. Si <math>\scriptstyle Y</math> suit une loi <math>\scriptstyle b(10\,;\,0,85)</math>, alors <math>\scriptstyle \mathbb P(Y\leq 4)=\mathbb P(X\geq 6)=1-\mathbb P(X\leq 5)\simeq 1-0,9986=0,0014</math>.

{{boîte déroulante début|align=left|titre=pour <math>\scriptstyle n=5</math>}}
<center>
{| class="wikitable" style="text-align:center" 
!!|<math>k / p</math> 
!| 0,05
!| 0,10
!| 0,15
!| 0,20
!| 0,25
!| 0,30
!| 0,35
!| 0,40
!| 0,50
|----
!| 0
|0,7738
|0,8905
|0,4437
|0,3277
|0,2373
|0,1681
|0,1160
|0,0778
|0,0312
|----
!| 1
|0,9774
|0,9185
|0,8352
|0,7373
|0,6328
|0,5282
|0,4284
|0,3370
|0,1875
|----
!| 2
|0,9988
|0,9914
|0,9734
|0,6421
|0,8965
|0,8369
|0,7648
|0,6826
|0,5000
|----
!| 3
|1,0000
|0,9995
|0,9978
|0,9933
|0,9844
|0,9692
|0,9460
|0,9130
|0,8125
|----
!| 4
|1,0000
|1,0000
|0,9999
|0,9997
|0,9990
|0,9976
|0,9947
|0,9898
|0,9688
|----
!| 5
|1,0000
|1,0000
|1,0000
|1,0000
|1,0000
|1,0000
|1,0000
|1,0000
|1,0000
|----
|}
</center>
{{boîte déroulante fin}}

{{boîte déroulante début|align=left|titre=pour <math>\scriptstyle n=10</math>}}
<center>
{| class="wikitable" style="text-align:center" 
!!|<math>k / p</math> 
!| 0,05
!| 0,10
!| 0,15
!| 0,20
!| 0,25
!| 0,30
!| 0,35
!| 0,40
!| 0,50
|----
!| 0
|0,5987
|0,3487
|0,1969
|0,1074
|0,0563
|0,0282
|0,0135
|0,0060
|0,0010
|----
!| 1
|0,9139
|0,7361
|0,5443
|0,3758
|0,2440
|0,1493
|0,0860
|0,0464
|0,0107
|----
!| 2
|0,9885
|0,9298
|0,8202
|0,6778
|0,5256
|0,3828
|0,2616
|0,1673
|0,0547
|----
!| 3
|0,9990
|0,9872
|0,9500
|0,8791
|0,7759
|0,6496
|0,5138
|0,3823
|0,1719
|----
!| 4
|0,9999
|0,9984
|0,9901
|0,9672
|0,9219
|0,8497
|0,7515
|0,6331
|0,3770
|----
!| 5
|1,0000
|0,9999
|0,9986
|0,9936
|0,9803
|0,9527
|0,9051
|0,8338
|0,6230
|----
!| 6
|1,0000
|1,0000
|0,9999
|0,9991
|0,9965
|0,9894
|0,9740
|0,9452
|0,8281
|----
!| 7
|1,0000
|1,0000
|1,0000
|0,9999
|0,9996
|0,9984
|0,9952
|0,9877
|0,9453
|----
!| 8
|1,0000
|1,0000
|1,0000
|1,0000
|1,0000
|0,9999
|0,9995
|0,9983
|0,9893
|----
!| 9
|1,0000
|1,0000
|1,0000
|1,0000
|1,0000
|1,0000
|1,0000
|0,9999
|0,9990
|----
!| 10
|1,0000
|1,0000
|1,0000
|1,0000
|1,0000
|1,0000
|1,0000
|1,0000
|1,0000
|----
|}
</center>
{{boîte déroulante fin}}

{{boîte déroulante début|align=left|titre=pour <math>\scriptstyle n=20</math>}}
<center>
{| class="wikitable" style="text-align:center" 
!!|<math>k / p</math> 
!| 0,05
!| 0,10
!| 0,15
!| 0,20
!| 0,25
!| 0,30
!| 0,35
!| 0,40
!| 0,50
|----
!| 0
|0,3585
|0,1216
|0,0388
|0,0115
|0,0032
|0,0008
|0,0002
|0,0000
|0,0000
|----
!| 1
|0,7358
|0,3817
|0,1756
|0,0692
|0,0243
|0,0076
|0,0021
|0,0005
|0,0000
|----
!| 2
|0,9245
|0,6769
|0,4049
|0,2061
|0,0913
|0,0355
|0,0121
|0,0036
|0,0002
|----
!| 3
|0,9841
|0,8670
|0,6477
|0,4114
|0,2252
|0,1071
|0,0444
|0,0160
|0,0013
|----
!| 4
|0,9974
|0,9568
|0,8298
|0,6296
|0,4148
|0,2375
|0,1182
|0,0510
|0,0059
|----
!| 5
|0,9997
|0,9887
|0,9327
|0,8042
|0,6172
|0,4164
|0,2454
|0,1256
|0,0207
|----
!| 6
|1,0000
|0,9976
|0,9781
|0,9133
|0,7858
|0,6080
|0,4166
|0,2500
|0,0577
|----
!| 7
|1,0000
|0,9996
|0,9941
|0,9679
|0,8982
|0,7723
|0,6010
|0,4159
|0,1316
|----
!| 8
|1,0000
|0,9999
|0,9987
|0,9900
|0,9591
|0,8867
|0,7624
|0,5956
|0,2517
|----
!| 9
|1,0000
|1,0000
|0,9998
|0,9974
|0,9861
|0,9520
|0,8782
|0,7553
|0,4119
|----
!| 10
|1,0000
|1,0000
|1,0000
|0,9994
|0,9961
|0,9829
|0,9468
|0,8725
|0,5881
|----
!| 11
|1,0000
|1,0000
|1,0000
|0,9999
|0,9991
|0,9949
|0,9804
|0,9435
|0,7483
|----
!| 12
|1,0000
|1,0000
|1,0000
|1,0000
|0,998
|0,9987
|0,9940
|0,9790
|0,8684
|----
!| 13
|1,0000
|1,0000
|1,0000
|1,0000
|1,0000
|0,9997
|0,9985
|0,9935
|0,9423
|----
!| 14
|1,0000
|1,0000
|1,0000
|1,0000
|1,0000
|1,0000
|0,9997
|0,9984
|0,9793
|----
!| 15
|1,0000
|1,0000
|1,0000
|1,0000
|1,0000
|1,0000
|1,0000
|0,9997
|0,9941
|----
!| 16
|1,0000
|1,0000
|1,0000
|1,0000
|1,0000
|1,0000
|1,0000
|1,0000
|0,9987
|----
!| 17
|1,0000
|1,0000
|1,0000
|1,0000
|1,0000
|1,0000
|1,0000
|1,0000
|0,9998
|----
!| 18
|1,0000
|1,0000
|1,0000
|1,0000
|1,0000
|1,0000
|1,0000
|1,0000
|1,0000
|----
|}
</center>
{{boîte déroulante fin}}

== Applications ==
Des exemples importants où la loi binomiale apparaît comme loi de la somme de [[Loi de Bernoulli#Variable de Bernoulli|variables de Bernoulli]] sont les suivants :
* l'étude des [[Loi de Bernoulli#Sondage|sondages]],
* la [[fonction de répartition empirique]],
* la [[fonction de répartition]] d'une [[Statistique d'ordre#Densité d'une statistique d'ordre|statistique d'ordre]], comme la médiane d'un échantillon, ou un quartile,
* En 1908, [[Émile Borel]] étudie la fréquence des différents chiffres dans le développement décimal d'un nombre réel. Il considère les <matH>\scriptstyle 2n</matH> premières valeurs de la décomposition décimale et estime la probabilité d'obtention du nombre de fois où apparait chaque entier dans cette décomposition grâce à l'approximation par la loi normale. Il démontre ainsi le théorème des [[nombre normal|nombres normaux]]<ref group="a">{{Article|langue=fr|prénom1=Émile|nom1=Borel|titre=Les probabilités dénombrables et leurs applications arithmétiques|périodique=Rendiconti del Circolo Matematico di Palermo|mois=décembre|année=1909 |volume=27|numéro=1|pages=247-271 |issn=0009-725X |issn2=1973-4409|doi=10.1007/BF03019651|url texte=http://www.springerlink.com/content/d82573l5k1n11722/}}</ref>.

== Notes et références ==
{{Références|colonnes=3}}

;Articles et autres sources
{{références|groupe="a"}}

== Voir aussi ==
=== Bibliographie ===
*{{ouvrage|langue=fr|prénom1=Patrick|nom1=Bogaert|titre=Probabilités pour scientifiques et ingénieurs |sous-titre= Introduction au calcul des probabilités|éditeur=De Boeck Supérieur|année=2005|pages totales=402|isbn=2-8041-4794-0|lire en ligne=http://books.google.fr/books?id=vbO_UTOW-gUC&dq=loi+binomiale+bernoulli&hl=fr&source=gbs_navlinks_s}}{{plume}}
*{{ouvrage|langue=fr|prénom1=Jean-Pierre|nom1=Courtin|titre=L'homme et les lois de la nature 1 |éditeur=Lulu.com|année=2012|pages totales=|isbn=978-1-4710-3427-5|lire en ligne=http://books.google.fr/books?id=7U2MAwAAQBAJ&hl=fr&source=gbs_navlinks_s}}{{plume}}
*{{ouvrage|langue=fr|prénom1=Yadolah|nom1=Dodge|titre=Statistique: Dictionnaire encyclopédique |éditeur=Springer Science & Business Media|année=2007|pages totales=662|isbn=978-2-10-05810-23|lire en ligne=http://books.google.fr/books?id=mc0_AAAAQBAJ&hl=fr&source=gbs_navlinks_s}}{{plume}}
*{{ouvrage|langue=fr|prénom1=Dominique|nom1=Foata|prénom2=Aimé|nom2=Fuchs|prénom3=Jacques|nom3=Ranchi|titre=Calcul des probabilités  |sous-titre = Cours, exercices et problèmes corrigés|numéro d'édition= 3 |éditeur=Dunod|année=2012|pages totales=368|isbn=978-2-287-72093-2|lire en ligne=http://books.google.fr/books?id=Lhr_casv0YcC&dq}}{{plume}}
*{{ouvrage|langue=en|prénom1=Eric|nom1=Gossett|titre=Discrete Mathematics with Proof |éditeur=John Wiley & Sons|année=2009|pages totales=904|isbn=978-0-470-45793-1|lire en ligne=http://books.google.fr/books?id=NuFeW8N2hlkC&hl=fr&source=gbs_navlinks_s}}{{plume}}
*{{ouvrage|langue=en|prénom1=Anders|nom1=Hald|titre=A History of Probability and Statistics and Their Applications before 1750 |éditeur=John Wiley & Sons |année=2005|pages totales=608|isbn=0-471-47129-1|lire en ligne=http://books.google.fr/books?id=pOQy6-qnVx8C&printsec=frontcover&hl=fr&source=gbs_ge_summary_r&cad=0#v=onepage&q&f=false}}{{plume}}
*{{ouvrage|langue=en|prénom1=Michiel |nom1=Hazewinkel|titre=Encyclopaedia of Mathematics (set) |volume = 2 |éditeur=Springer Science & Business Media|année=1994|pages totales=963|isbn=1-55608-010-7|lire en ligne=http://books.google.fr/books?id=PE1a-EIG22kC&dq}}{{plume}}
*{{ouvrage|langue=en|prénom1=Hans-Joachim |nom1=Mittag|prénom2=Horst  |nom2=Rinne|titre=Statistical Methods of Quality Assurance |éditeur=CRC Press |année=1993|pages totales=664|isbn=0-412-55980-3|lire en ligne=http://books.google.fr/books?id=b-XFrpBQ7d0C&dq=}}{{plume}}
*{{ouvrage|langue=fr|prénom1=Alan|nom1=Ruegg|titre=Probabilités et statistique |éditeur=PPUR presses polytechniques|volume=3|année=1994|pages totales=153|isbn=2-88074-286-2|lire en ligne=http://books.google.fr/books?id=PiiQruF2FWoC&hl=fr&source=gbs_navlinks_s}}{{plume}}
*{{ouvrage|langue=en|prénom1=Norman|nom1=Johnson|prénom2=Adrienne|nom2=Kemp|prénom3=Samuel|nom3=Kotz|titre=Univariate Discrete Distributions |éditeur=John Wiley & Sons|année=2005|pages totales=646|isbn=0-471-27246-9|lire en ligne=http://books.google.fr/books?id=JchiadWLnykC&printsec=frontcover&hl=fr&source=gbs_ge_summary_r&cad=0#v=onepage&q&f=false}}{{plume}}

=== Articles connexes ===

* [[Loi de Bernoulli]]
* [[Loi de Poisson]]
* [[Loi normale]]
* [[Loi multinomiale]]
* [[Probabilité]]
* [[Probabilités (mathématiques élémentaires)]]
* [[Variables aléatoires élémentaires]]
* [[Marche aléatoire]]
* [[Arbre (probabilité)#Arbre binaire uniforme]]


{{Palette|Lois de probabilités|Probabilités et statistiques}}
{{Portail|probabilités et statistiques}}

[[Catégorie:Loi de probabilité|Binomiale, Loi]]