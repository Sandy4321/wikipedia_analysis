L''''autostabilisation''', ou '''auto-stabilisation''', est la propriété d'un [[Algorithme réparti|système réparti]], composé de plusieurs [[ordinateur|machines]] capables de communiquer entre elles, qui consiste, lorsque le système est mal initialisé ou perturbé, à retourner automatiquement à un fonctionnement correct en un nombre fini d'étapes de calcul. Elle a été définie par [[Edsger Dijkstra]] en [[1974 en informatique|1974]]. Essentiellement analysée en [[informatique théorique]], l'autostabilisation vise des applications dans les domaines où l'intervention d'un humain pour rétablir le système après une défaillance est impossible ou dans lesquels il est préférable de s'en passer : les [[réseau informatique|réseaux informatiques]], les [[réseau de capteurs sans fil|réseaux de capteurs]] et les [[système critique|systèmes critiques]], tels que les [[Satellite artificiel|satellites]].

== Une application possible : les réseaux de capteurs ==
[[Image:WSN-french.svg|left|thumb|upright=1.5|Schéma de principe d'un réseau de capteurs.]]
Un [[réseau de capteurs sans fil]]<ref>{{ouvrage
| langue = en
| prénom1 = Holger
| nom1 = Karl
| prénom2 = Andreas
| nom2 = Willig
| titre = Protocols and Architectures for Wireless Sensor Networks
| éditeur = WileyBlackwell
| jour = 29
| mois = août
| année = 2007
| pages totales = 524
| isbn = 978-0470519233
}}</ref> est un ensemble de petites machines autonomes, les ''capteurs''. Chaque capteur possède un microprocesseur, une petite quantité de mémoire vive, une batterie, un émetteur-récepteur de [[Radiodiffusion|radio]] et un ou plusieurs instruments de mesure : [[thermomètre]], [[hygromètre]], etc. Le but d'un tel réseau est de rassembler automatiquement les mesures effectuées par les capteurs individuels pour en déduire un résultat global. Parmi les applications, les réseaux de capteurs peuvent être déployés dans une [[forêt]] pour avertir en cas d'incendie<ref>{{article
| langue          = en
| prénom1         = Liyang
| nom1            = Yu
| prénom2         = Neng
| nom2            = Wang
| prénom3         = Xiaoqiao
| nom3            = Meng
| titre           = Real-time forest fire detection with wireless sensor networks
| périodique      = Proceedings of the International Conference on Wireless Communications, Networking and Mobile Computing
| année           = 2005
| pages           = 1214 - 1217
}}</ref>, dans une zone de [[Guerre|conflit]] pour détecter la présence d'ennemis<ref>{{lien web |url=http://www.parapundit.com/archives/002394.html |titre=US Military Sensor Network In Iraq Invasion Performed Poorly |auteur=Randall Parker |éditeur=ParaPundit |consulté le={{date|12|janvier|2010}} }}</ref>{{,}}<ref>{{lien web |url=http://www.gizmag.com/the-soldier-helmet-that-pinpoints-enemy-snipers/11553/ |titre=The soldier helmet that pinpoints enemy snipers |auteur=David Greig |éditeur=Gizmag |consulté le={{date|12|janvier|2010}} }}</ref>, ou dans un [[biotope]] afin d'observer des animaux sans les perturber<ref>{{article
| langue          = en
| prénom1         = Jean
| nom1            = Kumagai
| titre           = Life of birds (wireless sensor network for bird study)
| périodique      = IEEE Spectrum
| volume          = 41
| numéro          = 4
| mois            = avril
| année           = 2004
| pages           = 42-49
}}</ref>. Les capteurs étant limités à des processeurs rudimentaires, leur puissance de calcul est limitée. De plus, leurs batteries sont réduites et la consommation en énergie augmente avec la portée des transmissions radio, ce qui limite la distance de leurs communications. En effet, comme les capteurs sont surtout utilisés dans les endroits difficiles d'accès, il n'est généralement pas prévu d'intervenir sur eux pour remplacer la batterie. En général, l'information en provenance des capteurs est récupérée par une station de base (schéma ci-contre) qui possède une plus grande puissance de calcul et de transmission. En règle générale, les capteurs sont ''fixes'' : on les pose à un endroit donné et ils ne peuvent pas se déplacer.

Un réseau de capteurs, pour être utile, doit être autonome. Les capteurs doivent s'échanger leurs informations et effectuer leurs traitements sans jamais nécessiter d'intervention. Or, de nombreuses perturbations du système peuvent se produire. Par exemple, un capteur peut tomber en panne, ou de nouveaux capteurs peuvent être déployés dans la zone. L'autostabilisation est une des solutions permettant de s'assurer que le réseau de capteurs récupère automatiquement de ces perturbations<ref>{{article
| langue          = en
| prénom1         = Ted
| nom1            = Herman
| titre           = Models of Self-Stabilization and Sensor Networks
| périodique      = 5th International Workshop on Distributed Computing
| année           = 2003
| pages           = 205-214
}}</ref>.

[[Image:Sun Spot.jpg|right|thumb|Capteurs [[Sun SPOT]].]]
Des algorithmes autostabilisants peuvent résoudre les problèmes de base spécifiques aux réseaux de capteurs, en particulier le [[Accès multiple à répartition dans le temps|multiplexage temporel]]<ref>{{article
| langue          = en
| prénom1         = Mahesh
| nom1            = Arumugam
| prénom2         = Sandeep S.
| nom2            = Kulkarni
| titre           = Self-stabilizing Deterministic TDMA for Sensor Networks
| périodique      = Second International Distributed Conference on Computing and Internet Technology
| année           = 2005
| pages           = 69-81
| format          = pdf
| url texte       = http://www.cse.msu.edu/~sandeep/publications/ka05IEEEPress/main.pdf
}}</ref> (les capteurs s'accordent sur des créneaux pendant lesquels un seul d'entre eux émet), la communication par ''diffusion orientée''<ref>{{article
| langue          = en
| prénom1         = Doina
| nom1            = Bein
| prénom2         = Ajoy Kumar
| nom2            = Datta
| titre           = A Self-Stabilizing Directed Diffusion Protocol for Sensor Networks
| périodique      = ICPP Workshops
| année           = 2004
| pages           = 69-76
| format          = pdf
| url texte       = http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.131.3&rep=rep1&type=pdf
}}</ref> (une méthode de [[routage]] adaptée aux réseaux de capteurs<ref>{{article
| langue          = en
| prénom1         = Chalermek
| nom1            = Intanagonwiwat
| prénom2         = Ramesh
| nom2            = Govindan
| prénom3         = Deborah
| nom3            = Estrin
| titre           = Directed diffusion: a scalable and robust communication paradigm for sensor networks
| périodique      = MOBICOM
| année           = 2000
| pages           = 56-67
}}</ref>), et le fonctionnement en dépit du fait que certains capteurs peuvent être périodiquement coupés du reste du réseau<ref>{{article
| langue          = en
| prénom1         = Ted
| nom1            = Herman
| prénom2         = Sriram V.
| nom2            = Pemmaraju
| prénom3         = Laurence
| nom3            = Pilard
| prénom4         = Morten
| nom4            = Mjelde
| titre           = Temporal Partition in Sensor Networks
| périodique      = Proceedings of the 9th International Symposium on Stabilization, Safety, and Security of Distributed Systems
| année           = 2007
| pages           = 325-339
}}</ref>. De même, des solutions autostabilisantes adaptées aux réseaux de capteurs existent pour des problèmes classiques tels que la [[coloration de graphe]]<ref name=sssensors>{{article
| langue          = en
| prénom1         = Christoph
| nom1            = Weyer
| prénom2         = Volker
| nom2            = Turau
| prénom3         = Andreas
| nom3            = Lagemann
| prénom4         = Jörg
| nom4            = Nolte
| titre           = Programming Wireless Sensor Networks in a Self-Stabilizing Style
| périodique      = Proceedings of the Third International Conference on Sensor Technologies and Applications
| année           = 2009
| pages           = 
}}</ref>, le calcul d'un [[stable maximum]]<ref name=sssensors /> ou d'un [[arbre couvrant]]<ref name=sssensors />, ou encore la [[synchronisation d'horloge]]s<ref>{{article
| langue          = en
| prénom1         = Ted
| nom1            = Herman
| prénom2         = Chen
| nom2            = Zhang
| titre           = Best Paper: Stabilizing Clock Synchronization for Wireless Sensor Networks
| périodique      = 8th International Symposium on Stabilization, Safety, and Security of Distributed Systems
| année           = 2006
| pages           = 335-349
}}</ref>.

Il existe également des réseaux de capteurs ''mobiles'', dans lesquels les capteurs sont posés sur des agents capables de se déplacer. Ceci donne une nouvelle façon d'observer des animaux sauvages sans perturber leur comportement<ref>{{lien web |url=http://www.princeton.edu/~mrm/zebranet.html |titre= The ZebraNet Wildlife Tracker |consulté le={{date|12|janvier|2010}} }}</ref>{{,}}<ref>{{article
| langue          = en
| prénom1         = Philo
| nom1            = Juang
| prénom2         = Hidekazu
| nom2            = Oki
| prénom3         = Yong
| nom3            = Wang
| prénom4         = Margaret
| nom4            = Martonosi
| prénom5         = Li-Shiuan 
| nom5            = Peh
| prénom6         = Daniel
| nom6            = Rubenstein
| titre           = Energy-Efficient Computing for Wildlife Tracking: Design Tradeoffs and Early Experiences with ZebraNet
| périodique      = Proceedings of the Tenth International Conference on Architectural Support for Programming Languages and Operating Systems
| année           = 2002
| format          = pdf
| url texte       = http://www.ee.princeton.edu/~mrm/asplos-x_annot.pdf
}}</ref> en installant les capteurs non plus dans le biotope, mais sur les animaux eux-mêmes. Les conditions nécessaires et suffisantes pour résoudre le problème du comptage autostabilisant, qui consiste à déterminer le nombre de capteurs présents dans le système, ont été établies dans ce cadre<ref>{{article
| langue          = en
| prénom1         = Joffroy
| nom1            = Beauquier
| prénom2         = Julien
| nom2            = Clément
| prénom3         = Stéphane
| nom3            = Messika
| prénom4         = Laurent
| nom4            = Rosaz
| prénom5         = Brigitte
| nom5            = Rozoy
| titre           = Self-stabilizing Counting in Mobile Sensor Networks with a Base Station
| périodique      = 21st International Symposium on Distributed Computing
| année           = 2007
| pages           = 63-76
}}</ref>{{,}}<ref>{{article
| langue          = en
| prénom1         = Joffroy
| nom1            = Beauquier
| prénom2         = Julien
| nom2            = Clément
| prénom3         = Stéphane
| nom3            = Messika
| prénom4         = Laurent
| nom4            = Rosaz
| prénom5         = Brigitte
| nom5            = Rozoy
| titre           = Self-stabilizing Counting in Mobile Sensor Networks with a Base Station
| périodique      = Proceedings of the Twenty-Sixth Annual ACM Symposium on Principles of Distributed Computing
| année           = 2007
| pages           = 396-397
}}</ref>. Cette problématique rejoint celle des ''protocoles de populations'', qui avait été formulée séparément, et qui consiste à considérer le système comme un ensemble d'[[Agent (informatique)|agents]] à mémoire très limitée qui se déplacent aléatoirement, capables de s'échanger des informations lorsqu'ils se rencontrent<ref>{{article
| langue          = en
| prénom1         = Dana
| nom1            = Angluin
| prénom2         = James
| nom2            = Aspnes
| prénom3         = Michael J.
| nom3            = Fischer
| prénom4         = Hong
| nom4            = Jiang
| titre           = Self-stabilizing population protocols
| périodique      = ACM Transactions on Autonomous and Adaptive Systems
| volume          = 3
| numéro          = 4
| année           = 2008
}}</ref>.

== Définitions ==

L'autostabilisation est définie dans le formalisme de l'[[algorithmique répartie]], dont elle est une branche. Les définitions ci-dessous se limitent à ce qui est nécessaire pour caractériser l'autostabilisation.

=== Modèle ===
Un ''système''<ref group=D>{{p.}}5-9</ref> est un ensemble de n ''processus''. Chaque processus possède des [[Variable (informatique)|variables]] dans lesquelles sont enregistrées les informations que possède le processus. La collection des variables d'un processus est son ''état''.

Deux modèles existent pour représenter les communications entre processus. Le premier modèle est à [[passage de messages]] : les processus peuvent communiquer en s'envoyant des messages via des canaux [[First in, first out|FIFO]]. Dans ce cas, l'existence ou non d'un canal entre deux processus donnés est définie par la [[Topologie de réseau|topologie du réseau]]. L'état d'un canal est défini comme la séquence des messages qu'il contient.
Le deuxième modèle est à [[mémoire partagée]]. Dans ce cas, il existe un certain nombre de registres partagés et il faut définir quels processus peuvent lire et écrire dans quels registres. L'état d'un registre est la valeur qu'il contient.
La ''configuration'' du système est la collection de l'état de tous les processus et moyens de communication.

[[Fichier:Principe de l'autostabilisation.svg|thumb|upright=1.5|alt=schéma expliquant l'autostabilisation|left|Principe de l'autostabilisation : le système, initialisé dans une configuration quelconque, finit par atteindre une configuration sûre. Toutes les configurations par lesquelles il passe ensuite sont sûres.]]

Un ''pas'' c→c' du système est défini comme l'exécution d'une transition par un processus telle que le système est au départ dans la configuration c, puis, en exécutant une action, passe dans la configuration c'. Au cours d'une transition, un processus peut recevoir un message (resp. lire un registre partagé dans le cas d'un modèle à mémoire partagée), changer d'état, et envoyer des messages (resp. écrire dans des registres partagés).

Une ''exécution'' est une suite alternée infinie de configurations et de pas : E = (c<sub>0</sub>,a<sub>1</sub>,c<sub>1</sub>,a<sub>2</sub>,c<sub>2</sub>,…) telle que pour tout i > 0, l'action a<sub>i</sub> fait passer le système de la configuration c<sub>i-1</sub> à la configuration c<sub>i</sub>. Elle est dite ''équitable'' si elle ne contient pas de séquence infinie de pas au cours de laquelle une certaine transition pourrait être exécutée, mais ne l'est jamais. En d'autres termes, dans une exécution équitable, aucun processus n'est privé de la possibilité d'effectuer une certaine transition.

=== Autostabilisation ===
Pour tout système autostabilisant, on définit un ensemble ℒ d'exécutions ''légitimes''. Cet ensemble représente les exécutions dans lesquelles le système se comporte toujours correctement. Une configuration c est dite ''sûre'' vis-à-vis de ℒ si et seulement si toute exécution commençant par c est dans ℒ. Un système est ''autostabilisant'' vers ℒ si et seulement si toute exécution de ce système, quelle que soit la configuration de départ, atteint une configuration sûre vis-à-vis de ℒ<ref group=D name=p9>{{p.}}9</ref>.

=== Propriété fondamentale ===
Un système est autostabilisant si et seulement si on peut associer à toute configuration une valeur prise dans un [[anneau noethérien]] tel que tout pas de l'exécution commençant dans une configuration non sûre de valeur v fait passer le système dans une configuration de valeur v'<v, et les valeurs les plus basses de l'anneau correspondent aux configurations sûres<ref group=D>p. 31</ref>. Cette propriété, démontrée par Gouda<ref>{{article
| langue          = en
| prénom1         = Mohamed G.
| nom1            = Gouda
| titre           = The Triumph and Tribulation of System Stabilization
| périodique      = Proceedings of the 9th International Workshop on Distributed Algorithms
| année           = 1995
| pages           = 1-18
}}</ref>, est utilisable pour démontrer qu'un algorithme est autostabilisant, de la même façon qu'elle peut servir à démontrer qu'un algorithme séquentiel [[Problème de l'arrêt|s'arrête]].

=== Mesures de complexité ===
La mesure de l'efficacité d'un [[algorithmique|algorithme]] est l'objet de la [[Théorie de la complexité des algorithmes|théorie de la complexité]]. Elle définit des méthodes permettant de calculer les performances d'un algorithme, principalement selon deux axes : le temps de calcul et la quantité de mémoire utilisée<ref>{{ouvrage
| langue = en
| prénom1 = Christos H.
| nom1 = Papadimitriou
| titre = Computational Complexity
| éditeur = Addison Wesley
| jour = 10
| mois = décembre
| année = 1993
| pages totales = 523
| isbn = 978-0201530827
}}</ref>.
Dans le cas de l'autostabilisation, on définit le ''temps de stabilisation'' comme le temps le plus élevé que le système peut mettre à atteindre une configuration sûre. Dans un système [[Asynchronisme|asynchrone]], qui ne dispose pas de notion de temps, on définit une ''ronde'' comme la plus courte séquence de pas de l'exécution au cours de laquelle chaque processus est activé au moins une fois, ce qui donne une unité dans laquelle on peut exprimer un temps de stabilisation<ref group=D name=p9/>. Les autres mesures de complexité définies dans les systèmes répartis s'appliquent aussi en autostabilisation : on peut ainsi chercher à échanger le moins possible de messages ou à utiliser un minimum de [[mémoire vive|mémoire]] sur chaque processus<ref group=D name=p11>{{p.}}11</ref>.

=== Interprétation en pratique ===
[[Image:Navstar-2.jpg|right|thumb|Satellite Navstar-2 en orbite autour de la Terre.]]
À la suite de tout incident qui change l'état du système, l'autostabilisation assure de retrouver automatiquement, après un certain temps de fonctionnement sans nouvel incident, une exécution légitime, et donc un fonctionnement correct. En particulier, cela permet de [[tolérance aux pannes|tolérer]] toute ''défaillance transitoire'', modification arbitraire de l'état d'un processus au cours d'une exécution. Une telle défaillance peut être causée, par exemple, par un [[rayon cosmique]] frappant un [[circuit intégré]]<ref>{{article
| langue          = en
| prénom1         = James F.
| nom1            = Ziegler
| lien auteur1    = 
| titre           = Terrestrial cosmic rays
| périodique      = IBM Journal of Research and Development
| lien périodique = 
| volume          = 40
| numéro          = 1
| jour            = 
| mois            = janvier
| année           = 1996
| pages           = 19-40
| issn            = 
| format          = 
| url texte       = 
| consulté le     = 
}}</ref>. Elle peut aussi être due au fonctionnement du système dans de mauvaises conditions, en particulier en cas de surchauffe ou de [[overclocking|surcadencement]]. Une défaillance transitoire laisse le système dans une configuration quelconque, totalement imprévisible. Ce retour automatique à la normale est particulièrement souhaitable dans un système sur lequel il n'est pas possible de faire intervenir un technicien<ref group=D>{{p.}}1</ref>, par exemple un satellite.

Dans la plupart des systèmes informatiques, le programme lui-même est une donnée enregistrée en mémoire vive. En conséquence, il est sujet aux défaillances transitoires, ce qui empêche l'autostabilisation. La solution est d'enregistrer le programme en [[Mémoire ROM|mémoire morte]]. Si le programme doit être chargé en mémoire vive, un [[chien de garde (informatique)|chien de garde]]<ref name=processor>{{article
| langue          = en
| prénom1         = Shlomi
| nom1            = Dolev
| lien auteur1    = 
| prénom2         = Yinnon A.
| nom2            = Haviv
| titre           = Self-Stabilizing Microprocessor: Analyzing and Overcoming Soft Errors
| périodique      = IEEE Transactions on Computers
| lien périodique = 
| volume          = 55
| numéro          = 4
| jour            = 
| mois            = 
| année           = 2006
| pages           = 385-399
| issn            = 
| format          = 
| url texte       = 
| consulté le     = 
}}</ref> peut le recharger à partir de la ROM en cas de besoin. Une autre possibilité est de réaliser directement le programme sous forme de circuit intégré.

== L'anneau à jeton de Dijkstra ==
[[Image:Edsger Wybe Dijkstra.jpg|left|thumb|Edsger Dijkstra.]]
Le concept d'autostabilisation est formulé pour la première fois par [[Edsger Dijkstra|Dijkstra]] en [[1974 en informatique|1974]]<ref group=note>Certains auteurs, par exemple Shlomi Dolev dans son livre ''Self-Stabilization'', parlent d'une précédente parution en 1973, mais elle ne figure sur aucun catalogue officiel. D'autre part, Dijkstra, dans son article de 1986 ''A Belated Proof of Self-Stabilization'', indique qu'il a publié son article fondateur en 1974.</ref> dans un article<ref name=d74>{{article
| langue          = en
| prénom1         = Edsger Wybe
| nom1            = Dijkstra
| lien auteur1    = Edsger Dijkstra
| titre           = Self-stabilizing Systems in Spite of Distributed Control
| périodique      = Communications of the ACM
| lien périodique = 
| volume          = 17
| numéro          = 11
| jour            = 
| mois            = 
| année           = 1974
| pages           = 643-644
| issn            = 
| format          = pdf
| url texte       = http://www-csag.ucsd.edu/teaching/cse291s03/Readings/p643-Dijkstra.pdf
| consulté le     = 
}}</ref> qui présente trois algorithmes autostabilisants basés sur le concept d'[[anneau à jeton]]. Le principe de l'anneau à jeton est de résoudre le problème de l'[[exclusion mutuelle]] en faisant circuler un ''jeton'', qui représente le droit pour le seul processus qui le possède d'effectuer une action qui poserait problème si plusieurs processus l'effectuaient en même temps, par exemple envoyer du texte à une [[imprimante]]<ref>{{ouvrage
| langue = en
| prénom1 = Nancy
| nom1 = Lynch
| titre = Distributed Algorithms
| éditeur = Morgan Kaufmann
| jour = 16
| mois = avril
| année = 1996
| pages totales = 904
| passage = {{p.}} 255
| isbn = 978-1558603486
}}</ref> : un processus qui veut imprimer doit d'abord attendre de recevoir le jeton, puis envoyer son texte à l'imprimante ; après quoi, il perd le jeton. Dans le cas d'un anneau à jeton autostabilisant, si le système est perturbé par l'introduction d'un ou plusieurs jetons supplémentaires, il récupère de lui-même de cette défaillance en supprimant tous les jetons présents sur l'anneau, sauf un ; puis il poursuit son exécution en passant l'unique jeton restant comme s'il n'y en avait jamais eu d'autre.

Les n processus (avec n [[Parité (arithmétique)|impair]]), numérotés de 0 à n-1, sont reliés en ''anneau'', c'est-à-dire que le processus i a comme voisin de droite i+1 [[Modulo (informatique)|modulo]] n et comme voisin de gauche i-1 modulo n. Autrement dit, le voisin de gauche du processus 0 est le processus n-1 et le voisin de droite du processus n-1 est le processus 0. Chaque processus a un ''état'' [[Entier naturel|entier]] compris entre 0 et 2. On note É l'état d'un processus, D l'état de son voisin de droite et G celui de son voisin de gauche.

L'algorithme présenté ci-dessous est le troisième de l'article, que Dijkstra considère comme le plus abouti<ref name=d74 />. Une exécution sans défaillance est donnée pour montrer comment se comporte normalement le système, puis le problème de la suppression des privilèges surnuméraires est abordé.

=== Fonctionnement avec un unique privilège ===

[[Fichier:D74-3-01.svg|thumb|alt=configuration : 1,2,2,2,2|right|Configuration initiale (1) : seul le processus 0, en rouge, a un privilège.]]

À chaque pas de l'exécution, un processus est choisi arbitrairement par un [[Ordonnancement dans les systèmes d'exploitation|ordonnanceur]]. En pratique, cet ordonnanceur dépend du matériel, du [[système d'exploitation]] et de l'environnement dans lequel il fonctionne ; son comportement est donc imprévisible. Le côté arbitraire de ce choix est à la base de la motivation initiale de Dijkstra, qui cherche à savoir si un système peut se comporter correctement ''en dépit d'un contrôle réparti''. Dans cet algorithme, seuls les processus qui ont un ''privilège'' peuvent réagir lorsqu'ils sont choisis, en changeant d'état. Les privilèges et les changements d'état associés sont définis par les règles suivantes :
# Pour le processus 0 : si (É+1) [[Modulo (informatique)|mod]] 3 = D alors É ← (É-1) mod 3
# Pour le processus n-1 : si G=D et (G+1) mod 3 ≠ É alors É ← (G+1) mod 3
# Pour tous les autres processus :
#* si (É+1) mod 3 = G alors É ← G
#* si (É+1) mod 3 = D alors É ← D

Ici, le privilège représente le fait pour un processus de posséder un jeton. Pour comprendre comment fonctionne cet algorithme lorsqu'il existe un unique privilège, considérons le cas ci-contre. Les numéros de processus sont en noir, les états en bleu. Le processus 0 a un privilège, matérialisé en rouge, en application de la règle 1. En effet, son état est 1 ; en ajoutant 1, on obtient 2, ce qui est l'état de son voisin de droite. En revanche, aucun autre processus n'a de privilège : le processus 4 parce que les états de ses voisins ne sont pas égaux, les autres processus parce qu'aucun processus n'a l'état (2+1) mod 3 = 0.

Lors du premier pas de l'exécution, c'est donc le processus 0 qui change d'état. En application de la règle 1, il prend l'état 1-1 = 0. Ceci donne un privilège au processus 1, qui change donc d'état lors du pas suivant de l'exécution. Celle-ci continue ainsi :
<gallery>
Fichier:D74-3-02.svg|Configuration (2)
Fichier:D74-3-03.svg|Configuration (3)
Fichier:D74-3-04.svg|Configuration (4)
Fichier:D74-3-05.svg|Configuration (5)
</gallery>
Dans la configuration (5), le processus 4 a le privilège. Il change donc d'état en application de la règle 2, prenant l'état 0+1=1. Ceci donne le privilège au processus 3.
<gallery>
Fichier:D74-3-06.svg|Configuration (6)
Fichier:D74-3-07.svg|Configuration (7)
Fichier:D74-3-08.svg|Configuration (8)
Fichier:D74-3-09.svg|Configuration (9)
</gallery>
Le privilège a été passé, de proche en proche, à tous les processus. La configuration (9) est équivalente à la configuration (1) ; le système est donc prêt à recommencer à passer le privilège selon le même principe. Le constat que « tout se passe bien » montre, informellement, que cette exécution est légitime.

=== Fonctionnement avec plusieurs privilèges ===
Pour comprendre comment l'algorithme garantit que le nombre de privilèges atteint forcément 1, il faut d'abord remarquer que les règles ne permettent aucune situation où il n'existerait pas de privilège. En effet, en vertu de la règle 3, dans une telle configuration, les processus dont les numéros vont de 1 à n-2 doivent tous avoir le même état e ; de plus, les processus 0 et n-1 doivent avoir soit l'état e, soit l'état (e-1) mod 3. Or, si le processus 0 a l'état (e-1) mod 3, alors il a un privilège ; si le processus n-1 a l'état (e-1) mod 3, alors il a un privilège.

La preuve de correction de cet algorithme, publiée en [[1986]]<ref name=belatedproof>{{article
| langue          = en
| prénom1         = Edsger Wybe
| nom1            = Dijkstra
| lien auteur1    = Edsger Dijkstra
| titre           = A belated proof of self-stabilization
| périodique      = Distributed Computing
| lien périodique = 
| volume          = 1
| numéro          = 1
| jour            = 
| mois            = 
| année           = 1986
| pages           = 5-6
| issn            = 
| format          = pdf
| url texte       = http://www.cs.utexas.edu/~EWD/ewd09xx/EWD922.PDF
| consulté le     = 
}}</ref>, s'appuie sur le fait que si plusieurs privilèges existent, alors leur nombre doit nécessairement diminuer. Pour cela, Dijkstra démontre qu'entre deux changements d'état du processus n-1, il se produit forcément un changement d'état du processus 0. Il prouve ensuite qu'il n'existe pas de séquence de pas infinie dans laquelle le processus 0 ne change pas d'état. Enfin, il établit la liste des scénarios possibles pour le comportement du privilège situé le plus à gauche sur l'anneau et démontre que ce privilège disparaît. Par [[Raisonnement par récurrence|récurrence]], après un certain nombre de pas, il ne reste finalement qu'un seul privilège.

<gallery>
Fichier:D74-3-collision1.svg|Premier cas de collision
Fichier:D74-3-collision2.svg|Deuxième cas de collision
</gallery>

Pour voir comment les privilèges surnuméraires disparaissent, il suffit de constater, dans l'exécution normale ci-dessus, que les privilèges circulent de la gauche vers la droite à partir du processus 0 et de la droite vers la gauche à partir du processus n-1. En conséquence, s'il y a deux privilèges sur l'anneau, ils finissent par se rencontrer. Cette situation est illustrée ci-dessus par le premier cas de collision, où ni le processus 0, ni le processus n-1 n'est impliqué. Dans ce cas, dès que l'un des processus privilégiés change d'état, il perd son privilège alors que l'autre processus garde le sien : le nombre de privilèges a diminué de 1.

Le cas de la collision des processus 0 et 1 est particulier (deuxième cas de collision ci-dessus). En effet, si 1 change d'état, son privilège change simplement de « sens », allant désormais de la gauche vers la droite. Cependant, il peut franchir le processus n-1 et doit donc disparaître. Si c'est le processus 0 qui change d'état, de façon analogue, son privilège passe au processus n-1.

Dijkstra n'aborde pas la question du temps de stabilisation de son algorithme, ni dans son article original de 1974<ref name=d74 />, ni dans l'article de 1986 dans lequel il donne la preuve de correction<ref name=belatedproof />. En 2007, une équipe sans lien avec Dijkstra démontre que cet algorithme se stabilise en O(n²) étapes<ref>{{article
| langue          = en
| prénom1         = Viacheslav
| nom1            = Chernoy
| prénom1         = Mordechai
| nom1            = Shalom
| prénom1         = Shmuel
| nom1            = Zaks
| titre           = On the Performance of Dijkstra's Third Self-stabilizing Algorithm for Mutual Exclusion.
| périodique      = Proceedings of the 9th International Symposium on Stabilization, Safety, and Security of Distributed Systems
| année           = 2007
| pages           = 114-123
| format          = pdf
| url texte       = http://132.68.32.15/people/vchernoy/online-publications/CSZ07.pdf
}}</ref>.

=== Un nouvel élan ===
[[Image:Leslie Lamport.jpg|right|thumb|Leslie Lamport.]]
Bien que l'algorithme présenté ci-dessus ait été utilisé en production<ref name=d74 />, l'article de Dijkstra passe pratiquement inaperçu jusqu'à ce que [[Leslie Lamport]], invité en [[1984 en informatique|1984]] à donner une présentation à la conférence PODC, le mentionne comme particulièrement digne d'intérêt<ref>{{article
| langue          = en
| prénom1         = Leslie
| nom1            = Lamport
| lien auteur1    = Leslie Lamport
| titre           = Solved Problems, Unsolved Problems and Non-Problems in Concurrency (invited address)
| périodique      = Principles of Distributed Systems
| lien périodique = 
| volume          = 
| numéro          = 
| jour            = 
| mois            = 
| année           = 1984
| pages           = 1-11
| issn            = 
| format          = pdf
| url texte       = http://research.microsoft.com/en-us/um/people/lamport/pubs/solved-and-unsolved.pdf
| consulté le     = 
}}</ref>. L'autostabilisation devient alors un sujet à part entière en algorithmique répartie, ce que Lamport considère comme une de ses contributions les plus importantes à l'informatique<ref group=note>{{Citation étrangère|lang=en|I regard the resurrection of Dijkstra's brilliant work on self-stabilization to be one of my greatest contributions to computer science.}} (« Je considère la résurrection de l'excellent travail de Dijkstra sur l'autostabilisation comme l'une de mes plus grandes contributions à l'informatique »), sur {{lien web |url=http://research.microsoft.com/en-us/um/people/lamport/pubs/pubs.html |titre=The Writings of Leslie Lamport |auteur=Leslie Lamport |consulté le={{date|10|janvier|2010}} }}</ref>. Des étudiants soutiennent des thèses de doctorat sur l'autostabilisation et se spécialisent dans la recherche sur ce sujet<ref group=T>{{ouvrage
| langue = en
| prénom1 = Ted
| nom1 = Herman
| titre = Adaptivity through distributed convergence
| éditeur = University of Texas at Austin (thèse de doctorat en informatique)
| année = 1991
}}</ref>{{,}}<ref group=T>{{ouvrage
| langue = en
| prénom1 = Shlomi
| nom1 = Dolev
| titre = Self-Stabilization of Dynamic Systems
| éditeur = Technion, Haïfa (thèse de doctorat en informatique)
| année = 1992
}}</ref>{{,}}<ref group=T>{{ouvrage
| langue = en
| prénom1 = George
| nom1 = Varghese
| titre = Self-stabilization by Local Checking and Correction
| éditeur = University of California, San Diego La Jolla (thèse de doctorat en informatique)
| année = 1993
}}</ref>{{,}}<ref group=T>{{ouvrage
| langue = fr
| prénom1 = Sébastien
| nom1 = Tixeuil
| titre = Auto-stabilisation efficace
| éditeur = Université de Paris Sud 11 (thèse de doctorat en informatique)
| année = 2000
| url texte = http://tel.archives-ouvertes.fr/tel-00124843/fr/
}}</ref>. L'autostabilisation est enseignée à l'université dans le cadre de cours sur l'algorithmique répartie<ref>{{lien web |url=http://mpri.master.univ-paris7.fr/C-2-18.html |éditeur=Master Parisien de Recherche en Informatique |titre=Algorithmique répartie et tolérance aux défaillances |consulté le={{date|11|janvier|2010}} }}</ref>{{,}}<ref>{{en}} {{lien web |url=http://users.ece.utexas.edu/~garg/sp10-opt3.html |titre=EE 382N: Distributed Systems Syllabus |auteur=Vijay Garg |consulté le={{date|11|janvier|2010}} }}</ref>.

En 2000 sort [[#ref_dolev_2000|''Self-Stabilization'']], un livre écrit par Shlomi Dolev, le premier entièrement consacré à l'autostabilisation. Par la suite, plusieurs manuels d'algorithmique répartie<ref>{{Harvsp|Tel|2001}}</ref>{{,}}<ref>{{Harvsp|Garg|2002}}</ref> et de programmation<ref>{{Harvsp|Garg|2004}}</ref> consacrent un chapitre à ce sujet.
Dijkstra reçoit le prix PoDC de l'article influent pour son article de 1974<ref>{{en}} {{lien web |url=http://www.podc.org/influential/2002.html |titre= PODC Influential Paper Award: 2002 |éditeur=PODC |consulté le={{date|30|décembre|2009}} }}</ref> en [[2002 en informatique|2002]], peu avant sa mort. Dès l'année suivante, ce prix est renommé [[prix Dijkstra]] en sa mémoire.

Une rencontre internationale sur le thème de l'autostabilisation<ref>{{lien web |url=http://www.selfstabilization.org/ |titre=Self-Stabilization Home Page |consulté le={{date|10|janvier|2010}} }}</ref> est lancée en [[1989 en informatique|1989]] sous le nom de WSS, ''{{Lang|en|Workshop on Self-Stabilizing Systems}}'' (« Atelier sur les systèmes autostabilisants »). En [[2003 en informatique|2003]], après cinq éditions de l'atelier, la rencontre devient une conférence internationale renommée SSS, ''{{Lang|en|Symposium on Self-Stabilizing Systems}}''<ref>{{lien web |url=http://www.selfstabilization.org/sss2003/ |titre=Sixth Symposium on Self-Stabilizing Systems |consulté le={{date|10|janvier|2010}} }}</ref>. En [[2005 en informatique|2005]], la conférence élargit son sujet et devient ''{{Lang|en|Symposium on Stabilization, Safety, and Security of Distributed Systems}}'' (« Congrès sur la stabilisation, la sûreté et la sécurité des systèmes répartis »)<ref>{{lien web |url=http://www.selfstabilization.org/sss2006/ |titre=Eighth International Symposium on Stabilization, Safety, and Security of Distributed Systems |consulté le={{date|10|janvier|2010}} }}</ref>.
Depuis l'édition de 2003, les actes sont [[#Bibliographie|publiés sous forme de livres]].

== Construction de systèmes autostabilisants ==

Des travaux de recherche sur l'autostabilisation permettent de mieux comprendre comment il est possible de construire un algorithme autostabilisant. Il est possible de l'obtenir automatiquement à partir d'un algorithme réparti classique au moyen d'un stabilisateur, ou en composant plusieurs algorithmes eux-mêmes autostabilisants. D'autre part, l'analyse de la question du fonctionnement à bas niveau montre les conditions que le matériel doit remplir pour permettre à l'autostabilisation de fonctionner.

=== Utilisation d'un stabilisateur ===
Un stabilisateur est un algorithme qui rend autostabilisant n'importe quel algorithme réparti<ref group=D>{{p.}}121</ref>. La meilleure solution connue pour réaliser un stabilisateur consiste à donner à un processus distingué le rôle d'examiner tout le système, ce qui suppose d'obtenir et enregistrer l'état de tous les autres processus, puis, si nécessaire, [[remise à zéro|remettre le système à zéro]] de façon autostabilisante. Cette méthode est trop coûteuse en mémoire et en nombre de messages échangés pour être viable en pratique<ref>{{article
| langue          = en
| prénom1         = Baruch
| nom1            = Awerbuch
| prénom2         = Shay
| nom2            = Kutten
| prénom3         = Yishay
| nom3            = Mansour
| prénom4         = Boaz
| nom4            = Patt-Shamir
| prénom5         = George
| nom5            = Varghese
| titre           = Time optimal self-stabilizing synchronization
| périodique      = Proceedings of the twenty-fifth annual ACM symposium on Theory of computing
| lien périodique = 
| volume          = 
| numéro          = 
| jour            = 
| mois            = 
| année           = 1993
| pages           = 652-661
| issn            = 
| consulté le     = 
}}</ref>.

=== La composition équitable ===

[[Fichier:compo.svg|thumb|alt=deux algorithmes composés en un|left|Composition équitable des algorithmes P et Q.]]

La réutilisation d'algorithmes est une question classique en [[génie logiciel]]. Dans le cadre de l'autostabilisation, elle se pose en ces termes : en supposant donnés des algorithmes autostabilisants, est-il possible de les combiner pour obtenir un algorithme global, ou faut-il à chaque fois tout réécrire depuis le début ? La ''composition équitable''<ref group=D>{{p.}}22</ref> apporte la réponse : sous certaines conditions, la réutilisation d'algorithmes autostabilisants est possible.

Introduite par Shlomi Dolev, Amos Israeli et Shlomo Moran en 1989<ref>{{article
| langue          = en
| prénom1         = Shlomi
| nom1            = Dolev
| lien auteur1    = 
| prénom2         = Amos
| nom2            = Israeli
| lien auteur2    = 
| prénom3         = Shlomo
| nom3            = Moran
| lien auteur3    = 
| titre           = Self-stabilization of Dynamic Systems
| périodique      = Proceedings of the MCC Workshop on Self-stabilizing Systems
| lien périodique = 
| volume          = 
| numéro          = 
| jour            = 
| mois            = 
| année           = 1989
| pages           = 
| issn            = 
| format          = 
| url texte       = 
| consulté le     = 
}}</ref> et développée par les mêmes auteurs en [[1993 en informatique|1993]]<ref name=dim93>{{article
| langue          = en
| prénom1         = Shlomi
| nom1            = Dolev
| lien auteur1    = 
| prénom2         = Amos
| nom2            = Israeli
| lien auteur2    = 
| prénom3         = Shlomo
| nom3            = Moran
| lien auteur3    = 
| titre           = Self-Stabilization of Dynamic Systems Assuming Only Read/Write Atomicity
| périodique      = Distributed Computing
| lien périodique = 
| volume          = 7
| numéro          = 1
| jour            = 
| mois            = 
| année           = 1993
| pages           = 3-16
| issn            = 
| format          = 
| url texte       = 
| consulté le     = 
}}</ref>, elle repose sur deux observations. Premièrement, un algorithme Q qui n'écrit pas dans les variables que lit un algorithme P ne peut pas le gêner pour se stabiliser. Deuxièmement, puisque P est autostabilisant, Q peut lire les variables de P pendant sa propre stabilisation : en effet, il est garanti par définition que les valeurs de ces variables finissent par devenir correctes ; à partir de ce moment, Q se stabilise normalement.

Il est donc possible de fusionner les algorithmes P et Q, en ajoutant simplement leurs codes et variables, pour former un nouvel algorithme, noté P⊕Q (voir le schéma ci-contre). Ce nouvel algorithme est lui-même autostabilisant, à condition qu'aucun des algorithmes ne puisse bloquer l'autre ; il faut donc exiger que, dans toute exécution du système global, chacun des deux algorithmes effectue un nombre infini de pas. Cette dernière condition garantit l'''équité'' de l'ordonnancement entre les deux algorithmes, d'où le terme de ''composition équitable''.

Il est ainsi possible de concevoir un algorithme autostabilisant de façon [[Module (programmation)|modulaire]], en le découpant en sous-algorithmes spécialisés à composer pour obtenir l'algorithme final. Si un algorithme a déjà été écrit pour une tâche donnée, on peut le réutiliser. Par exemple<ref group=D>{{p.}}24</ref>, si on veut faire circuler un jeton sur un système dont la topologie n'est pas en anneau, il suffit de composer l'algorithme de Dijkstra<ref name=d74 /> avec un algorithme de construction de topologie d'où on peut extraire un anneau<ref name=dim93/>.

=== Conception d'un matériel autostabilisant ===

Pour qu'un système puisse réellement être autostabilisant, le matériel sur lequel il fonctionne doit être prévu pour cela. En effet, le matériel ou son [[micrologiciel]] peut contenir des [[Bug informatique|bugs]] qui provoquent son [[plantage]]<ref group=note>Exemple pour les processeurs [[Intel Core 2]] : {{en}} {{pdf}} {{lien web |url=http://download.intel.com/design/processor/specupdt/318733.pdf |titre=Intel® Core™ 2 Duo Processor E8000Δ and E7000Δ Series — Specification Update |éditeur=Intel |consulté le={{date|29|janvier|2010}} }}</ref>. Il est donc nécessaire de s'assurer que le [[microprocesseur]] ne puisse pas se bloquer en entrant dans un état duquel il ne peut plus sortir. La recherche dans ce domaine a permis d'identifier précisément les conditions à remplir par le microprocesseur<ref name=processor />, les différents composants matériels de base et les logiciels qui les exploitent afin qu'ils permettent l'autostabilisation : le microprocesseur<ref name=processor />, le système d'exploitation<ref>{{article
| langue          = en
| prénom1         = Shlomi
| nom1            = Dolev
| lien auteur1    = 
| prénom2         = Reuven
| nom2            = Yagel
| lien auteur2    = 
| titre           = Towards Self-Stabilizing Operating Systems
| périodique      = IEEE Transactions on Software Engeneering
| lien périodique = 
| volume          = 34
| numéro          = 4
| jour            = 
| mois            = 
| année           = 2008
| pages           = 564-576
| issn            = 
| format          = 
| url texte       = 
| consulté le     = 
}}</ref>{{,}}<ref>{{article
| langue          = en
| prénom1         = Shlomi
| nom1            = Dolev
| lien auteur1    = 
| prénom2         = Reuven
| nom2            = Yagel
| lien auteur2    = 
| titre           = Memory Management for Self-stabilizing Operating Systems
| périodique      = Proceedings of the 7th International Symposium on Self-Stabilizing Systems
| lien périodique = 
| volume          = 
| numéro          = 
| jour            = 
| mois            = 
| année           = 2005
| pages           = 113-127
| issn            = 
| format          = 
| url texte       = 
| consulté le     = 
}}</ref>, les [[Pilote informatique|pilotes de périphériques]]<ref>{{article
| langue          = en
| prénom1         = Shlomi
| nom1            = Dolev
| lien auteur1    = 
| prénom2         = Reuven
| nom2            = Yagel
| lien auteur2    = 
| titre           = Self-stabilizing device drivers
| périodique      = ACM Transactions on Autonomous and Adaptive Systems
| lien périodique = 
| volume          = 3
| numéro          = 4
| jour            = 
| mois            = 
| année           = 2008
| pages           = 
| issn            = 
| format          = 
| url texte       = 
| consulté le     = 
}}</ref> et le [[système de fichiers]]<ref>{{article
| langue          = en
| prénom1         = Shlomi
| nom1            = Dolev
| lien auteur1    = 
| prénom2         = Ronen
| nom2            = Kat
| lien auteur2    = 
| titre           = Self-stabilizing distributed file system
| périodique      = Journal of High Speed Networks
| lien périodique = 
| volume          = 14
| numéro          = 2
| jour            = 
| mois            = 
| année           = 2005
| pages           = 135-153
| issn            = 
| format          = 
| url texte       = 
| consulté le     = 
}}</ref>. D'une façon générale, il s'agit de s'assurer qu'aucun blocage n'est possible, ni dans un état dont le système ne peut sortir, ni dans un ensemble d'états où il tournerait sans fin en [[Structure de contrôle#Boucles|boucle]]. Un [[compilateur]] préservant la stabilisation<ref>{{article
| langue          = en
| prénom1         = Shlomi
| nom1            = Dolev
| lien auteur1    = 
| prénom2         = Yinnon A.
| nom2            = Haviv
| lien auteur2    = 
| prénom3         = Mooly
| nom3            = Sagiv
| lien auteur3    = 
| titre           = Self-stabilization preserving compiler
| périodique      = ACM Transactions on Programming Languages and Systems
| lien périodique = 
| volume          = 31
| numéro          = 6
| jour            = 
| mois            = 
| année           = 2009
| pages           = 
| issn            = 
| format          = 
| url texte       = 
| consulté le     = 
}}</ref> a été conçu pour permettre d'écrire des programmes tirant parti de ces matériels et logiciels : si on lui fournit un programme autostabilisant, il produit un [[Langage machine|code machine]] respectant ce même concept d'évitement des blocages. Un brevet a été déposé sur la base de ces résultats<ref>{{en}}{{lien web |url=http://www.freshpatents.com/Apparatus-and-methods-for-stabilization-of-processors-operating-systems-and-other-hardware-and-or-software-configurations-dt20080424ptan20080098205.php |titre=Apparatus and methods for stabilization of processors, operating systems and other hardware and/or software configurations |consulté le=29janvier2010 .}}</ref>.

== Variantes de l'autostabilisation ==

Selon les circonstances et les problèmes posés, l'autostabilisation est parfois considérée comme inutilement contraignante ou, au contraire, insuffisamment forte. C'est là qu'interviennent des variantes, relâchements ou renforcements de la définition de base.

=== La pseudo-stabilisation ===
La pseudo-stabilisation, ou pseudo-autostabilisation<ref group=D>{{p.}}45</ref>, est un relâchement des contraintes de l'autostabilisation. Au lieu d'exiger que toute exécution se termine dans ℒ, on exige que toute exécution réalise une ''tâche abstraite'', c'est-à-dire un prédicat sur le système. Par exemple, pour spécifier l'exclusion mutuelle, on peut exiger que tous les processus du système possèdent un privilège donné infiniment souvent, mais que deux processus ne le possèdent jamais en même temps. Ceci ne permet pas de définir les exécutions légitimes, car elles doivent reposer sur l'état du système ; or, dans la définition d'une tâche abstraite, c'est impossible car on ne sait rien de la façon dont les processus sont réalisés. La pseudo-stabilisation est moins forte et moins contraignante que l'autostabilisation, car tout système autostabilisant est pseudo-stabilisant, mais la réciproque est fausse. Burns, Gouda et Miller, qui ont introduit cette notion en 1993, estiment qu'elle est généralement suffisante en pratique<ref>{{article
| langue          = en
| prénom1         = James E.
| nom1            = Burns
| prénom2         = Mohamed G.
| nom2            = Gouda
| prénom3         = Raymond E.
| nom3            = Miller
| titre           = Stabilization and Pseudo-Stabilization
| périodique      = Distributed Computing
| lien périodique = 
| volume          = 7
| numéro          = 1
| jour            = 
| mois            = 
| année           = 1993
| pages           = 35-42
| issn            = 
| consulté le     = 
}}</ref>.

<gallery>
Fichier:Pseudo-stabilisation1.svg|Première boucle
Fichier:Pseudo-stabilisation2.svg|Perte d'un message
Fichier:Pseudo-stabilisation3.svg|Deuxième boucle
</gallery>

L'exemple classique de pseudo-stabilisation<ref group=D>{{p.}}47</ref> illustré ci-dessus est un système dans lequel deux processus s'échangent des messages. En fonctionnement normal, le système est dans l'état A ; il envoie un message, ce qui fait passer le système dans l'état S ; l'autre processus reçoit le message, ce qui fait passer le système dans l'état B ; le deuxième processus envoie à son tour un message, ce qui fait passer le système dans l'état T ; le premier processus reçoit le message, et le système est de retour dans l'état A. Le problème est que le canal par lequel passent les messages peut perdre un message, auquel cas le système récupère de cette perte en passant dans l'état A'. La définition de A' est totalement dépendante de la méthode utilisée pour récupérer de la perte du message ; elle est donc inconnue au niveau de la tâche abstraite. À partir de A', l'exécution se poursuit de façon similaire : A', S', B', T', A', etc.

Comme la perte d'un message peut se produire, le système n'est pas autostabilisant vers la boucle A, S, B, T. D'un autre côté, cette perte de message peut très bien ne jamais arriver, ce qui fait que le système n'est pas non plus autostabilisant vers la boucle A', S', B', T', ni vers l'ensemble des états possibles. En revanche, ce système, sans être autostabilisant, est bien pseudo-stabilisant pour la tâche abstraite selon laquelle les deux processeurs s'échangent des messages à tour de rôle, puisque la perte d'un message ne remet pas en cause cette définition.

=== La superstabilisation ===
L'idée de la superstabilisation<ref group=D>{{p.}}159</ref>, introduite par Shlomi Dolev et Ted Herman<ref>{{article
| langue          = en
| prénom1         = Shlomi
| nom1            = Dolev
| prénom2         = Ted
| nom2            = Herman
| titre           = Superstabilizing Protocols for Dynamic Distributed Systems
| périodique      = Chicago Journal of Theoretical Computer Science
| lien périodique = 
| volume          = 
| numéro          = 
| jour            = 
| mois            = 
| année           = 1997
| pages           = 
| issn            = 
| format          = pdf
| url texte       = http://cjtcs.cs.uchicago.edu/articles/1997/4/cj97-04.pdf
| consulté le     = 
}}</ref>, est de considérer le changement de topologie, c'est-à-dire l'ajout ou le retrait d'un lien de communication dans le système, comme un événement spécial dont tout processus concerné est averti et qui déclenche une [[Procédure (informatique)|procédure]] appelée ''section d'interruption''. Grâce à cela, le système est capable de garantir qu'une [[Sûreté (propriété de programme)|propriété de sûreté]] particulière, le ''prédicat de passage'', reste toujours vérifiée pendant la stabilisation lorsqu'un changement de topologie se produit à partir d'une configuration sûre. Ceci renforce les garanties données par le système face à un type de défaillance très fréquent en pratique. Plusieurs problèmes de base de l'algorithmique répartie ont été résolus par un algorithme superstabilisant, par exemple l'exclusion mutuelle<ref>{{article
| langue          = en
| prénom1         = Ted
| nom1            = Herman
| titre           = SuperStabilizing Mutual Exclusion
| périodique      = Proceedings of the International Conference on Parallel and Distributed Processing Techniques and Applications
| lien périodique = 
| volume          = 
| numéro          = 
| jour            = 
| mois            = 
| année           = 1995
| pages           = 31-40
| issn            = 
| consulté le     = 
}}</ref>, la construction d'un arbre couvrant<ref>{{article
| langue          = en
| prénom1         = Yoshiak
| nom1            = Katayama
| prénom2         = Toshiyuki
| nom2            = Hasegawa
| prénom3         = Naohisa
| nom3            = Takahashi
| titre           = A superstabilizing spanning tree protocol for a link failure
| périodique      = Systems and Computers in Japan
| lien périodique = 
| volume          = 38
| numéro          = 14
| jour            = 
| mois            = 
| année           = 2007
| pages           = 41-51
| issn            = 
| consulté le     = 
}}</ref> et la construction d'un [[arbre de Steiner]]<ref>{{article
| langue          = en
| prénom1         = Lélia
| nom1            = Blin
| prénom2         = Maria
| nom2            = Gradinariu Potop-Butucaru
| prénom3         = Stéphane
| nom3            = Rovedakis
| titre           = A Superstabilizing log(n)-Approximation Algorithm for Dynamic Steiner Trees
| périodique      = Proceedings of the 11th International Symposium on Stabilization, Safety, and Security of Distributed Systems
| lien périodique = 
| volume          = 
| numéro          = 
| jour            = 
| mois            = 
| année           = 2009
| pages           = 133-148
| issn            = 
| consulté le     = 
}}</ref>.

=== La stabilisation instantanée ===
Au lieu de laisser le système appliquer son algorithme et se corriger si nécessaire, il est possible de faire l'inverse : surveiller le système en permanence pour chercher les incohérences et les corriger immédiatement, avant de laisser un pas s'effectuer. Ainsi, le système se comporte toujours conformément à sa spécification : il est autostabilisant en zéro étape<ref>{{article
| langue          = en
| prénom1         = Alain
| nom1            = Bui
| prénom2         = Ajoy Kumar
| nom2            = Datta
| prénom3         = Franck
| nom3            = Petit
| prénom4         = Vincent
| nom4            = Villain
| titre           = State-optimal snap-stabilizing PIF in tree networks
| périodique      = Proceedings of the ICDCS Workshop on Self-stabilizing Systems
| lien périodique = 
| volume          = 
| numéro          = 
| jour            = 
| mois            = 
| année           = 1999
| pages           = 78-85
| issn            = 
| format          = pdf
| url texte       = http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.49.1477&rep=rep1&type=pdf
| consulté le     = 
}}</ref>. Un système instantanément stabilisant résiste donc parfaitement aux défaillances transitoires, sans qu'un observateur ne s'aperçoive qu'elles se sont produites.

Pour le moment, seuls quelques algorithmes basiques instantanément stabilisants ont été développés, par exemple pour le problème du [[Algorithme de parcours en profondeur|parcours en profondeur]] d'un [[Arbre (informatique)|arbre]]<ref>{{article
| langue          = en
| prénom1         = Alain
| nom1            = Cournier
| prénom2         = Stéphane
| nom2            = Devismes
| prénom3         = Franck
| nom3            = Petit
| prénom4         = Vincent
| nom4            = Villain
| titre           = Snap-Stabilizing Depth-First Search on Arbitrary Networks
| périodique      = Computing Journal
| lien périodique = 
| volume          = 49
| numéro          = 3
| jour            = 
| mois            = 
| année           = 2006
| pages           = 268-280
| issn            = 
| consulté le     = 
}}</ref> ou la communication [[Liaison point à point|point à point]] dans un [[Réseau téléphonique commuté|réseau commuté]]<ref>{{article
| langue          = en
| prénom1         = Alain
| nom1            = Cournier
| prénom2         = Swan
| nom2            = Dubois
| titre           = A snap-stabilizing point-to-point communication protocol in message-switched networks
| périodique      = Proceedings of the 23rd IEEE International Symposium on Parallel and Distributed Processing
| lien périodique = 
| volume          = 
| numéro          = 
| jour            = 
| mois            = 
| année           = 2009
| pages           = 1-11
| issn            = 
| consulté le     = 
}}</ref>. Il est possible de rendre instantanément stabilisant tout algorithme autostabilisant en mémoire partagée, mais la transformation a un coût élevé<ref>{{article
| langue          = en
| prénom1         = Alain
| nom1            = Cournier
| prénom2         = Stéphane
| nom2            = Devismes
| prénom3         = Vincent
| nom3            = Villain
| titre           = From Self- to Snap- Stabilization
| périodique      = Proceedings of the 8th International Symposium on Stabilization, Safety, and Security of Distributed Systems
| lien périodique = 
| volume          = 
| numéro          = 
| jour            = 
| mois            = 
| année           = 2006
| pages           = 199-213
| issn            = 
| consulté le     = 
}}</ref>. Enfin, la stabilisation instantanée est utilisable dans les systèmes à passage de messages, mais là encore, avec un surcoût considérable<ref>{{article
| langue          = en
| prénom1         = Sylvie
| nom1            = Delaët
| prénom2         = Stéphane
| nom2            = Devismes
| prénom3         = Mikhail
| nom3            = Nesterenko
| prénom4         = Sébastien
| nom4            = Tixeuil
| titre           = Snap-Stabilization in Message-Passing Systems
| périodique      = Proceedings of the 10th International Conference on Distributed Computing and Networking
| lien périodique = 
| volume          = 
| numéro          = 
| jour            = 
| mois            = 
| année           = 2009
| pages           = 281-286
| issn            = 
| consulté le     = 
}}</ref>.

=== L'approche probabiliste ===
Dans une version étendue de son article fondateur<ref>{{article
| langue          = en
| prénom1         = Edsger Wybe
| nom1            = Dijkstra
| titre           = Self-stabilization in spite of distributed control
| périodique      = Edsger W. Dijkstra, Selected Writings on Computing: A Personal Perspective
| année           = 1982
| pages           = 3
| format          = pdf
| url texte       = http://www.cs.utexas.edu/users/EWD/ewd03xx/EWD391.PDF
}}</ref>, Dijkstra établit qu'il ne peut pas exister d'algorithme d'anneau à jeton autostabilisant dans lequel tous les processus sont identiques, à moins que la taille de l'anneau ne soit un [[nombre premier]]. En [[1990 en informatique|1990]], Ted Herman apporte un moyen de surmonter cette limitation : obliger l'ordonnanceur à se comporter non plus de façon non-déterministe, mais de façon [[Probabilité|probabiliste]]<ref group=D name=p11/>, avec pour preuve de concept l'algorithme d'anneau à jeton autostabilisant probabiliste suivant<ref name=herman90>{{article
| langue          = en
| prénom1         = Ted
| nom1            = Herman
| titre           = Probabilistic Self-Stabilization
| périodique      = Information Processing Letters
| volume          = 35
| numéro          = 2
| année           = 1990
| pages           = 63-67
}}</ref> : le nombre de processus est impair, et l'état de chaque processus est un [[bit]], qui ne peut donc valoir que 0 ou 1. Un processus possède un jeton si et seulement si son état est le même que celui de son voisin de gauche. Dans la configuration (1) ci-dessous, le processus 0 a un jeton car son état est 1, comme pour le processus 4, et aucun autre processus n'a de jeton. Tout processus qui a un jeton est susceptible d'être choisi par l'ordonnanceur pour changer d'état. Dans ce cas, son nouvel état est tiré au sort : 0 ou 1, avec probabilité ½.
<gallery>
Fichier:hermanring01.svg|Configuration (1)
Fichier:hermanring02.svg|Configuration (2)
</gallery>
L'interprétation de cette règle en pratique est que le processus a une chance sur deux de garder son jeton, et une chance sur deux de le passer au processus suivant sur l'anneau. Dans la configuration (1), si le processus qui a le jeton tire l'état 1, rien ne change. S'il tire l'état 0, il n'a plus de jeton, car son nouvel état est identique à celui de son voisin de gauche. En revanche, le processus 1 a maintenant un jeton, car il a le même état que son voisin de gauche.

Dans la configuration (2), trois processus ont un jeton. Selon le processus choisi par l'ordonnanceur et le résultat du tirage au sort, après un pas de l'exécution, il peut rester trois jetons ou seulement un. Ainsi, si le processus 1 est choisi, il peut soit garder son jeton, soit le transmettre au processus 2, ce qui ne change pas le nombre de jetons. Mais si le processus 0 est choisi et tire l'état 0, non seulement il perd son jeton, mais le processus 1 perd également le sien. Un ordonnanceur non-déterministe, comme celui utilisé par Dijkstra, pourrait obliger les processus à passer leurs jetons sans jamais les perdre, mais un ordonnanceur probabiliste ne peut pas le faire, car la perte du jeton a une probabilité strictement positive : au cours d'une exécution infinie, elle se produit donc avec probabilité 1.

Dans le cas d'un algorithme probabiliste, il n'est pas possible de calculer un temps de stabilisation, car celui-ci dépend des tirages aléatoires. En revanche, il est possible de calculer son [[Espérance mathématique|espérance]]. Initialement, Herman démontre<ref name=herman90 /> que l'espérance du temps de stabilisation de son algorithme est O(n² [[logarithme|log]] n) étapes. Un calcul plus précis montre par la suite<ref>{{article
| langue          = en
| prénom1         = Annabelle
| nom1            = McIver
| prénom2         = Carroll
| nom2            = Morgan
| titre           = An elementary proof that Herman’s Ring is Θ(n²)
| périodique      = Information Processing Letters
| volume          = 94
| numéro          = 2
| année           = 2005
| pages           = 79–84
}}</ref> que cette espérance est exactement Θ(n²) étapes. Des recherches plus récentes donnent un cadre général basé sur la théorie des [[Chaîne de Markov|chaînes de Markov]] pour effectuer ces calculs de complexité dans le modèle probabiliste<ref>{{article
| langue          = en
| prénom1         = Laurent
| nom1            = Fribourg
| prénom2         = Stéphane
| nom2            = Messika
| titre           = Coupling and self-stabilization
| périodique      = Distributed Computing
| volume          = 18
| numéro          = 3
| année           = 2006
| pages           = 221-232
}}</ref>.

== Notes et références ==

=== Notes ===
{{Références |groupe=note}}

=== Références ===
* Références issues de ''[[#ref_dolev_2000|Self-Stabilization]]''
{{Références|colonnes=2|groupe=D}}

* Références à des thèses de doctorat
{{Références|colonnes=2|groupe=T}}

* Autres références
{{Références |colonnes=2}}

== Annexes ==

=== Bibliographie ===
{{légende plume}}
*{{ouvrage
| langue = en
| prénom1 = Shlomi
| nom1 = Dolev
| titre = Self-Stabilization
| éditeur = The MIT Press
| lien éditeur = The MIT Press
| lieu = 
| jour = 3
| mois = mars
| année =2000
| pages totales = 207
| commentaire = Le livre de référence sur l'autostabilisation. Partiellement [http://books.google.com/books?id=UPdnRDX-ygQC&printsec=frontcover&hl=fr&source=gbs_v2_summary_r&cad=0#v=onepage&q=&f=false disponible] en ligne.
| isbn = 978-0262041782
| id = ref_dolev_2000
| plume = oui
}}
*{{ouvrage
| langue = en
| prénom1 = Vijay Kumar
| nom1 = Garg
| titre = Elements of Distributed Computing
| éditeur = Wiley-IEEE Press
| jour = 23
| mois = mai
| année =2002
| pages totales = 423
| commentaire = Manuel de base sur l'algorithmique répartie. Le chapitre 23 (pages 287-296) est consacré à l'autostabilisation. Partiellement [http://books.google.com/books?id=NlVBtVPeR0QC&printsec=frontcover&hl=fr&source=gbs_v2_summary_r&cad=0#v=onepage&q=&f=false disponible] en ligne.
| isbn = 978-0471036005
}}
*{{ouvrage
| langue = en
| prénom1 = Vijay Kumar
| nom1 = Garg
| titre = Concurrent and Distributed Computing in Java
| éditeur = Wiley-IEEE Press
| jour = 4
| mois = février
| année =2004
| pages totales = 336
| commentaire = Ce livre enseigne la programmation en [[Java (langage)|Java]] d'algorithmes concurrents et répartis. Le chapitre 18 (pages 279-290) présente des algorithmes autostabilisants. Partiellement [http://books.google.com/books?id=h6hAn4hsXAwC&printsec=frontcover&hl=fr&source=gbs_v2_summary_r&cad=0#v=onepage&q=&f=false disponible] en ligne.
| isbn = 978-0471036005
}}
*{{ouvrage
| langue = en
| prénom1 = Gerard
| nom1 = Tel
| titre = Introduction to Distributed Algorithms
| éditeur = Cambridge University Press
| lien éditeur = Cambridge University Press
| lieu = 
| jour = 15
| mois = février
| année =2001
| pages totales = 608
| commentaire = Manuel de base sur l'algorithmique répartie. Le chapitre 17 (pages 520-547) est consacré à l'autostabilisation. Partiellement [http://books.google.com/books?id=vlpnS25qAJQC&printsec=frontcover&hl=fr&source=gbs_v2_summary_r&cad=0#v=onepage&q=&f=false disponible] en ligne.
| isbn = 978-0521794831
}}

Depuis l'édition de 2003, les actes de la conférence SSS sont publiés sous forme de livres dans la collection ''Lecture Notes in Computer Science'' de [[Springer Verlag]]. L'autostabilisation est le seul thème de la conférence jusqu'en 2005, l'un des principaux thèmes par la suite.
*{{ouvrage
| langue = en
| prénom1 = Shing-Tsaan
| nom1 = Huang
| directeur1=oui
| prénom2 = Ted
| nom2 = Herman
| directeur2=oui
| titre = Self-Stabilizing Systems: 6th International Symposium, SSS 2003, San Francisco, Ca, USA, June 24-25, 2003 Proceedings
| éditeur = Springer Verlag
| lien éditeur = Springer Verlag
| lieu = 
| jour = 11
| mois = juin
| année =2003
| pages totales = 215
| commentaire = 
| isbn = 978-3540404538
| plume = oui
}}
*{{ouvrage
| langue = en
| prénom1 = Sébastien
| nom1 = Tixeuil
| directeur1=oui
| prénom2 = Ted
| nom2 = Herman
| directeur2=oui
| titre = Self-Stabilizing Systems: 7th International Symposium, SSS 2005, Barcelona, Spain, October 26-27, 2005 (Lecture Notes in Computer Science)
| éditeur = Springer Verlag
| lien éditeur = Springer Verlag
| lieu = 
| jour = 27
| mois = octobre
| année =2005
| pages totales = 229
| commentaire = 
| isbn = 978-3540298144
| plume = oui
}}
*{{ouvrage
| langue = en
| prénom1 = Ajoy Kumar
| nom1 = Datta
| directeur1=oui
| prénom2 = Maria
| nom2 = Gradinariu Potop-Butucaru
| directeur2=oui
| titre = Stabilization, Safety, and Security of Distributed Systems: 8th International Symposium, SSS 2006 Dallas, TX, USA, November 17-19, 2006 Proceedings (Lecture Notes in Computer Science)
| éditeur = Springer Verlag
| lien éditeur = Springer Verlag
| lieu = 
| jour = 8
| mois = novembre
| année =2006
| pages totales = 805
| commentaire = 
| isbn = 978-3540490180
| plume = oui
}}
*{{ouvrage
| langue = en
| prénom1 = Toshimitsu
| nom1 = Masuzawa
| directeur1=oui
| prénom2 = Sébastien
| nom2 = Tixeuil
| directeur2=oui
| titre = Stabilization, Safety, and Security of Distributed Systems: 9th International Symposium, SSS 2007 Paris, France, November 14-16, 2007 Proceedings (Lecture Notes in Computer Science)
| éditeur = Springer Verlag
| lien éditeur = Springer Verlag
| lieu = 
| jour = 6
| mois = novembre
| année =2007
| pages totales = 409
| commentaire = 
| isbn = 978-3540766261
| plume = oui
}}
*{{ouvrage
| langue = en
| prénom1 = Sandeep
| nom1 = Kulkarni
| directeur1=oui
| prénom2 = André
| nom2 = Schiper
| directeur2=oui
| titre = Stabilization, Safety, and Security of Distributed Systems: 10th International Symposium, SSS 2008, Detroit, MI, USA, November 21-23, 2008
| éditeur = Springer Verlag
| lien éditeur = Springer Verlag
| lieu = 
| jour = 6
| mois = novembre
| année =2008
| pages totales = 265
| commentaire = 
| isbn = 978-3540893349}}
*{{ouvrage
| langue = en
| prénom1 = Rachid
| nom1 = Guerraoui
| directeur1=oui
| prénom2 = Franck
| nom2 = Petit
| directeur2=oui
| titre = Stabilization, Safety, and Security of Distributed Systems: 11th International Symposium, SSS 2009, Lyon, France, November 3-6, 2009. Proceedings
| éditeur = Springer Verlag
| lien éditeur = Springer Verlag
| lieu = 
| jour = 26
| mois = octobre
| année =2009
| pages totales = 805
| commentaire = 
| isbn = 978-3642051173
| plume = oui
}}

=== Articles connexes ===
* [[Algorithmique répartie]]
* [[Tolérance aux pannes]]
* [[Système critique]]
* [[Réseau de capteurs sans fil]]

=== Liens externes ===

* {{en}} [http://www.selfstabilization.org/ Page d'accueil de SSS], la conférence sur l'autostabilisation
* {{en}} [http://www.cs.uiowa.edu/ftp/selfstab/bibliography/ Liste d'articles sur l'autostabilisation] compilée par Ted Herman
* {{en}} [http://www.cs.bgu.ac.il/~dolev/ Site web de Shlomi Dolev], avec des informations sur son livre et ses publications
* {{fr}} {{pdf}} [http://mpri.master.univ-paris7.fr/attached-documents/C-2-18/autostabilisation.pdf Notes] prises par Philippe Gambette sur un cours de Joffroy Beauquier et Laurent Fribourg concernant l'algorithmique répartie, dont l'autostabilisation, mises à disposition sur le site du [http://mpri.master.univ-paris7.fr/ master parisien de recherche en informatique]

{{Portail|informatique}}
{{Article de qualité|oldid=50254665|date=23 février 2010}}

[[Catégorie:Algorithmique répartie]]

[[en:Self-stabilization]]
[[pt:Autoestabilização]]