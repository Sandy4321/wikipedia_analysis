[[Файл:Logo proba 4.svg|thumb|280px]]
'''История [[Теория вероятностей|теории вероятностей]]''' отмечена многими уникальными особенностями. Прежде всего, в отличие от появившихся примерно в то же время других разделов [[математика|математики]] (например, [[Математический анализ|математического анализа]] или [[Аналитическая геометрия|аналитической геометрии]]), у теории вероятностей по существу не было античных или средневековых предшественников, она целиком — создание Нового времени<ref>{{статья |автор=Гнеденко Б. В. |заглавие=О работах М. В. Остроградского по теории вероятностей |издание=[[Историко-математические исследования]] |номер=4 |издательство=ГИТТЛ |место=М. |год=1951 |страницы=120 }}</ref>. Долгое время теория вероятностей считалась чисто опытной наукой и «не совсем математикой»<ref>{{книга |автор=Гнеденко Б. В.|заглавие=Очерки по истории математики в России |место=М.—Л. |издательство=ОГИЗ |год=1946 |страницы=201}}</ref>{{sfn |Майстров Л. Е.|1967|с=303. }}, её строгое обоснование было разработано только в 1929 году, то есть даже позже, чем [[аксиоматика теории множеств]] (1922). В наши дни теория вероятностей занимает одно из первых мест в прикладных науках по широте своей области применения; «нет почти ни одной естественной науки, в которой так или иначе не применялись бы вероятностные методы»<ref>{{книга|автор=Вентцель Е. С.|заглавие=Теория вероятностей|издание=Изд. 4-е, стереотипное|место=М.|издательство=Наука|год=1969|страницы=17|страниц=577}}</ref>.

Историки выделяют в развитии теории вероятностей несколько периодов<ref name=KOLMO1947/>{{sfn |Шейнин О. Б.|1978|с=284—285. }}.
# Предыстория, до XVI века включительно. В античные времена и в средневековье [[Натурфилософия|натурфилософы]] ограничивались [[Метафизика|метафизическими]] рассуждениями о происхождении случайности и её роли в природе{{sfn |Шейнин О. Б.|1978| с=285—288. }}. Математики в этот период рассматривали и иногда решали задачи, связанные с теорией вероятностей, но никаких общих методов и тематических понятий ещё не появилось. Главным достижением данного периода можно считать развитие [[Комбинаторика|комбинаторных методов]], которые позже пригодились создателям теории вероятностей.
# Начало формирования во второй половине XVII века основных понятий и методов теории вероятностей для [[Случайная величина|случайных величин]] с конечным числом значений. Стимулом вначале служили преимущественно проблемы, возникающие в [[Азартная игра|азартных играх]], однако область применения теории вероятностей почти сразу начинает расширяться, включая в себя прикладные задачи [[Демография|демографической статистики]], [[Страхование|страхового дела]] и [[Вычислительная математика|теории приближённых вычислений]]. На этом этапе важный вклад в идеи новой науки внесли [[Паскаль, Блез|Паскаль]] и [[Ферма, Пьер|Ферма]]. [[Гюйгенс, Христиан|Гюйгенс]] ввёл два фундаментальных понятия: числовая мера вероятности события, а также понятие [[Математическое ожидание|математического ожидания]] случайной величины.
# В XVIII веке появились монографии с систематическим изложением теории вероятностей. Первой из них стала книга [[Бернулли, Якоб|Якоба Бернулли]] «Искусство предположений» (1713 год). В ней Бернулли предложил классическое определение [[Вероятность|вероятности]] [[Случайное событие|случайного события]] как отношение числа равновероятных исходов, связанных с этим событием, к общему числу исходов. Он также изложил правила подсчёта вероятности для сложных событий и дал первый вариант ключевого [[Закон больших чисел|«закона больших чисел»]], разъясняющего, почему частота [[Случайное событие|события]] в серии испытаний не меняется хаотично, а в некотором смысле стремится к своему предельному теоретическому значению (то есть вероятности).
# Идеи Бернулли далеко развили в начале XIX века [[Лаплас, Пьер-Симон|Лаплас]], [[Гаусс, Карл Фридрих|Гаусс]], [[Пуассон, Симеон Дени|Пуассон]]. Применение вероятностных методов в прикладной статистике значительно расширилось. Понятие вероятности стало определено и для непрерывных случайных величин, благодаря чему появилась возможность применения методов математического анализа. Появляются первые попытки применения теории вероятностей в физике. К концу XIX века появляются [[статистическая физика]], строгая теория ошибок измерения, вероятностные методы проникают в самые различные прикладные науки.
# В XX веке в физике была создана [[квантовая механика|теория микромира]], а в биологии — [[Генетика|теория наследственности]], обе они существенно основаны на вероятностных методах. [[Карл Пирсон]] разработал алгоритмы [[Математическая статистика|математической статистики]], широко и повсеместно применяемые для анализа прикладных измерений, [[Проверка статистических гипотез|проверки гипотез]] и [[Теория принятия решений|принятия решений]]. [[Колмогоров, Андрей Николаевич|А. Н. Колмогоров]] дал классическую [[Аксиоматика Колмогорова|аксиоматику теории вероятностей]]. Из других новых областей применений теории вероятностей необходимо упомянуть [[Теория информации|теорию информации]] и теорию [[Случайный процесс|случайных процессов]]. Философские споры о том, что такое вероятность и в чём причина её устойчивости, продолжаются.

== Средневековая Европа и начало Нового времени ==
[[Файл:Historical dice.jpg|мини|left|Древние образцы игральных костей]]
Первые задачи вероятностного характера возникли в различных [[Азартная игра|азартных играх]] — [[Игральная кость|костях]], [[Игральные карты|картах]] и др.{{sfn |Гнеденко Б. В.|2005|с=366. }} Французский каноник XIII века [[Фурниваль, Ришар де|Ришар де Фурниваль]] правильно подсчитал все возможные суммы очков после броска трёх костей и указал число способов, которыми может получиться каждая из этих сумм. Это число способов можно рассматривать как первую числовую меру ожидаемости события, аналогичную вероятности. До Фурниваля, а иногда и после него, эту меру часто подсчитывали неверно, считая, например, что суммы 3 и 4 очка равновероятны, так как оба могут получиться «только одним способом»: по результатам броска «три единицы» и «двойка с двумя единицами» соответственно. При этом не учитывалось, что три единицы в самом деле получаются только одним способом: <math>~1+1+1</math>, а двойка с двумя единицами — тремя: <math>~1+1+2;\;1+2+1;\;2+1+1</math>, так что эти события не равновероятны{{sfn |Майстров Л. Е.|1967|с=22. }}. Аналогичные ошибки неоднократно встречались и в дальнейшей истории науки.

В обширной математической энциклопедии «Сумма арифметики, геометрии, отношений и пропорций» итальянца [[Лука Пачоли|Луки Пачоли]] (1494) содержатся оригинальные задачи на тему: как разделить ставку между двумя игроками, если серия игр прервана досрочно. Пример подобной задачи: игра идёт до 60 очков, победитель получает всю ставку в 22 [[дукат]]а, в ходе игры первый игрок набрал 50 очков, второй — 30, и тут игру пришлось прекратить; требуется справедливо разделить исходную ставку. Решение зависит от того, что понимать под «справедливым» разделом; сам Пачоли предложил делить [[Пропорциональность|пропорционально]] набранным очкам (55/4 и 33/4 дуката){{sfn |Гнеденко Б. В.|2005|с=368. }}; позднее его решение было признано ошибочным<ref name="renyi">{{книга|автор=[[Реньи, Альфред|Реньи А.]]|часть=Об истории теории вероятностей|ссылка часть=http://veroyat.narod.ru/istoriya_teorii_veroyatnostey.html|заглавие=[[Реньи, Альфред|Реньи А.]]&nbsp; Трилогия о математике|место=М.|издательство=Мир|год=1980|страниц=376}} — С. 184—186.</ref>.

[[Файл:Dice Distribution (bar).svg|мини|Распределение суммы очков после бросания двух костей]]
Крупный алгебраист XVI века [[Джероламо Кардано]] посвятил анализу игры содержательную монографию «Книга об игре в кости» (1526 год, опубликована посмертно). Кардано провёл полный и безошибочный [[Комбинаторика|комбинаторный]] анализ для значений суммы очков и указал для разных событий ожидаемое значение доли «благоприятных» событий: например, при бросании трёх костей доля случаев, когда значения всех 3 костей совпадают, равна 6/216 или 1/36. Кардано сделал проницательное замечание: реальное количество исследуемых событий может при небольшом числе игр сильно отличаться от теоретического, но чем больше игр в серии, тем доля этого различия меньше. По существу, Кардано близко подошёл к понятию вероятности{{sfn |Майстров Л. Е.|1967|с=23—31. }}:
{{начало цитаты}}
Итак, имеется одно общее правило для расчёта: необходимо учесть общее число возможных выпадений и число способов, которыми могут появиться данные выпадения, а затем найти отношение последнего числа к числу оставшихся возможных выпадений.
{{конец цитаты}}

Другой итальянский алгебраист, [[Тарталья, Никколо|Никколо Тарталья]], раскритиковал подход Пачоли к решению задачи о разделе ставки: ведь если один из игроков ещё не успел набрать ни одного очка, то алгоритм Пачоли отдаёт всю ставку его сопернику, но это трудно назвать справедливым, поскольку некоторые шансы на выигрыш у отстающего всё же имеются. Кардано и Тарталья предложили свои (различные) способы раздела, но впоследствии и эти способы были признаны неудачными{{sfn |Гнеденко Б. В.|2005|с=370—371. }}.

Исследованием данной темы занимался и [[Галилео Галилей]], написавший трактат «О выходе очков при игре в кости» (1718 год, опубликован посмертно). Изложение теории игры у Галилея отличается исчерпывающей полнотой и ясностью. В своей главной книге «Диалог о двух главнейших системах мира, птоломеевой и коперниковой» Галилей также указал на возможность оценки погрешности астрономических и иных измерений, причём заявил, что малые ошибки измерения вероятнее, чем большие, отклонения в обе стороны равновероятны, а средний результат должен быть близок к истинному значению измеряемой величины. Эти качественные рассуждения стали первым в истории предсказанием [[Нормальное распределение|нормального распределения]] ошибок<ref>{{статья|автор=Майстров Л. Е.|заглавие=Элементы теории вероятностей у Галилея|издание=Вопросы истории естествознания и техники|место=Μ. |издательство=Наука |год=1964|выпуск=16 |страницы=94—98 }}</ref>.

== XVII век: Паскаль, Ферма, Гюйгенс ==
[[Файл:PascalTriangleAnimated2.gif|мини|слева|[[Арифметический треугольник]], основа комбинаторных исследований Паскаля]]
В XVII веке начало формироваться отчётливое представление о проблематике теории вероятностей и появились первые математические ([[Комбинаторика|комбинаторные]]) методы решения вероятностных задач. Основателями математической теории вероятностей стали [[Паскаль, Блез|Блез Паскаль]] и [[Ферма, Пьер|Пьер Ферма]]{{sfn|Стройк Д. Я.|1984|с=143.}}.

Перед этим математик-любитель [[шевалье де Мере]] обратился к Паскалю по поводу так называемой «задачи об очках»: сколько раз нужно бросать две кости, чтобы ставить на одновременное выпадение хотя бы раз двух шестёрок было выгодно? Паскаль и Ферма вступили в переписку друг с другом по поводу данной задачи и родственных вопросов ([[1654 год в науке|1654]]). В рамках этой переписки учёные обсудили ряд проблем, связанных с вероятностными расчётами; в частности, рассматривалась старая задача о разделе ставки, и оба учёных пришли к решению, что надо разделить ставку соответственно остающимся шансам на выигрыш. Паскаль указал де Мере на ошибку, допущенную им при решении «задачи об очках»: в то время как де Мере неверно определил равновероятные события, получив ответ: 24 броска, Паскаль дал правильный ответ: 25 бросков{{sfn|Стройк Д. Я.|1984|с=143.}}<ref>{{статья |автор=Ван дер Варден Б. Л. |заглавие=Переписка между Паскалем и Ферма по вопросам теории вероятностей |издание=[[Историко-математические исследования]] |номер=21 |издательство=Наука |место=М. |год=1976 |страницы=228—232 }}</ref>.

Паскаль в своих трудах далеко продвинул применение комбинаторных методов, которые систематизировал в своей книге «Трактат об [[Треугольник Паскаля|арифметическом треугольнике]]» (1665){{sfn |Гнеденко Б. В.|2005|с=375—376, 379. |name=GN375 }}. Опираясь на вероятностный подход, Паскаль даже доказывал (в посмертно опубликованных заметках), что быть верующим выгоднее, чем атеистом (см. «[[пари Паскаля]])».

[[Файл:PSM V78 D339 Christaan Huygens.png|мини|Христиан Гюйгенс]]
Тематика дискуссии Паскаля и Ферма (без подробностей) стала известна [[Гюйгенс, Христиан|Христиану Гюйгенсу]], который опубликовал собственное исследование «О расчётах в азартных играх» (1657): первый трактат по теории вероятностей{{sfn|Стройк Д. Я.|1984|с=143.}}. В предисловии Гюйгенс пишет{{sfn |История математики, том II|1970|с=89—91.|name=IST89 }}:
{{начало цитаты}}Я полагаю, что при внимательном изучении предмета читатель заметит, что имеет дело не только с игрой, но что здесь закладываются основы очень интересной и глубокой теории.{{конец цитаты}}

В трактате Гюйгенса подробно излагаются вопросы, рассмотренные Ферма и Паскалем, но ставятся и новые вопросы<ref name="renyi"/>. Главным достижением нидерландского учёного стало введение понятия [[Математическое ожидание|математического ожидания]], то есть теоретического [[Среднее арифметическое|среднего значения]] [[Случайная величина|случайной величины]]. Гюйгенс также указал классический способ его подсчёта<ref name=IST89/>:
{{начало цитаты}}
Если число случаев, в которых получается сумма <math>a</math>, равно <math>p</math>, а число случаев, в которых получается сумма <math>b</math>, равно <math>q</math>, то стоимость моего ожидания равна <math>~\frac{ap + bq}{p+q}</math>.
{{конец цитаты}}
Гюйгенс, как видно из цитаты, вначале использовал термин «стоимость», а термин «ожидание» появился впервые при переводе трактата Гюйгенса [[Ван Схоутен, Франс|Ван Схоутеном]] на латинский язык и стал общепринятым в науке{{sfn |Гнеденко Б. В.|2005|с=379—380. }}.

В книге большое число задач, некоторые с решениями, другие «для самостоятельного решения». Из последних особый интерес и оживлённое обсуждение вызвала «[[задача о разорении игрока]]». В несколько обобщённом виде она формулируется так: у игроков A и B есть <math>a</math> и <math>b</math> монет соответственно, в каждой игре выигрывается одна монета, вероятность выигрыша A в каждой игре равна <math>p,</math> требуется найти вероятность полного его разорения. Полное общее решение «задачи о разорении» дал [[Муавр, Абрахам де|Абрахам де Муавр]] полвека спустя (1711 год){{sfn |Гнеденко Б. В. |2005 |с=399—400. }}. В наши дни вероятностная схема «задачи о разорении» используется при решении многих задач типа «[[случайное блуждание]]»<ref>{{книга|автор=Витерби Э. Д. |заглавие=Принципы когерентной связи |ссылка=http://edu.sernam.ru/book_vit.php?id=27|место=М. |издательство=Советское радио|год=1970 |страниц=392 |страницы=102 }}</ref>.

Гюйгенс проанализировал и задачу о разделе ставки, дав её окончательное решение: ставку надо разделить пропорционально вероятностям выигрыша при продолжении игры{{sfn |Майстров Л. Е.|1967|с=58—60. }}. Он также впервые применил вероятностные методы к [[Демографическая статистика|демографической статистике]] и показал, как рассчитать среднюю продолжительность жизни{{sfn |Майстров Л. Е.|1967|с=64—65. }}.

К этому же периоду относятся публикации английских статистиков [[Граунт, Джон|Джона Граунта]] (1662) и [[Петти, Уильям|Уильяма Петти]] (1676, 1683). Обработав данные более чем за столетие, они показали, что многие [[демография|демографические]] характеристики лондонского населения, несмотря на случайные колебания, имеют достаточно устойчивый характер — например, соотношение числа новорождённых мальчиков и девочек редко отклоняется от пропорции 14 к 13, невелики колебания и процента смертности от конкретных случайных причин. Эти данные подготовили научную общественность к восприятию новых идей<ref name=IST89/>. 

Граунт также впервые составил {{нп5|Таблица смертности|таблицы смертности||Life table}}&nbsp;— таблицы вероятности смерти как функции возраста. Вопросами [[теория вероятностей|теории вероятностей]] и её применения к [[демографическая статистика|демографической статистике]] занялись также [[Худде, Иоганн|Иоганн Худде]] и [[Витт, Ян де|Ян де Витт]] в Нидерландах, которые в 1671 году также составили таблицы смертности и использовали их для вычисления размеров [[пожизненная рента|пожизненной ренты]]. Более подробно данный круг вопросов был изложен в 1693 году [[Галлей, Эдмунд|Эдмундом Галлеем]]<ref name="renyi"/><ref>{{книга|автор=Alter G.|часть=Plague and the Amsterdam Annuitant: A New Look at Life Annuities as a Source for Historical Demography|заглавие=''Population Studies'', '''37''', 1983}} — P. 23—41.</ref>.

== XVIII век ==
На книгу Гюйгенса опирались появившиеся в начале XVIII века трактаты [[Монмор, Пьер Ремон де|Пьера де Монмора]] «Опыт исследования азартных игр» ({{lang-fr|Essay d'analyse sur les jeux de hazard}}; опубликован в 1708 и переиздан с дополнениями в 1713 году) и [[Якоб Бернулли|Якоба Бернулли]] «Искусство предположений» ({{lang-la|Ars conjectandi}}; опубликован уже после смерти учёного, в том же 1713 году). Последний имел для теории вероятностей особенно большое значение<ref name="renyi"/>.

=== «Искусство предположений» Якоба Бернулли ===
[[Файл:Basel 2012-10-06 Batch Part 5 (31).JPG|мини|280px|слева|<center>[[Якоб Бернулли]]<br /> Базель, Исторический музей</center>]]
В трактате «Искусство предположений» (над которым его автор работал двадцать лет и который уже лет за десять до публикации в виде незаконченной рукописи стал распространяться по Европе, вызывая большой интерес) было дано ''первое систематическое изложение'' теории вероятностей. В этой книге Якоб Бернулли привёл, в частности, классическое определение [[вероятность|вероятности]] события как отношения числа исходов, связанных с этим событием, к общему числу исходов (у достоверного события вероятность равна единице, у невозможного&nbsp;— нулю). Систематически изученная Бернулли вероятностная схема сейчас называется [[биномиальное распределение|биномиальным распределением]]{{sfn |Гнеденко Б. В.|2005|с=387—389, 73.|name=GN387 }}.

Ранее математики чаще всего оперировали самим количеством исходов; историки полагают, что замена количества на «частоту» (то есть деление на общее количество исходов) была стимулирована статистическими соображениями: частота, в отличие от количества, обычно имеет тенденцию к стабилизации при увеличении числа наблюдений. Определение вероятности «по Бернулли» сразу стало общепринятым, его воспроизводили [[Муавр, Абрахам де|Абрахам де Муавр]] в книге «Учение о случаях» (1718) и все последующие математики. Единственное важное уточнение — о том, что все «элементарные исходы» обязаны быть равновероятны, — сделал [[Лаплас, Пьер-Симон|Пьер-Симон Лаплас]] в 1812 году. Если для события невозможно подсчитать классическую вероятность (например, из-за отсутствия возможности выделить равновероятные исходы), то Бернулли предложил использовать статистический подход, то есть оценить вероятность по результатам наблюдений этого события или связанных с ним<ref name=GN387/>.

[[Файл:Ars Conjectandi of Jakob Bernoulli, 1713 (1160x1130).png|мини|280px|справа|Трактат «Искусство предположений»]]
В первой части своего трактата Бернулли полностью перепечатывает книгу Гюйгенса, которой он даёт самую высокую оценку, и существенно дополняет собственными комментариями. В частности, он приводит общую [[формула Бернулли|«формулу Бернулли»]]: если вероятность события равна <math>p</math>, то вероятность того, что в <math>n</math> испытаниях событие случится <math>m</math> раз, равна <math>~C_n^m p^m (1-p)^{n-m}</math>. Далее Бернулли подробно излагает [[Комбинаторика|комбинаторику]] и на её основе решает несколько задач со случайным выбором. В последней части книги, оставшейся недописанной, Бернулли собирался рассмотреть экономические и другие практические приложения теории вероятностей{{sfn |Майстров Л. Е.|1967|с=67—79. }}.

Огромное значение как для теории вероятностей, так и для науки в целом имел доказанный Бернулли первый вариант [[Закон больших чисел|закона больших чисел]] (название закону дал позже [[Пуассон, Симеон Дени|Пуассон]]){{sfn |Бернулли Я.|1957 }}. Этот закон объясняет, почему статистическая частота при увеличении числа наблюдений сближается с теоретическим её значением — вероятностью, и тем самым связывает два разных определения вероятности. В дальнейшем закон больших чисел трудами многих математиков был значительно обобщён и уточнён; как оказалось, стремление статистической частоты к теоретической отличается от стремления к пределу в анализе — частота может значительно отклоняться от ожидаемого предела, и можно только утверждать, что ''вероятность'' таких отклонений с ростом числа испытаний стремится к нулю. Вместе с тем отклонения частоты от вероятности также поддаются вероятностному анализу{{sfn |Майстров Л. Е.|1967|с=81—89. }}.

=== Развитие идей Бернулли ===
[[Файл:Abraham de Moivre - Doctrine of Chance - 1718.gif|мини|left|Трактат де Муавра<br />«Учение о случаях»]]
Трактат Якоба Бернулли вызвал резкий подъём интереса к вероятностным проблемам и рост числа исследований новых задач. [[Муавр, Абрахам де|Абрахам де Муавр]] опубликовал несколько работ, среди которых наиболее интересны статья «Об измерении случайности, или вероятностях результатов в азартных играх» (1711) и трактат «Учение о случаях» (1718), выдержавший в XVIII веке три издания. В этом трактате Муавр не только полностью решил упоминавшуюся выше «задачу о разорении игрока», но и оценил для неё среднюю продолжительность игры и вероятности выигрыша за заданное число игр для каждого игрока<ref name="renyi"/>{{sfn |Гнеденко Б. В.|2005|с=402. }}. В другой работе, называвшейся «Аналитическая смесь», Муавр дал первый вариант [[Локальная теорема Муавра — Лапласа|теоремы Муавра—Лапласа]], исследующей распределение возможных отклонений статистической частоты от вероятности. Муавр рассмотрел только случай, когда вероятность равна 1/2, общий же случай для любой вероятности доказал [[Лаплас, Пьер-Симон|Лаплас]]{{sfn |Майстров Л. Е.|1967|с=95—96. }}. Ещё одним достижением Муавра стало первое введение в науку [[нормальное распределение|нормального распределения]] (1733), которое появилось у него как аппроксимация биномиального распределения{{sfn|Стройк Д. Я.|1984|с=175.}}.

[[Даниил Бернулли]], племянник основателя теории вероятностей, также внёс вклад в эту науку. Он, независимо от Муавра, исследовал нормальное распределение для ошибок наблюдений, первым применил к вероятностным задачам методы [[Математический анализ|математического анализа]], опубликовал [[Санкт-Петербургский парадокс|первый из вероятностных парадоксов]] (1738){{sfn |Никифоровский В. А.|1992|с=48. }}.

Следующий важный шаг сделал английский математик [[Симпсон, Томас|Томас Симпсон]], который в ходе занятий [[Вычислительная математика|численным анализом]] в книге «Природа и законы случая» (1740) фактически использовал третье (наряду с классическим и статистическим) определение вероятности — геометрическое, пригодное для исследования непрерывных случайных величин с бесконечным числом значений. В задаче XXVI Симпсон нашёл вероятность того, что наудачу брошенный на плоскость [[параллелепипед]] остановится на заданной своей грани<ref name=GN390/>.

[[Файл:Buffon.png|мини|Задача об игле Бюффона]]
Подход Симпсона развил [[Бюффон, Жорж-Луи Леклерк де|Жорж-Луи де Бюффон]], который в 1777 году привёл классический пример задачи на геометрическую вероятность{{sfn|Стройк Д. Я.|1984|с=175.}}. Это была занимавшая впоследствии многих математиков {{нп5|Игла Бюффона|задача об игле||Buffon's needle}}: плоскость разграфлена «в линейку», на неё наудачу бросается игла, требуется найти вероятность того, что игла попадёт между линиями{{sfn |Гнеденко Б. В.|2005|с=390—391.|name=GN390 }}. Если длина иглы <math>a</math> меньше, чем расстояние между линиями <math>l</math>, то искомая вероятность равна <math>~\frac{2a}{\pi l}</math>. Данная формула была несколько раз проверена экспериментально, в том числе самим Бюффоном, а в 1901 году итальянский математик Марио Лаццарини (Mario Lazzarini) использовал её для опытного определения [[Число пи|числа <math>\pi</math>]]. Задача Бюффона, её анализ и различные модификации обсуждались математиками многие годы<ref>{{книга|автор=Badger L.|часть=Lazzarini’s Lucky Approximation of <math>\pi</math>|заглавие=''Mathematics Magazine'', '''67''' (2), 1994}} — P. 83—91. — {{DOI|10.2307/2690682}}.</ref>.

Была решена важнейшая задача расчёта вероятности для сложных событий. Английский математик [[Томас Байес]] первым в отчётливом виде привёл [[Теорема сложения вероятностей|теорему сложения вероятностей]] для нескольких несовместимых событий и основополагающие в теории вероятностей и статистике «[[формулы Байеса]]» (1763 год, опубликованы посмертно). В современной терминологии формулы Байеса позволяют рассчитать [[Условная вероятность|условную вероятность]], а также уточнить рассчитанную вероятность после получения новых данных. [[Теорема умножения вероятностей|Теорему умножения вероятностей]] ранее открыл Муавр (1718 год) и дал ей вполне современную, хотя и словесную формулировку: «вероятность появления двух зависимых событий равна произведению вероятности появления одного из них на вероятность того, что другое должно появиться, если первое из них уже появилось»{{sfn |Гнеденко Б. В.|2005|с=394—397. }}.

К середине XVIII века анализ игр всё ещё привлекает некоторый интерес — например, [[Леонард Эйлер]] дал подробный анализ разных типов [[Лотерея|лотерей]]{{sfn |Майстров Л. Е.|1967|с=119—125. }}, но центром внимания математиков всё в большей степени становятся [[демографическая статистика]], [[страхование]] и оценка ошибок (измерения, округления и т. п.). Статистике и страхованию Эйлер посвятил немало работ; он, в частности, решал задачу: оценить по статистическим таблицам, какова вероятность того, что человек в возрасте <math>m</math> лет проживёт ещё <math>n</math> лет<ref>{{книга |автор=Гнеденко Б. В. |часть=О работах Леонарда Эйлера по теории вероятностей, теории обработки наблюдений, демографии и страхованию |заглавие=К 250-летию со дня рождения Л. Эйлера |издание=Сборник |издательство=Изд-во АН СССР |год=1958 }}</ref>.

== XIX век ==

=== Общие тенденции и критика ===
В XIX веке число работ по теории вероятностей продолжало расти, были даже компрометирующие науку попытки распространить её методы далеко за разумные пределы — например, на область морали, психологии, правоприменения и даже богословия<ref>{{книга|автор=Вентцель Е. С.|заглавие=Теория вероятностей|издание=Изд. 4-е, стереотипное|место=М.|издательство=Наука|год=1969|страницы=20|страниц=577}}</ref>. В частности, [[Валлийцы|валлийский]] философ [[Прайс, Ричард|Ричард Прайс]], а следом за ним и [[Лаплас, Пьер-Симон|Лаплас]], считали возможным рассчитать по [[Теорема Байеса|формулам Байеса]] вероятность предстоящего восхода Солнца{{sfn |История математики, том III|1972|с=138, 148—149, 151. }}, [[Пуассон, Симеон Дени|Пуассон]] пытался провести вероятностный анализ справедливости судебных приговоров и достоверности показаний свидетелей<ref name=SHEY1977/>. Философ [[Милль, Джон Стюарт|Дж. С. Милль]] в 1843 году, указав на подобные спекулятивные применения, назвал исчисление вероятностей «позором математики»<ref name=GRIG>{{статья |автор=Григорян А. А. |заглавие=Теория вероятностей Р. фон Мизеса: история и философско-методологические основания |издание=[[Историко-математические исследования]] |номер=38 (4) |издательство=Янус-К |место=М. |год=1999 |страницы=198—220}}</ref>. Эта и другие оценки свидетельствовали о недостаточной строгости обоснования теории вероятностей.

Математический аппарат теории вероятностей тем временем продолжал совершенствоваться. Основной сферой её применения в тот период была математическая обработка результатов наблюдений, содержащих случайные погрешности, а также расчёты рисков в [[Страхование|страховом деле]] и других статистических параметров. Среди главных прикладных задач теории вероятностей и математической статистики XIX века можно назвать следующие{{sfn |История математики, том III|1972|с=149. }}:
* найти вероятность того, что сумма независимых случайных величин с одинаковым (известным) законом распределения находится в заданных пределах. Особую важность эта проблема представляла для теории ошибок измерения, в первую очередь для оценки [[Погрешность измерения|погрешности наблюдений]];
* установление [[Статистическая значимость|статистической значимости]] различия случайных значений или серий таких значений. Пример: сравнение результатов применения нового и старого видов лекарств для принятия решения о том, действительно ли новое лекарство лучше;
* исследование влияния заданного фактора на случайную величину ([[факторный анализ]]).
Уже к середине XIX века формируется вероятностная теория артиллерийской стрельбы. В большинстве крупных стран Европы были созданы национальные статистические организации. В конце века область применения вероятностных методов начала успешно распространяться на физику, биологию, экономику, социологию<ref name=ISTIII150/>{{sfn |Математика XIX века. Том I|1978|с=208, 239.|name=ISTXIX208 }}.

=== Гаусс, Лаплас, Пуассон ===
[[Файл:Dice sum central limit theorem.svg|мини|С увеличением числа ''n'' бросков игральной кости её сумма стремится к [[Нормальное распределение|нормальному распределению]]]]
[[Гаусс, Карл Фридрих|Карл Фридрих Гаусс]], постоянно занимавшийся астрономическими вычислениями, разработал вероятностную методику работы с измерениями, содержащими погрешности (1809). Он глубоко изучил [[нормальное распределение]], показал, что оно во многих практических ситуациях является предельным для случайных значений, обосновал применение [[Метод наименьших квадратов|метода наименьших квадратов]] для оценки измеряемого значения и параметров его возможного диапазона разброса. Окончательную версию теории Гаусс изложил в двух трудах «Теория комбинации наблюдений, подверженных случайным ошибкам» (1823, 1828){{sfn |Майстров Л. Е.|1967|с=178—187. }}. Хотя нормальный закон был известен задолго до Гаусса, его вклад в теорию этого важнейшего распределения настолько велик, что долгое время нормальный закон называли «законом Гаусса»; современный термин закрепился благодаря работам [[Пирсон, Карл|Карла Пирсона]] в конце XIX века<ref name=ISTXIX208/>.

Основные достижения теории вероятностей подытожены в капитальной монографии [[Лаплас, Пьер-Симон|Лапласа]] «Аналитическая теория вероятностей» (1812 год), которая завершила «классический этап» развития этой науки. В XIX веке труд Лапласа выдержал во Франции три переиздания и был переведён на многие языки мира{{sfn |История математики, том III|1972|с=150—151.|name=ISTIII150 }}. Лаплас исследовал как дискретные, так и непрерывные случайные величины (ещё не вводя термина «случайная величина»), причём для непрерывных дал ключевое понятие [[Плотность вероятности|плотности распределения вероятности]], ранее неявно и ограниченно использованное Даниилом Бернулли. Интегральное понятие [[Функция распределения|функции распределения]] возникло гораздо позже (его в 1912 году ввёл [[Ляпунов, Александр Михайлович|А. М. Ляпунов]]); общий термин «случайная величина» также, по-видимому, впервые появился в работах русской вероятностной школы{{sfn |Гнеденко Б. В.|2005|с=414. }}. Введение плотности вероятности и [[Характеристическая функция случайной величины|характеристических функций]] позволило Лапласу применить для решения вероятностных задач мощные аналитические средства, включая [[Дифференциальное уравнение в частных производных|дифференциальные уравнения в частных производных]]<ref name=SHEY1977>{{статья |автор=Шейнин О. Б. |заглавие=Теория вероятностей П. С. Лапласа |издание=[[Историко-математические исследования]] |номер=22 |издательство=Наука |место=М. |год=1977 |страницы=212—224. }}</ref>. 

Лаплас привёл [[Формула полной вероятности|формулу полной вероятности]] для нескольких несовместных «причин» (в современной терминологии, «гипотез»), доказал ряд предельных теорем, в том числе [[Локальная теорема Муавра — Лапласа|теорему Муавра—Лапласа]] и сходимость [[Биномиальное распределение|биномиального распределения]] к нормальному при увеличении числа испытаний. Значительная часть книги посвящена статистическим приложениям и решению задач. Для оценки возможного диапазона значений измеряемой величины Лаплас, как и Гаусс, рекомендовал метод наименьших квадратов{{sfn |Майстров Л. Е.|1967|с=167—175. }}.

Лаплас описал и своё понимание сущности случайности и вероятности. По его мнению, ход реальных процессов полностью предопределён ([[Детерминизм|«детерминирован»]]), случайность появляется лишь в человеческом восприятии и только там, где человек не владеет полным знанием происходящего{{sfn |Майстров Л. Е.|1967|с=163. }}:
{{начало цитаты}}
Ум, которому были бы известны для какого-либо данного момента все силы, одушевляющие природу, и относительное положение всех её составных частей, если бы вдобавок он оказался достаточно обширным, чтобы подчинить эти данные анализу, обнял бы в одной формуле движение величайших тел вселенной наравне с движениями легчайших атомов; не осталось бы ничего, что было бы для него недостоверно, и будущее, так же, как и прошедшее, предстало бы пред его взором.{{конец цитаты}}

[[Пуассон, Симеон Дени|Симеон Дени Пуассон]] в 1837 году обобщил закон больших чисел Бернулли, сняв условие о том, что вероятность события в каждой игре одна и та же; при этих новых условиях статистическая частота будет сходиться к [[Среднее арифметическое|среднему арифметическому]] для вероятностей отдельных игр{{sfn |Майстров Л. Е.|1967|с=187—189. }}. Он же опубликовал [[Формула Пуассона|формулу Пуассона]], удобную для описания схемы Бернулли в том случае, когда вероятность события близка к нулю или к единице. [[Распределение Пуассона]] («закон редких событий») является одним из основных в прикладных задачах, например, ему подчиняются [[радиоактивный распад]], рождение тройни, статистика аварий и несчастных случаев{{sfn |Никифоровский В. А.|1992|с=113—114. }}.

=== Теория ошибок измерения ===
Основная проблема в этой области следующая. Пусть последовательные измерения некоторой величины дали <math>n</math> близких, но неравных значений. Подразумевается, что систематические ошибки и зависимость величины от времени измерения (скажем, при вращении [[Небесная сфера|небесного свода]]) учтены, так что различие данных вызвано чисто случайными погрешностями. Надо по результатам измерений найти наилучшую оценку истинного значения исследуемой величины<ref>{{книга|автор=Щиголев Б. М.|заглавие=Математическая обработка наблюдений|издание=Изд. 2-е, стереотипное|место=М.|издательство=Физматлит|год=1962|страницы=209—215|страниц=344}}</ref>.

Первое математическое исследование этой практически важной (особенно в астрономии) темы предпринял [[Симпсон, Томас|Томас Симпсон]] (1755). Он исходил из неверной гипотезы, что [[Погрешность измерения|ошибки измерения]] распределены по «треугольному закону», но сделал правильный вывод — [[среднее арифметическое]] результатов измерения ближе к истинному значению, чем отдельное измерение. [[Даниил Бернулли]] (1778) считал, что плотность распределения ошибок представляет собой дугу окружности, но вывод Симпсона подтвердил{{sfn |Гнеденко Б. В.|2005|с=408—411.|name=GN408 }}. Идеи Симпсона развил [[Ламберт, Иоганн Генрих|И. Г. Ламберт]], впервые применивший [[Производящая функция моментов|метод производящих функций]] и [[метод максимального правдоподобия]], позднее обобщённый [[Рональд Эйлмер Фишер|Р. Э. Фишером]]{{sfn |История математики, том III|1972|с=134. }}.

В XIX веке Лаплас указал, что наблюдаемые погрешности измерения являются обычно результатом суммирования множества случайных ошибок, и поэтому их распределение должно быть близко к [[Нормальное распределение|нормальному]]. Вместо среднего арифметического он предложил [[Медиана (статистика)|статистическую медиану]]. Однако почти одновременно был опубликован гораздо более практичный [[метод наименьших квадратов]] [[Гаусс, Карл Фридрих|Гаусса]] (1809), который и стал общеупотребительным. В 1853 году [[Коши, Огюстен Луи|Коши]] обнаружил [[Распределение Коши|пример распределения]], для которого среднее арифметическое является очень плохой оценкой. К концу XIX века статистическая теория обработки ошибок была в основном завершена<ref name=GN408/>.

=== [[Парадокс Бертрана (вероятность)|Парадоксы Бертрана]] ===
В 1889 году французский математик [[Бертран, Жозеф Луи Франсуа|Жозеф Бертран]] в своём курсе «Анализ вероятностей» предложил ряд [[Парадокс Бертрана (вероятность)|парадоксов]], связанных с геометрической вероятностью. В каждом парадоксе разное истолкование понятий «наудачу» или «взятое произвольно» приводило к разным решениям задачи. Пример одного из парадоксов Бертрана: найти вероятность того, что выбранная наудачу [[Хорда (геометрия)|хорда окружности]] окажется длиннее стороны вписанного в эту окружность треугольника. При разных методах выбора хорды «наудачу» получаются разные ответы.
<center><gallery>
Файл:bertrand1-figure.svg|<center>Метод 1</center>
Файл:bertrand2-figure.svg|<center>Метод 2</center>
Файл:bertrand3-figure.svg|<center>Метод 3</center>
</gallery></center>
Обсуждение парадоксов Бертрана содействовало уточнению оснований теории вероятностей и смысла термина «равновероятно»{{sfn |Майстров Л. Е.|1967|с=279—285. }}.

=== Статистическая физика ===
[[Файл:Boltzmann2.jpg|мини|220px|Людвиг Больцман]]
До середины XIX века практическое применение теории вероятностей было в основном ограничено [[Статистика|статистикой]] и [[Вычислительная математика|приближёнными вычислениями]], поэтому общий термин «случайная величина» появился довольно поздно{{sfn |Гнеденко Б. В.|2005|с=417—418.  }}. Одним из первых [[Случайный процесс|случайных процессов]] в физике стало изученное [[Броун, Роберт|Робертом Броуном]] в [[1827 год]]у под микроскопом хаотическое движение цветочной пыльцы, плававшей в воде («[[броуновское движение]]»). Его [[математическая модель]], однако, появилась только в начале XX века ([[Эйнштейн, Альберт|А. Эйнштейн]], [[Смолуховский, Мариан|М. Смолуховский]], [[Винер, Норберт|Н. Винер]])<ref>{{книга |автор=Спасский Б. И. |заглавие=История физики |место= М. |издательство= Высшая школа |год=1977 |том=II |ссылка=http://osnovanija.narod.ru/History/Spas/T2_1.djvu |страницы=74—75 }}</ref>.

Первые физические вероятностные модели возникли в [[Статистическая физика|статистической физике]], которую разработали во второй половине XIX века [[Больцман, Людвиг|Л. Больцман]], [[Максвелл, Джеймс Клерк|Д. К. Максвелл]] и [[Гиббс, Джозайя Уиллард|Д. У. Гиббс]]. Больцман в серии работ (1860-е годы) показал, что термодинамические законы имеют вероятностно-статистический характер и связаны с переходом физических систем из менее вероятного состояния в более вероятное, причём мерой вероятности является [[энтропия]]. Максвелл в эти же годы вывел [[Распределение Максвелла|закон распределения скоростей молекул]] в газе, который позволяет рассчитать [[Энергия|энергию]], [[Длина свободного пробега|длину свободного пробега]] и другие характеристики молекул. В 1902 году Гиббс опубликовал монографию «Основные принципы статистической механики», оказавшую большое влияние на развитие физики{{sfn |Майстров Л. Е.|1967|с=268—276. }}. К концу XIX века огромное практическое значение вероятностных методов стало общепризнанным фактом.

=== Российская школа ===
В России в первой половине XIX века начали возникать собственные серьёзные исследования по теории вероятностей. Первый учебный курс начал читать С. Ревковский в [[Вильнюсский университет|Вильнюсском университете]] (1829 год), там же в 1830 году была создана первая в Российской империи кафедра теории вероятностей. В [[Санкт-Петербургский государственный университет|Петербургском университете]] лекции с 1837 года читал сначала [[Анкудович, Викентий Александрович|В. А. Анкудович]], а с 1850 года — [[Буняковский, Виктор Яковлевич|В. Я. Буняковский]]. Фундаментальный учебник «Основания математической теории вероятностей» Буняковский опубликовал в 1846 году, и придуманная им русская терминология стала общепринятой. В [[Московский государственный университет|Московском университете]] курс появился в 1850 году, лекции читал [[Давидов, Август Юльевич|А. Ю. Давидов]], будущий президент [[Московское математическое общество|Московского математического общества]]{{sfn |Майстров Л. Е.|1967|с=191—197, 204—213. }}.

Статьи по вероятностным темам публиковали многие крупные математики России, в том числе [[Остроградский, Михаил Васильевич|М. В. Остроградский]], [[Брашман, Николай Дмитриевич|Н. Д. Брашман]], [[Лобачевский, Николай Иванович|Н. И. Лобачевский]], [[Зернов, Николай Ефимович|Н. Е. Зернов]]. В значительной части этих работ ощущается сильное влияние трудов и взглядов Лапласа{{sfn |Майстров Л. Е.|1967|с=197—204, 214. }}.

[[Файл:PL Chebyshev.jpg|мини|слева|П. Л. Чебышёв]]
Первыми русскими математиками мирового уровня в теории вероятностей стали [[Чебышёв, Пафнутий Львович|П. Л. Чебышёв]] и его ученики [[Марков, Андрей Андреевич (старший)|А. А. Марков]] и [[Ляпунов, Александр Михайлович|А. М. Ляпунов]]. Чебышёв с самого начала своей научной карьеры уделял наибольшее внимание теории вероятностей (наряду с [[Теория чисел|теорией чисел]]), а с 1860 года сменил Буняковского на кафедре теории вероятностей и начал свой цикл лекций. Он опубликовал по данной теме всего четыре работы, но фундаментального характера. Особенно интересна его статья «О средних величинах» (1866 год), где приведено «[[неравенство Чебышёва]]», позднее [[Неравенство Маркова|усиленное Марковым]]:
: <math>\mathbb{P}\left(|x - Mx|\geqslant k \sigma \right) \leqslant \frac{1}{k^2}</math>.
[[Файл:Txebixev 01.png|мини|[[Неравенство Чебышёва]], ограничивающее вероятность больших отклонений [[Случайная величина|случайной величины]] от своего [[Математическое ожидание|математического ожидания]]]]
Эта формула означает, что вероятность отклонения любой случайной величины <math>x</math> от её среднего значения ([[Математическое ожидание|математического ожидания]]) <math>Mx</math> более чем на <math>k</math> [[Среднеквадратическое отклонение|стандартных отклонений]] (<math>\sigma</math>) не превышает <math>~\frac{1}{k^2}</math>. Например, отклонение на 5 <math>\sigma</math> имеет вероятность 1/25, то есть 4 %.

В качестве следствия своего неравенства Чебышёв получил чрезвычайно общую формулировку [[Закон больших чисел|закона больших чисел]]: если математические ожидания серии <math>n</math> случайных величин и квадраты этих математических ожиданий ограничены в совокупности, то среднее арифметическое этих величин с ростом <math>n</math> сходится к среднему арифметическому для их математических ожиданий. Из этой теоремы получаются как следствия теоремы Бернулли и Пуассона; Чебышёв впервые строго оценил точность этих теорем и других приближений{{sfn |Майстров Л. Е.|1967|с=225—238. }}.

В 1887 году появилась статья Чебышёва «О двух теоремах относительно вероятностей». В этой работе он установил, что при некоторых (достаточно общих) условиях выполняется предельная теорема: сумма большого числа независимых случайных величин (например, погрешностей измерения) распределена приближённо по нормальному закону и тем точнее, чем больше слагаемых. Этот результат по своей общности далеко перекрывает [[Локальная теорема Муавра — Лапласа|теорему Муавра — Лапласа]] и все её аналоги<ref>{{книга|автор=Чебышёв П. Л.&nbsp;|заглавие=Полное собрание сочинений|издательство=Изд-во АН СССР |год=1948|том=III|страницы=404}}</ref>. Позже А. А. Марков и А. М. Ляпунов уточнили и ещё более обобщили данную теорему Чебышёва.

Обе упомянутые теоремы Чебышёва занимают центральное место в теории вероятностей. Особенно важно то обстоятельство, что Чебышёв не только указал предельное распределение, но в обоих случаях детально проанализировал границы возможных отклонений от этого предела<ref name=KOLMO1947>{{статья|автор=Колмогоров А. Н.|заглавие=Роль русской науки в развитии теории вероятностей|издание=Учёные записки МГУ|место=Μ.|год=1947|том=I|выпуск=91, кн.1 |страницы=53—64 }}</ref>.

Если Чебышёв исследовал независимые случайные величины, то [[Марков, Андрей Андреевич (старший)|А. А. Марков]] в 1907 году расширил поле исследований, рассматривая и случай, когда новое случайное значение зависит от старого. Марков доказал вариант закона больших чисел для некоторых распространённых типов зависимых величин, введя в терминологию мировой науки «[[цепи Маркова]]». Анализу и классификации этих цепей Марков посвятил немало работ; цепи Маркова и [[Марковские процессы|марковские случайные процессы]] применяются не только в математике, но и в других науках, таких как [[статистическая физика]], [[квантовая механика]], [[теория автоматического управления]] и многие другие{{sfn |Майстров Л. Е.|1967|с=253—259. }}. Маркову принадлежит также вероятностное обоснование метода наименьших квадратов{{sfn|Стройк Д. Я.|1984|с=255.}}.

[[Ляпунов, Александр Михайлович|А. М. Ляпунову]] принадлежит введение [[характеристическая функция случайной величины|метода характеристических функций]] в учение о предельных теоремах теории вероятностей{{sfn|Стройк Д. Я.|1984|с=255.}}.

== XX век ==

=== Теоретические вопросы и математические методы ===
В XX веке исследования Чебышёва и Маркова продолжили [[Хинчин, Александр Яковлевич|А. Я. Хинчин]], [[Колмогоров, Андрей Николаевич|А. Н. Колмогоров]] и др. В частности, [[Линдеберг, Ярл Вальдемар|Ярл В. Линдеберг]] (1922) и Колмогоров (1926) нашли условия, необходимые и достаточные для выполнения закона больших чисел{{sfn |Майстров Л. Е.|1967|с=310—311. }}.

Математический аппарат теории вероятностей значительно обогатился во многих направлениях. После разработки [[Мера множества|теории меры]] это общее понятие оказалось удобно применить к теории вероятностей, то есть рассматривать [[Вероятностная мера|вероятность как меру]] (конечного или бесконечного) множества «благоприятных событий». Такой подход позволяет описывать и исследовать свойства вероятности на хорошо разработанном языке [[Теория множеств|теории множеств]]<ref>{{cite web|url=http://www.nsu.ru/mmf/tvims/chernova/tv/lec/node10.html|title=Мера и вероятностная мера|author=Чернова Н. И.|accessdate=2014-01-11}}</ref>.

[[Файл:N-body problem (3).gif|thumb|240px|left|<center>Хаотическое движение в задаче трёх тел (компьютерное моделирование)</center>]]
В теории [[Динамическая система|динамических систем]] было обнаружено, что решения [[Дифференциальное уравнение|дифференциальных уравнений]] некоторых систем ведут себя как [[Случайный процесс|случайные процессы]]. Это крупное открытие привело к созданию понятия «[[динамический хаос]]» и [[Теория хаоса|общей «теории хаоса»]]. Одним из примеров является «[[задача трёх тел]]» [[Небесная механика|небесной механики]]<ref>{{статья |автор=Тихомиров В. |заглавие=Математика во второй половине XX века |ссылка=http://vivovoco.rsl.ru/quantum/2001.01/TIKH_1_01.PDF |издание=[[Квант (журнал)|Квант]]|номер=1|год=2001 }}</ref>.

До XX века использовались в основном нормальное, биномиальное и (иногда) [[Распределение Пуассона|пуассоновское распределения]], однако практически полезными оказались и многие другие [[:Категория:Непрерывные распределения|теоретические законы]]. Например, [[логнормальное распределение]] часто встречается в ситуациях, когда исследуемая величина есть произведение нескольких независимых положительных случайных величин<ref>{{книга |часть=Логарифмически нормальное распределение |заглавие=Математическая энциклопедия (в 5 томах) |место=М. |год=1982 |том=3 |ссылка=http://eqworld.ipmnet.ru/ru/library/books/Vinogradov_MatEnc_t3.djvu |издательство=[[Большая Российская энциклопедия (издательство)|Советская Энциклопедия]] }}</ref>.

Вероятностные методы оказались плодотворными во многих областях теоретической и прикладной математики, даже в таких классических, как [[теория чисел]]<ref>{{книга|автор=Постников А. Г.|заглавие=Вероятностная теория чисел |место=М. |издательство=Знание|год=1974|страниц=63}}</ref> или [[логика]]<ref>{{cite web |url=http://dic.academic.ru/dic.nsf/enc_philosophy/200|title=Вероятностная логика|accessdate=2014-01-10}}</ref>. В свою очередь, современная теория вероятностей использует методы и подходы, разработанные в [[Функциональный анализ|функциональном анализе]], [[Топология|топологии]] и других разделах математики, появившихся в XX веке<ref>{{книга |часть=Теория вероятностей |заглавие=Математика в СССР за сорок лет, 1917—1957 |том=I |место=М. |издательство=Физматгиз |год=1959 }}</ref>.

=== Создание математической статистики ===
[[Файл:Karl Pearson.jpg|мини|Карл Пирсон]]
[[Математическая статистика]] как основа для принятия надёжных решений о случайных величинах возникла на рубеже XIX—XX веков благодаря основополагающим работам [[Пирсон, Карл|Карла Пирсона]]. Пирсон разработал теорию [[Корреляционный анализ|корреляции]], [[Критерий согласия Пирсона|критерии согласия]], [[регрессионный анализ]], алгоритмы [[Проверка статистических гипотез|проверки гипотез]], принятия решений и оценки параметров<ref>{{MacTutor Biography|id=Pearson|title=Пирсон, Карл}}</ref>. Алгоритмы, предложенные Пирсоном, находят широкое применение в физике, медицине, биологии, социологии, сельском хозяйстве и др.<ref>{{книга|автор=Porter, T. M.|заглавие=Karl Pearson: The Scientific Life in a Statistical Age|издательство=Princeton University Press|год=2004|isbn=978-0-691-12635-7}}.</ref>

Виднейшим продолжателем работ Пирсона по прикладной математической статистике в первой половине XX века стал [[Рональд Эйлмер Фишер]]. Он опубликовал работы по [[Планирование эксперимента|планированию эксперимента]], разработал [[метод максимального правдоподобия]], [[Точный тест Фишера|тест статистической значимости]], [[дисперсионный анализ]] и решение ряда других практически важных статистических проблем. Совместно с [[Нейман, Ежи|Ежи Нейманом]] разработал концепцию [[Доверительный интервал|доверительного интервала]] (1937). Фишер — автор общепризнанного термина «[[дисперсия случайной величины]]» ({{lang-en|variance}})<ref>{{cite web |url=http://digital.library.adelaide.edu.au/dspace/bitstream/2440/15097/1/9.pdf|title=The correlation between relatives on the supposition of Mendelian Inheritance|date=1918|accessdate=2013-12-29}}</ref>.

Начиная примерно с 1920-х годов, быстро развивается теория [[Статистический контроль качества|статистического контроля качества]] промышленной продукции. Первую проблему по этой теме рассмотрел ещё [[Симпсон, Томас|Томас Симпсон]] в 1846 году. В массовом производстве надо определить, по какой методике следует изъять предметы из одной или нескольких партий продукции для проверки их качества{{sfn |Гнеденко Б. В.|2005|с=403—405. }}.

Изобилие в наши дни статистических исследований, нередко дающих противоположные результаты (например, о наличии или отсутствии вреда от [[Мобильный телефон|мобильных телефонов]] или [[Генетически модифицированный организм|генно-модифицированных продуктов]]), сделало актуальной и часто обсуждаемой проблему обеспечения достоверных выводов из статистического обследования. Наиболее частая ошибка — объявление, что статистическая зависимость ([[корреляция]]) изучаемых факторов якобы свидетельствует о причинной связи между ними, хотя часто связь этих факторов реально объясняется их зависимостью от одного или нескольких третьих факторов<ref>{{cite web|url=http://www.psychologos.ru/articles/view/korrelyaciya_ili_prichinno-sledstvennaya_svyaz|title=Корреляция или причинно-следственная связь |author=Майерс Дэвид Дж. |accessdate=2014-01-06}}</ref>. «Статистическая зависимость, как бы ни была она сильна, никогда не может установить причинной связи: наши идеи о причине должны приходить извне статистики, в конечном счёте из некоторой другой теории»<ref>{{книга|автор=Кендалл М., Стьюарт А.|заглавие=Статистические выводы и связи |место=М. |издательство=Наука |год=1972 |страницы=374 |страниц=900}}</ref>.

=== Случайные процессы ===
[[Файл:White noise.png|мини|Запись случайного процесса ([[белый шум]])]]
Понятие [[Случайный процесс|случайного (или стохастического) процесса]], возникшее в начале XX века, стало одним из центральных, быстро развивающихся и наиболее полезных применений теории вероятностей. Случайный процесс — это переменная во времени случайная величина. Первые исследования случайных процессов касались в основном электроники и сообщений [[Электросвязь|теории связи]], в наши дни можно привести в качестве примеров [[Временной ряд|временные ряды]] в экономике или медицине, регистрограммы [[Теория механизмов и машин|теории механизмов]], статистику жизни [[Популяция|биологии популяций]]. Широкую сферу практического применения имеет [[теория массового обслуживания]]. Среди типовых задач анализа случайных процессов<ref>{{книга|автор=Розанов Ю. А.|заглавие=Случайные процессы. Краткий курс|издание=Изд. 2-е, перераб. и дополн.|место=М.|издательство=Наука|год=1979|страницы=174—183|страниц=184}}</ref>:
* прогнозирование развития процесса, исходя из его прошлой истории;
* надёжное выделение сигнала на фоне шумовых помех;
* оценка и оптимизация параметров (например, вероятного времени безотказной работы);
* фильтрация входного случайного процесса для получения желаемого выходного процесса.

Проведена классификация типов случайных процессов, разработаны аналитические средства их исследования ([[Корреляционная функция|корреляционная]] и [[Ковариационная матрица|ковариационная функции]], спектральное разложение){{sfn |Гнеденко Б. В.|2005|с=430—434. | }}<ref>{{книга |автор=Корн Г., Корн Т. |ссылка=http://eqworld.ipmnet.ru/ru/library/books/Korn1973ru.djvu |заглавие=Справочник по математике (для научных работников и инженеров) |страниц=720 |издательство=Наука |место=М. |год=1973 |страницы=522—534 }}</ref>. Для анализа процессов разработаны такие новые средства, как [[стохастические дифференциальные уравнения]], [[стохастический интеграл]], средства [[Спектральный анализ|спектрального анализа и фильтрации]]<ref>{{книга|автор=Розанов Ю. А. |заглавие=Теория вероятностей, случайные процессы и математическая статистика |место=М. |издательство=Наука |год=1985|страницы=236—282|страниц=320}}</ref>.

=== Новые приложения ===
Новые применения вероятностных методов возникали в XX веке постоянно и во многих науках; кратко перечислим некоторые этапные события в этой тенденции.

; Физика
Центральным понятием созданной в 1920-е годы [[Квантовая механика|квантовой механики]] является [[Комплексное число|комплексная]] [[волновая функция]], квадрат модуля которой, согласно распространённой [[Копенгагенская интерпретация|копенгагенской интерпретации]], определяет плотность вероятности обнаружения микрочастицы в данной точке пространства. Если принять такую интерпретацию, то в математической модели микромира случайность неустранима, а лапласовский [[детерминизм]] полностью опровергнут<ref>{{книга|автор=Детлаф А. А., Яворский Б. М.|заглавие=Курс физики. Учебное пособие|издание=Изд. 2-е|место=М.|издательство=Высшая школа |год=1999 |страницы=514 |страниц=719 |isbn=5-06-003556-5}}</ref>. Для микромира были разработаны специальные [[Квантовая статистика|квантовые статистики]] [[Статистика Бозе — Эйнштейна|Бозе — Эйнштейна]] и [[Статистика Ферми — Дирака|Ферми — Дирака]].

; Биология
После открытий [[Мендель, Грегор Иоганн|Менделя]] и [[Морган, Томас Хант|Моргана]] стало понятно, что наследственные признаки передаются потомкам путём случайной комбинации одного из двух признаков ([[Аллели|аллелей]]) от отца и одного из двух аналогичных аллелей от матери. Случайный выбор аллели отца определяет заодно пол будущего потомка. На этот процесс дополнительно накладываются случайные [[мутации]], поэтому вероятностные методы легли в основу [[Генетика|генетики]]. Применяются они также при исследовании и управлении развитием биологических [[Популяция|популяций]]<ref>{{книга |заглавие=Теория вероятностей и математическая статистика. Математические модели: учеб. пособие по направлению «Биология» |место=Μ.|издательство=Академия|год=2009|страниц=315 |isbn=978-5-7695-4704-1 }}</ref>. Существенно используются вероятностные подходы (например, [[байесовская вероятность|байесовские методы]] и методы, основанные на [[метод максимального правдоподобия|принципе наибольшего правдоподобия]]) в {{нп5|вычислительная филогенетика|вычислительной филогенетике||Computational phylogenetics}}, предусматривающей применение специальных вычислительных алгоритмов и компьютерных программ для построения [[филогенетическое дерево|филогенетических деревьев]]<ref>{{книга|автор=Kolaczkowski B., Thornton J. W.|часть=Long-Branch Attraction Bias and Inconsistency in Bayesian Phylogenetics|ссылка часть=https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2785476/pdf/pone.0007891.pdf|заглавие=''PLoS One'', '''4''' (12), 2009}} — P. e7891. — {{DOI|doi:10.1371/journal.pone.0007891}}.</ref><ref>{{книга|автор=Simmons M. P.|часть=Misleading Results of Likelihood-based Phylogenetic Analyses in the Presence of Missing Data|ссылка часть=https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3676676/|заглавие=''Cladistics'', '''28''' (2), 2012}} — P. 208—222. — {{DOI|10.1111/j.1096-0031.2011.00375.x}}.</ref>.

; Кибернетика и теория информации
[[Теория информации]] опирается на введённое [[Шеннон, Клод|Клодом Шенноном]] в 1948 году понятие [[информационная энтропия|информационной энтропии]]<ref>{{cite web|url=http://www.krugosvet.ru/enc/nauka_i_tehnika/matematika/INFORMATSII_TEORIYA.html |title=Информации теория |publisher=Энциклопедия «Кругосвет»|accessdate=2013-12-29}}</ref>. Если случайная величина <math>x</math> может принимать значения <math>~x_1, x_2, \dots x_n</math>, вероятности которых соответственно равны <math>~p_1, p_2, \dots p_n</math>, то энтропия определяется формулой:
: <math>H(x)=-\sum_{i=1}^n p_i \log_2 p_i</math>.
Определённая так энтропия есть мера случайности (или неопределённости): она равна нулю, если случайность отсутствует, то есть с вероятностью 1 величина принимает одно определённое значение. Увеличение случайности связано с увеличением энтропии<ref>{{книга|автор=Волькенштейн М. В.|заглавие=Энтропия и информация |место=М. |издательство=Наука|год=2006|страниц=325 }}</ref>.

[[Теория автоматического управления]] также изначально использовала вероятностные методы. С появлением компьютеров применение таких методов многократно расширилось. Используя [[генератор псевдослучайных чисел]], можно промоделировать на компьютере случайные величины или процессы с произвольным распределением, а это, в свою очередь, позволяет исследовать самые разные реальные процессы путём их [[компьютерное моделирование|компьютерного моделирования]] ([[метод Монте-Карло]])<ref>{{книга|автор=Соболь И. М.|заглавие=Метод Монте-Карло |место=Μ. |издательство=Наука |год=1968|серия=Популярные лекции по математике, вып. 46}}</ref>.

; Лингвистика
Во 2-й половине XX века в важное направление [[математическая лингвистика|математической лингвистики]] оформилось применение методов теории вероятностей и математической статистики к изучению лингвистических явлений. Многочисленные исследования, основанные на применении таких методов, включали: получение вероятностно-информационных оценок [[языковая норма|нормы]] языка; анализ распределения синтактической информации в пределах [[словоформа|словоформы]], контекстной обусловленности и избыточности [[текст]]ов, взаимодействия случайных и детерминированных процессов в [[речь|речи]]; разработку адекватных методик лингвистического эксперимента; выявление статистических характеристик лингвистических вариационных рядов и др.<ref>{{книга|автор=[[Пиотровский, Раймонд Генрихович|Пиотровский Р. Г.]], [[Бектаев, Калдыбай Бектаевич|Бектаев К. Б.]], [[Пиотровская, Анна Александровна|Пиотровская А. А.]]&nbsp;|заглавие=Математическая лингвистика|место=М.|издательство=Высшая школа|год=1977|страниц=383}} — С. 8—10, 110, 142, 189, 205—207, 233.</ref>

=== Обоснование и аксиоматизация ===
К моменту создания теории вероятностей основой математики были два класса [[Математический объект|объектов]] — числа и геометрические фигуры. Для теории вероятностей потребовалось добавить в этот список совершенно особый объект: [[случайное событие]], а также тесно связанные с ним понятия (вероятность, случайная величина и др.). Своеобразие новой науки проявлялось и в том, что её утверждения носили не безусловный характер, как ранее было принято в математике, а предположительно-вероятностный.

По мере развития теории вероятностей не прекращались споры о том, можно ли считать [[Идеализация|идеализированное]] событие математическим понятием (и тогда теория вероятностей есть часть математики) или же это факт, наблюдаемый в опыте (и тогда теорию вероятностей следует отнести к естественным наукам). Разные учёные высказывали самые разные мнения на этот счёт. [[Чебышёв, Пафнутий Львович|П. Л. Чебышёв]] уверенно считал теорию вероятностей математической дисциплиной, задача которой — по известным вероятностям некоторых событий определить неизвестную вероятность исследуемого события. По мнению [[Давид Гильберт|Давида Гильберта]], теория вероятностей родственна механике, то есть представляет собой математизированную «физическую дисциплину»<ref name=GRIG/>. [[Морган, Огастес де|Август де Морган]] и его последователь [[Джевонс, Уильям Стенли|У. С. Джевонс]] считали базовым понятием «субъективную вероятность», то есть количественную меру нашего понимания предмета исследования, и связывали теорию вероятностей с логикой{{sfn |Математика XIX века. Том I|1978|с=238—239. }}. Проблемы, связанные с неоднозначной субъективной вероятностью, неоднократно обсуждались, их часто формулируют в виде «вероятностных парадоксов» (см., например, «[[Задача трёх узников|парадокс трёх узников]]» или «[[парадокс мальчика и девочки]]»).

Ещё Бернулли дал фактически два определения вероятности: как доли «благоприятных случаев» и как статистической частоты; чтобы свести второе понимание к первому, понадобился [[закон больших чисел]]. Австрийский математик и экономист [[Людвиг фон Мизес]] предложил обратный подход (1914 год): считать определением вероятности именно предел частоты. Теорию вероятностей Мизес к математике не относил, он считал её опытной наукой, изучающей наблюдаемые факты<ref name=GRIG/>. Определение Мизеса и изложенная им аксиоматика подверглись критике за бессодержательность, поскольку не существует средств для выяснения, имеет ли частота заданного события предел<ref>{{статья|автор=Хинчин А. Я.|заглавие=Частотная теория Р. Мизеса и современные идеи теории вероятности|издание=Вопросы философии|год=1961|страницы=91—102 (вып. 1), 77—89 (вып. 2)}}</ref>. Обсуждение концепции Мизеса иногда продолжается и в наши дни{{sfn |Гнеденко Б. В.|2005|с=407. }}. Были и другие попытки обоснования — [[Джон Мейнард Кейнс]] (1921) и [[Гарольд Джеффрис]] (1939) предложили понимать вероятность утверждения как «степень правдоподобия» этого утверждения, этот подход также время от времени упоминается в обсуждении вопроса<ref>{{книга|автор=Robert C. P., Chopin N., Rousseau J.|часть=Harold Jeffreys’s Theory of Probability Revisited|ссылка часть=http://arxiv.org/pdf/0804.3173.pdf|заглавие=''Statistical Science'', '''24''' (2), 2009}} — P. 141—172.</ref>.

[[Файл:Andrej Nikolajewitsch Kolmogorov.jpg|мини|[[А. Н. Колмогоров]]]]
В начале XX века школа Д. Гильберта поставила такие классические разделы математики, как геометрия и анализ, на строгую [[Аксиоматика|аксиоматическую]] основу, появилась аксиоматика и в других разделах математики: [[теория множеств]], [[математическая логика]] и др. Назрела необходимость разработать аксиоматику и для теории вероятностей, поскольку старое, полуинтуитивное и неформальное обоснование Бернулли и Лапласа давно устарело. Первый вариант такой аксиоматики дал советский математик [[Бернштейн, Сергей Натанович|С. Н. Бернштейн]] в своём курсе «Теория вероятностей» (1927 год). Общепризнанным в науке стал [[Аксиоматика Колмогорова|вариант А. Н. Колмогорова]], опубликованный в 1929—1933 годах и основанный на идеях [[Мера множества|теории меры]]{{sfn |Майстров Л. Е.|1967|с=297—302, 311—313. }}. Во второй половине XX века [[Реньи, Альфред|Альфред Реньи]] и А. Н. Колмогоров исследовали возможность дать обоснование теории вероятностей на базе [[Теория информации|теории информации]]{{sfn |Гнеденко Б. В.|2005|с=407—408 }}. В наши дни «сложилось чёткое понимание того, что теория вероятностей является подлинно математической наукой, имеющей вместе с тем самые тесные и непосредственные связи с широким спектром наук о природе, а также с техническими и социально-экономическими дисциплинами»{{sfn |Математика XIX века. Том I|1978|с=240. }}.

Несмотря на доказанную практикой эффективность вероятностных методов, роль случайности в природе, причина и границы статистической устойчивости остаются предметом дискуссий<ref>{{статья |автор=Алимов Ю. И., Кравцов Ю. А. |заглавие=Является ли вероятность «нормальной» физической величиной? |ссылка=http://ufn.ru/ru/articles/1992/7/d/ |издание=Успехи физических наук |место=М. |год=1992 |номер=162 (7) |страницы=149—182 }}</ref>. «За 200 лет, прошедших со времен Лапласа и Гаусса, наука не добилась продвижения в фундаментальном вопросе — когда возникает статистическая устойчивость»<ref>{{статья |автор=Тутубалин В. Н. |заглавие=Вероятность, компьютеры и обработка результатов эксперимента |ссылка=http://ufn.ru/ru/articles/1993/7/g/|издание=Успехи физических наук |место=М. |год=1993 |номер=163 (7) |страницы=93—109 }}</ref>.

== См. также ==
* [[Вероятностная логика]]
* [[Вероятностное пространство]]
* [[:Категория:Вероятностные парадоксы|Вероятностные парадоксы]]
* [[Риск]]
* [[Стохастичность]]

== Примечания ==
{{примечания|3}}

== Литература ==
; Труды основоположников
* {{книга|автор=[[Бернулли, Якоб|Бернулли Я.]] |заглавие=О законе больших чисел |место=Μ. |издательство=Наука |год=1986 |страниц=176 |ref=Бернулли Я.}}
* {{книга|автор=[[Гаусс, Карл Фридрих|Гаусс К. Ф.]] |заглавие=Избранные геодезические сочинения. Т. 1. Метод наименьших квадратов |место=Μ. |издательство=Изд-во геодезической литературы |год=1957 |страниц=234 |ref=Гаусс К. Ф.}} 
* {{книга|автор=[[Лаплас, Пьер-Симон|Лаплас П. С.]] |заглавие=Опыт философии теории вероятностей. 2-е изд |серия=Физико-математическое наследие: математика (философия математики) |место=Μ. |издательство=URSS |год=2011 |страниц=208 |isbn=978-5-397-01695-7 }}.
* {{книга |автор=[[Марков, Андрей Андреевич (старший)|Марков А. А.]] |заглавие=Избранные труды. Теория чисел. Теория вероятностей. |место=Л. |издательство=Изд-во АН СССР |год=1951 |страниц=719}}
* {{книга|автор=[[Реньи, Альфред|Реньи А.]] |заглавие=Письма о вероятности: письма Паскаля к Ферма |место=Μ. |издательство=Мир |год=1970 |страниц=96}}
** Рецензия: {{статья|автор=Майстров Л. Е. |заглавие=О вероятностной концепции Паскаля у А. Реньи|год=1977 |место=Μ. |издание=[[Историко-математические исследования]]|издательство=Наука  |номер=22 |страницы=200—211 }}
* {{книга |заглавие=Хрестоматия по истории математики. Математический анализ. Теория вероятностей |ответственный=Под ред. [[Юшкевич, Адольф Павлович|А. П. Юшкевича]] |место=М. |издательство=Просвещение |год=1977 |страниц=224 |ref=Хрестоматия по истории математики }}
* {{книга |автор=[[Чебышёв, Пафнутий Львович|Чебышёв П. Л.]] |место=М.—Л. |год=1936 |издательство=Изд-во АН СССР |страниц=253  |заглавие=Теория вероятностей. Лекции акад. П. Л. Чебышёва, читанные в 1879/80 г. }}

; Современные исследования
* {{книга |автор=Вилейтнер Г. |заглавие=История математики от Декарта до середины XIX столетия
  |издательство=ГИФМЛ |место=М. |год=1960 |страниц=468 |ref=Вилейтнер Г.
  |ссылка=http://www.math.ru/lib/book/djvu/istoria/vileitner.djvu }}
* {{статья |автор=[[Гнеденко, Борис Владимирович|Гнеденко Б. В.]] |заглавие=К истории основных понятий теории вероятностей
  |издание=История и методология естественных наук |издательство=Изд. МГУ |выпуск=XXXII. Математика, механика
  |место=М. |год=1986 |страницы=81—88 |ref=К истории основных понятий теории вероятностей }} 
* {{книга |автор=Гнеденко Б. В. |часть=Очерк по истории теории вероятностей
  |заглавие=Курс теории вероятностей. 8-е изд |место=Μ. |издательство=Едиториал УРСС
  |год=2005 |страниц=448 |isbn=5-354-01091-8  |ref=Гнеденко Б. В. }}. — С. 366—435.
* {{книга |заглавие=Математика XIX века. Математическая логика, алгебра, теория чисел, теория вероятностей. Том I |ответственный=Под ред. А. Н. Колмогорова, А. П. Юшкевича |место=М. |издательство=Наука |страниц=255 |год=1978 |ref=Математика XIX века. Том I }}
* {{книга|автор=Майстров Л. Е. |заглавие=Теория вероятностей. Исторический очерк |место=Μ. |издательство=Наука |год=1967 |страниц=321 |ref=Майстров Л. Е. }}
* {{книга |заглавие=История математики. Т. II. Математика XVII столетия |ссылка=http://ilib.mccme.ru/djvu/istoria/istmat2.htm |ответственный=Под ред. [[Юшкевич, Адольф Павлович|А.&nbsp;П.&nbsp;Юшкевича]] |место=М. |издательство=Наука |год=1970 |страниц=301 |ref=История математики, том II }}
* {{книга |заглавие=История математики. Т. III. Математика XVIII столетия |ссылка=http://ilib.mccme.ru/djvu/istoria/istmat3.htm |ответственный=Под ред. [[Юшкевич, Адольф Павлович|А.&nbsp;П.&nbsp;Юшкевича]] |место=М. |издательство=Наука |год=1972 |страниц=496 |ref=История математики, том III }}
* {{книга|автор=Никифоровский В. А. |заглавие=Вероятностный мир |место=М. |издательство=Наука
  |год=1992|серия=История науки и техники |страницы=48|isbn=5-02-003523-8 |ref=Никифоровский В. А. }}.
* {{книга |автор=Стройк Д. Я. |заглавие=Краткий очерк истории математики |ссылка=http://www.reshebnik.ru/history/ |издание=Изд. 3-е |место=М. |издательство=Наука |год=1984 |страниц=285 |ref=Стройк Д. Я.}}
* {{статья |автор=Шейнин О. Б. |заглавие=Теория вероятностей до П. Л. Чебышёва |издание=[[Историко-математические исследования]] |номер=23 |издательство=Наука |место=М. |год=1978
  |страницы=284—306 |ref=Шейнин О. Б. }}

== Ссылки ==
* {{cite web|url=http://www.math.rutgers.edu/~cherlin/History/Papers2000/cheng.html |lang=en
  |title=The Origin of Probability and The Problem of Points|author=Jui-Pin Cheng.|date=2000|accessdate=2013-12-30 }}.
* {{cite web|url=http://www.glennshafer.com/assets/downloads/articles/article50.pdf |lang=en
  |title=The Early Development of Mathematical Probability |author=Glenn Shafer. |accessdate=2013-12-30 }}.


{{История математики}}

{{Избранная статья|Наука}}

[[Категория:Теория вероятностей]]
[[Категория:Математическая статистика]]
[[Категория:История статистики]]

{{Link GA|de}}