'''Индексирование''', совершаемое [[Поисковая машина|поисковой машиной]], — процесс сбора, сортировки и хранения данных с целью обеспечить быстрый и точный [[Информационный поиск|поиск информации]]. Создание индекса{{Переход|#Индексация}} включает междисциплинарные понятия из [[Лингвистика|лингвистики]], [[Когнитивная психология|когнитивной психологии]], [[Математика|математики]], [[информатика|информатики]] и [[Физика|физики]]. [[Индексация в поисковых системах|Веб-индексированием]] называют процесс индексирования в контексте поисковых машин, разработанных, чтобы искать [[веб-страницы]] в Интернете.

Популярные поисковые машины сосредотачиваются на полнотекстовой индексации документов, написанных на [[Естественный язык|естественных языках]]{{sfn|Clarke,Cormack|1995}}. [[Мультимедиа|Мультимедийные документы]], такие как видео и аудио{{sfn|Rice,Bailey}} и графика{{sfn|Jacobs,Finkelstein,Salesin|2006}}{{sfn|Lee}} также могут участвовать в поиске.

[[Метапоисковая система|Метапоисковые машины]] используют индексы других поисковых сервисов и не хранят локальный индекс, в то время как поисковые машины, основанные на кешированных страницах, долго хранят как индекс, так и [[текстовый корпус|корпусы]]. В отличие от полнотекстовых индексов, частично-текстовые сервисы ограничивают глубину индексации, чтобы уменьшить размер индекса. Большие сервисы, как правило, выполняют индексацию в заданном временном интервале из-за необходимого времени и затрат на обработку, в то время как поисковые машины, основанные на [[Интеллектуальный агент|агентах]], строят индекс в масштабе [[реальное время|реального времени]].

== Индексация ==
Цель использования индекса — повышение скорости поиска [[Релевантность|релевантных]] документов по [[Поисковый запрос|поисковому запросу]]. Без индекса поисковая машина должна была бы [[Лексический анализ|сканировать]] каждый документ в корпусе, что потребовало бы большого количества времени и вычислительной мощности. Например, в то время, как индекс 10 000 документов может быть опрошен в пределах миллисекунд, последовательный просмотр каждого слова в 10 000 больших документов мог бы занять часы. Сэкономленное на поиске информации время компенсирует дополнительную память, выделяемую для хранения индекса, и увеличение времени, требуемое для обновления индекса.

===Факторы, влияющие на создание поисковых систем===
При разработке [[Поисковая система|поисковой системы]] необходимо учитывать следующие факторы:
;Факторы слияния :Как данные входят в индекс, как слова и подчиненные функции добавляются в индекс во время текстового корпусного обхода, и могут ли несколько [[Поисковый робот|поисковых роботов]] работать асинхронно. Поисковый робот должен сначала проверить, обновляет он старое содержание или добавляет новое. Слияние индекса{{Переход|#Слияние индекса}} поисковой системы подобно [[Merge (SQL)|SQL Merge]] и другим алгоритмам слияния{{sfn|Brown|1996}}.
;Методы хранения :Как хранить индексируемые [[Данные|данные]], т.е. информация должна храниться в виде сжатых или отфильтрованных данных.
;Размер индекса :Сколько памяти компьютера необходимо, чтобы поддерживать индекс.
;Скорость поиска :Как быстро можно найти слово в [[Инвертированный индекс|инвертированном индексе]]. Скорость нахождения записи в структуре данных по сравнению с тем, как быстро можно обновить или удалить индекс, является центром информатики.
;Хранение :Как хранится индекс в течение длительного времени{{sfn|Cutting,Pedersen|1990}}.
;Отказоустойчивость :Для службы важно быть надежной. Вопросы [[Отказоустойчивость|отказоустойчивости]] включают проблему повреждения индекса, определяя, можно ли отдельно рассматривать некорректные данные, связанные с плохими аппаратными средствами, [[Секционирование|секционированием]] и схемами на основе [[Хеширование|хеш-функций]] и композитного секционирования{{sfn|mysql}}, а также [[Репликация (вычислительная техника)|репликации]].

===Индексные структуры данных===
Архитектура поисковой системы различается по способам индексирования и по методам хранения индексов, удовлетворяя факторы {{Переход|#Факторы, влияющие на создание поисковых систем}}. Типы индексов бывают:
;[[Суффиксное дерево]]:Образно структурировано как дерево, поддерживает линейное время поиска. Построено на хранении суффиксов слов. Суффиксное дерево имеет тип [[Префиксное дерево|дерево]]. Деревья поддерживают расширенное хеширование, которое важно для индексации поисковой системы{{sfn|trie}}. Используется для поиска по шаблону в последовательностях [[Дезоксирибонуклеиновая кислота|ДНК]] и [[Кластеризация документов|кластеризации]]. Основным недостатком является то, что хранение слова в дереве может потребовать пространство за пределами необходимого для хранения самого слова{{sfn|Gusfield|1997}}. Альтернативное представление - [[Суффиксный массив|суффиксный массив]]. Считается, что он требуют меньше виртуальной памяти и поддерживает [[Преобразование Барроуза — Уилера|блочно-сортирующее сжатие]] данных.
;[[Инвертированный индекс]]:Хранилище списка вхождений каждого критерия поиска{{sfn|inverted index}},  обычно в форме [[Хеш-таблица|хэш-таблиц]] или [[Двоичное дерево|бинарного дерева]]{{sfn|Foster|1965}}{{sfn|Landauer|1963}}.
;[[Индекс цитирования научных статей|Индекс цитирования]]:Хранилище [[Цитата|цитат]] или [[Гиперссылка|гиперссылок]] между документами для поддержки анализа цитирования, предмет [[Библиометрия|библиометрии]].
;[[N-грамм|N-грамм]]:Хранилище последовательностей длины данных для поддержки других типов поиска или анализа текста{{sfn|5-gram}}.
;Матрица термов документа:Используется в [[Латентно-семантический анализ|ЛСА]], хранит вхождения слов в документах в двумерной [[Разреженная матрица|разреженной матрице]].

===Проблемы параллельного индексирования===
Одной из основных задач при проектировании поисковых систем является управление последовательными вычислительными процессами. Существует много удобных ситуаций для создания [[Состояние гонки|состояния гонки]] и [[Когерентность|когерентных]] отказов. Например, новый документ добавлен к корпусу, и индекс должен быть обновлен, но в то же время индекс должен продолжать отвечать на поисковые запросы. Это коллизия между двумя конкурирующими задачами. Считайте, что авторы являются производителями информации, а поисковый робот — потребителем этой информации, захватывая текст и сохраняя его в кэше (или корпусе). Прямой индекс является потребителем информации, произведенной корпусом, а инвертированный индекс — потребителем информации, произведенной прямым индексом. Это обычно упоминается как '''модель производителя-потребителя'''. Индексатор является производителем доступной для поиска информации, а пользователи, которые ее ищут, — потребителями. Проблема усиливается при распределенном хранении и распределенной обработке. Чтобы масштабировать большие объемы индексированной информации, архитектура поисковой системы может включать [[Распределённые вычисления|распределенные вычисления]], при этом поисковая система состоит из нескольких машин, работающих в [[wikt:унисон|унисон]]. Это увеличивает вероятность нелогичности и делает сложнее поддержку полностью синхронизируемой, распределенной, параллельной архитектуры{{sfn|Dean,Ghemawat|2004}}.

===Прямой индекс===
Прямой индекс хранит список слов для каждого документа. Ниже приведена упрощенная форма прямого индекса:
{| align="center" class="wikitable"
|+ Прямой индекс
|-
! Документ !! Слова
|-
|Документ 1 || наша, Таня, громко, плачет
|-
|Документ 2 || уронила, в, речку, мячик
|-
|Документ 3 || тише, Танечка, не, плач,
|-
|Документ 4 || не, утонет, в, речке, мяч
|-
|}
Необходимость разработки прямого индекса объясняется тем, что лучше сразу сохранять слова за документом, поскольку документы анализируют. Формирование прямого индекса включает асинхронную системную обработку, которая частично обходит [[Узкое место|узкое место]] обновления инвертированного индекса{{sfn|Brin,Page|2006}}. Прямой индекс [[Алгоритм сортировки|сортируют]], чтобы преобразовать в инвертированный. Прямой индекс по сути представляет собой список пар, состоящих из документов и слов, отсортированный по документам. Преобразование прямого индекса к инвертированному является только вопросом сортировки пар по словам. В этом отношении инвертированный индекс — отсортированный по словам прямой индекс.

===Инвертированный индекс===
Многие поисковые системы используют инвертированный индекс при оценке поискового запроса, чтобы быстро определить местоположение документов, содержащих слова из запроса, а затем [[Ранжирование (поисковые системы)|ранжировать]] эти документы по релевантности. Поскольку инвертированный индекс хранит список документов, содержащих каждое слово, поисковая система может использовать прямой доступ, чтобы найти документы, связанные с каждым словом в запросе, и быстро получить их. Ниже приведено упрощенное представление инвертированного индекса:
{| align="center" class="wikitable"
|+ Инвертированный индекс
|-
! Слово !! Документы
|-
|в || Документ 2, Документ 4
|-
|громко || Документ 1
|-
|мяч || Документ 2, Документ 4
|-
|наша || Документ 1 
|-
|не || Документ 3, Документ 4
|-
|плакать || Документ 1, Документ 3
|-
|речка || Документ 2, Документ 4
|-
|Таня || Документ 1, Документ 3
|-
|тише||	Документ 3
|-
|уронить || Документ 2
|-
|утонуть || Документ 4
|-
|}
Инвертированный индекс может только определить существует ли слово в пределах конкретного документа, так как не хранит никакой информации относительно частоты и позиции слова, и поэтому его считают [[Логический тип|логическим]] индексом. Инвертированный индекс определяет, какие документы соответствуют запросу, но не оценивает соответствующие документы. В некоторых случаях индекс включает дополнительную информацию, такую как частота каждого слова в каждом документе или позиция слова в документе{{sfn|Grossman,Frieder,Goharian|2002}}. Информация о позиции слова позволяет поисковому алгоритму идентифицировать близость слова, чтобы поддерживать поиск фраз. Частота может использоваться, чтобы помочь в ранжировании документов по запросу. Такие темы в центре внимания исследований информационного поиска.

Инвертированный индекс представлен разреженной матрицей, так как не все слова присутствуют в каждом документе. Индекс подобен матрице термов документа, используемом в ЛСА. Инвертированный индекс можно считать формой хэш-таблицы. В некоторых случаях индекс представлен в форме двоичного дерева, которая требует дополнительной памяти, но может уменьшить время поиска. В больших индексах архитектура как правило представлена [[Распределённая хеш-таблица|распределенной хэш-таблицей]]{{sfn|Tang,Sandhya|2004}}.

===Слияние индекса===
Инвертированный индекс заполняется путем слияния или восстановления. Архитектура может быть спроектирована так, чтобы поддерживать инкрементную индексацию{{sfn|Tomasic|1994}}{{sfn|Luk,Lam|2007}}, где слияние определяет документ или документы, которые будут добавлены или обновлены, а затем анализирует каждый документ в слова. Для технической точности, слияние объединяет недавно индексированные документы, обычно находящиеся в [[Виртуальная память|виртуальной памяти]], с индексным кэшем, который находится на одном или нескольких [[Жёсткий диск|жестких дисках]] компьютера.

После [[Синтаксический анализ|синтаксического анализа]] индексатор добавляет указанный документ в список документов для соответствующих слов. В более крупной поисковой системе процесс нахождения каждого слова для инвертированного индекса может быть слишком трудоемким, поэтому его обычно разделяют на две части:
*разработка прямого индекса, 
*сортировка прямого индекса в инвертированный индекс. 
Инвертированный индекс так называется, потому что он является [[wikt:инверсия|инверсией]] прямого индекса.

===Сжатие===
Создание и поддержка крупномасштабного поискового индекса требует значительной памяти и выполнения задач обработки. Многие поисковые системы используют форму сжатия, чтобы уменьшить размер индексов на [[Компьютерная память|диске]]{{sfn|Cutting,Pedersen|1990}}. Рассмотрим следующий сценарий для полнотекстового механизма поиска в Интернете:
*Требуется 8 [[Бит|битов]] (или 1 [[Байт|байт]]) для хранения одного символа. Некоторые [[Набор символов|кодировки]] используют 2 байта на символ{{sfn|unicode}}.
*Среднее число символов в любом слове на странице примем за 5.
Учитывая этот сценарий, несжатый индекс для 2 миллиардов веб-страниц должен был бы хранить 500 миллиардов записей слов. 1 байт за символ или 5 байт за слово — потребовалось бы 2500 гигабайт одного только пространства памяти. Это больше, чем среднее свободное пространство на диске 2 персональных компьютеров. Для отказоустойчивой распределенной архитектуры требуется еще больше памяти. В зависимости от выбранного метода сжатия индекс может быть уменьшен до части такого размера. Компромисс времени и вычислительной мощности, требуемой для выполнения сжатия и распаковки.

Примечательно, что крупномасштабные проекты поисковых систем включают затраты на хранение, а также на электроэнергию для осуществления хранения. Таким образом сжатие является мерой стоимости.

==Синтаксический анализ документа==
Синтаксический анализ (или ''парсинг'') документа предполагает разбор документа на компоненты (слова) для вставки в прямой и инвертированный индексы. Найденные слова называют токенами (анг. ''tokens''), и в контексте индексации поисковых систем и [[Обработка естественного языка|обработки естественного языка]] парсинг часто называют [[:en:Tokenization|токенизацией]] (т.е. разбиением на токены). Синтаксический анализ иногда называют [[частеречная разметка|частеречной разметкой]] (анг. ''tagging''), морфологическим анализом, [[контент-анализ|контент-анализом]], текстовым анализом, [[анализ текста|анализом текста]], генерацией [[Согласование|согласования]], сегментацией речи, [[лексический анализ|лексическим анализом]]. Термины 'индексация', 'парсинг' и 'токенизация' взаимозаменяемы в корпоративном сленге.

Обработка естественного языка, начиная с 2006 года, является предметом постоянных исследований и технологических улучшений. Токенизация имеет много проблем в извлечении необходимой информации из документов для индексации, чтобы поддерживать качественный поиск. Токенизация для индексации включает в себя несколько технологий, реализация которых обычно является [[Коммерческая тайна|коммерческой тайной]].

===Проблемы при обработке естественного языка===
;Неоднозначность границ слова: На первый взгляд может показаться, что токенизация является простой задачей, но это не так, особенно при разработке [[:en:Multilingualism|многоязычного]] индексатора. В цифровой форме тексты некоторых языков таких как [[Китайский язык|китайский]], [[Японский язык|японский]] или [[Арабский язык|арабский]] представляют сложную задачу, так как слова четко не разделены [[Пробел|пробелом]]. Цель токенизации в том, чтобы распознать слова, которые будут искать пользователи. Специфичная для каждого языка логика используется, чтобы правильно распознать границы слов, что необходимо для разработки синтаксического анализатора для каждого поддерживаемого языка (или для групп языков с похожими границами и синтаксисом).
;Неоднозначность языка: Для более точного ранжирования документов многие поисковые системы учитывают дополнительную информацию о слове, например, к какому [[Язык|языку]] или [[Часть речи|части речи]] оно относится. Эти методы зависят от языка, поскольку синтаксис между языками различается. При токенизации некоторые поисковые системы пытаются автоматически определить язык документа.
;Различные форматы файлов: Для того чтобы правильно определить, какие байты представляют символы документа, [[формат файла]] должен быть правильно обработан. Поисковые системы, которые поддерживают различные форматы файлов должны правильно открывать документ, получать доступ к документу и токенизировать его символы.
;Ошибки памяти: Качество данных естественного языка не всегда может быть совершенным. Уязвимость существует из-за неизвестного количества документов, в частности в Интернете, которые не подчиняются соответствующему протоколу файла. [[Двоичный файл|Двоичные символы]] могут быть ошибочно закодированы в различных частях документа. Без распознавания этих символов и соответствующей обработки может ухудшиться качество индекса или индексирования.

===Токенизация===
В отличие от [[Грамотность|грамотных]] людей, компьютеры не понимают структуру документа естественного языка и не могут автоматически распознавать слова и предложения. Для компьютера документ — это только последовательность байтов. Компьютер не 'знает', что символ пробела является разделителем слов в документе. Человек должен [[wikt:программировать|запрограммировать]] компьютер так, чтобы определить, что является отдельным словом, называемым токеном. Такую программу обычно называют токенизатором или синтаксическим анализатором (парсером), а также лексическим анализатором{{sfn|Tokenization Guidelines|2011}}. Многие поисковые системы и другое [[Программное обеспечение|ПО]] для обработки естественного языка, включают специализированные программы для синтаксического анализа, например, [[yacc|YACC]] или [[lex|Лекс]].

Во время токенизации синтаксический анализатор определяет последовательность символов, которые представляют слова и другие элементы, например, [[пунктуация]], которые представлены числовыми кодами, некоторые из которых являются [[Управляющие символы|непечатаемыми управляющими символами]]. Синтаксический анализатор может распознать некоторые объекты, например, адреса [[Электронная почта|электронной почты]], [[Телефонный номер|телефонные номера]] и [[URL]]. При распознавании каждого токена могут быть сохранены некоторые характеристики, например, язык или кодировка, часть речи, позиция, число предложения, позиция в предложении, длина и номер строки{{sfn|Tokenization Guidelines|2011}}.

===Распознавание языка===
Если поисковая система поддерживает несколько языков, то первым шагом во время токенизации будет определение языка каждого документа, поскольку многие последующие шаги зависят от этого (например, [[стемминг]] и определение части речи). [[:en:Language identification|Распознавание языка]] — это процесс, при котором компьютерная программа пытается автоматически определить или классифицировать язык документа. Автоматическое распознавание языка является предметом исследований в обработке естественного языка{{sfn|Automated language recognition|2009}}.

===Анализ формата документа===
Если поисковая система поддерживает множество форматов документов, то документы должны быть подготовлены для токенизации. Проблема состоит в том, что многие форматы документов содержат информацию о форматировании в дополнение к текстовому содержанию. Например, документы [[HTML]] содержат [[Элементы HTML|HTML-теги]]{{sfn|html|2011}}. Если бы поисковая система игнорировала различие между содержанием и разметкой текста, то посторонняя информация включалась бы в индекс, что привело к плохим результатам поиска. Анализ формата — выявление и обработка [[Язык разметки|языка разметки]], встроенного в документ. Анализ формата также упоминается как структурный анализ, разделение [[Тег (языки разметки)|тегов]], текстовая нормализация. 

Задача анализа формата осложняется тонкостями различных форматов файлов. Некоторые форматы файлов защищаются правом [[Интеллектуальная собственность|интеллектуальной собственности]], о них мало информации, а другие наоборот хорошо документированы. Распространенные, хорошо задокументированные форматы файлов, которые поддерживают многие поисковые системы:
* [[HTML]]
* [[ASCII]] текстовые файлы (текстовые документы без удобночитаемого для компьютера форматирования)
* [[Adobe Systems|Adobe]]-формат электронных документов ([[PDF]])
* [[PostScript]] (PS)
* [[LaTeX]]
* [[Usenet]] формат новостных интернет-серверов
* [[XML]] и производные, например, [[RSS]]
* [[SGML]]
* Форматы мультимедийных [[Метаданные|метаданных]], как [[ID3 (метаданные)|ID3]]
* [[Microsoft Word]]
* [[Microsoft Excel]]
* [[Microsoft PowerPoint]]
* [[IBM Lotus Notes]]

Некоторые поисковые системы поддерживают файлы, которые хранятся в [[Сжатие данных|сжатом]] или зашифрованном формате. При работе со сжатым форматом индексатор сначала распаковывает документ. Этот шаг может привести к одному или нескольким файлам, каждый из которых должен быть индексирован отдельно. Обычно поддерживаемые форматы сжатого файла включают:

* [[ZIP]] — формат сжатия данных и [[Архиватор|архивации]] файлов
* [[RAR]] — формат сжатия данных и [[Условно-бесплатное программное обеспечение|условно-бесплатная]] программа-архиватор
* [[Cabinet|CAB]] — [[Microsoft Windows]] Cabinet File
* [[Gzip]] — формат сжатого файла gzip
* [[Bzip2|BZIP]] — формат сжатого файла bzip
* [[Tar|Tape ARchive (TAR)]], сжатый файл [[Unix]] 
* TAR.Z, TAR.GZ or TAR.BZ2 — [[Unix]]-архив файлов сжатых в Compress, GZIP или BZIP2

Анализ формата может включать методы повышения качества, чтобы избежать включения 'ненужной информации' в индекс. Контент может управлять информацией о форматировании, чтобы включать дополнительные сведения. Примеры злоупотребления форматированием документа в случае [[Поисковый спам|веб-спама]]:
* Включение сотни или тысячи слов в раздел, который скрыт от представления на мониторе, но является видимым индексатору, при помощи тегов форматирования (например, скрытый тег "div" в HTML, в который можно включить использование CSS или JavaScript).
* Установка цвета шрифта слов таким же, как цвет фона, что делает невидимыми слова для человека при просмотре документа, но слова остаются видимыми для индексатора.

===Распознавание раздела===
Некоторые поисковые системы включают распознавание раздела, определяют основные части документа до токенизации. Не все документы в корпусе читаются как правильно написанная книга, разделенная на главы и страницы. Многие документы в Интернете, такие как [[Информационный бюллетень|новостные рассылки]] и корпоративные отчеты, содержат ошибочное содержание и боковые блоки, в которых нет основного материала. Например, эта статья отображает в левом меню [[Гиперссылка|ссылки]] на другие веб-страницы. Некоторые форматы файлов, как HTML или PDF, допускают содержание, которое будет отображаться в колонках. Хотя содержимое документа представлено на экране в различных областях, [[Исходный код|исходный текст]] хранит эту информацию последовательно. Слова, которые появляются последовательно в исходном тексте, индексируются последовательно, несмотря на то, что предложения и абзацы отображаются в различных частях монитора. Если поисковые системы индексируют весь контент, как будто это основное содержание документа, качество индекса и поиска может ухудшиться. Отмечают две основные проблемы:
*Содержание в различных разделах рассматривают как связанное с индексом, хотя в действительности это не так.
*Дополнительное содержание 'боковой панели' включено в индекс, но оно не способствует реальной значимости документа, поэтому индекс заполнен плохим представлением о документе.
Для анализа раздела может потребоваться, чтобы поисковая система реализовала логику [[Визуализация|визуализации]] каждого документа, то есть абстрактное представление самого документа, и затем проиндексировала представление вместо документа. Например, некоторый контент в Интернете представлен через [[JavaScript]]. Если бы поисковая система не 'видела' JavaScript, то индексация страниц происходила бы неправильно. Учитывая, что некоторые поисковые системы не беспокоятся о проблемах с визуализацией, многие [[Веб-разработка|веб-разработчики]] стараются не представлять контент через JavaScript или используют тег [[NoScript]], чтобы убедиться, что веб-страница индексируется должным образом. В то же время этот факт можно использовать, чтобы 'заставить' индексатор поисковой системы 'видеть' различное скрытое содержание.

===Индексация метатегов===
Определенные документы часто содержат встроенные метаданные, такие как автор, [[Ключевое слово|ключевые слова]], описание и язык. В HTML-страницах [[метатеги]] содержат ключевые слова, которые также включены в индекс. В более ранних технологиях поиска в Интернете индексировались ключевые слова в метатегах для прямого индекса, а полный текст документа не анализировался. В то время еще не было полнотекстовой индексации, и [[аппаратное обеспечение]] компьютера было не в состоянии поддерживать такую технологию. Язык разметки HTML первоначально включал поддержку метатегов для того, чтобы правильно и легко индексировать, не требуя токенизации{{sfn|Lee Hypertext|1995}}.

В процессе развития Интернета в [[1990-е_годы|1990-ых]], многие корпорации вышли [[онлайн]] и создали корпоративные веб-сайты. Ключевые слова, используемые для описания веб-страниц стали больше ориентироваться на [[маркетинг]] и разрабатывались, чтобы управлять продажами, помещая веб-страницу в начало [[Страница результатов поиска|страницы результатов поиска]] для определенных поисковых запросов. Факт, что эти ключевые слова были определены субъективно, приводил к спаму, что вынудило многие поисковые системы принять полнотекстовую индексацию. Разработчики поисковой системы могли поместить много 'маркетинговых ключевых слов' в содержание веб-страницы до того, как наполнят ее интересной и полезной информацией. Однако целью проектирования веб-сайтов являлось привлечение клиентов, поэтому разработчики были заинтересованы в том, чтобы включить больше полезного контента на сайт, чтобы сохранить [[Уникальный посетитель|посетителей]]. В этом смысле полнотекстовая индексация была более объективной и увеличила качество результатов поисковой системы, что содействовало исследованиям технологий полнотекстовой индексации.
В [[Локальный поисковик|локальном поиске]] многие решения включают метатеги, чтобы обеспечить поиск по авторам, так как поисковая система индексирует контент из различных файлов, содержание которых не очевидно. Локальный поиск больше находиться под контролем пользователя, в то время как механизмы интернет-поиска должны больше фокусироваться на полнотекстовом индексе.

== См. также ==
* [[Вертикальный поиск]]
* [[Извлечение информации]]
* [[Индекс (базы данных)]]
* [[Семантическая паутина]]

== Примечания ==
{{примечания}}

== Литература ==
*{{статья
 |автор= Charles L. A. Clarke , Gordon V. Cormack
 |заглавие= Dynamic Inverted Indexes for a Distributed Full-Text Retrieval System
 |ссылка=http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.36.4366&rep=rep1&type=pdf
 |язык=en
 |издание= MultiText Pro ject Technical Report MT-95-01 
 |место= University of Waterloo, Waterloo, Ontario N2L 3G1, Canada
 |год=1995
 |ref=Clarke,Cormack
}}

*{{статья
 |автор= Charles E. Jacobs, Adam Finkelstein, David H. Salesin
 |заглавие=Fast Multiresolution Image Querying
 |ссылка=http://grail.cs.washington.edu/projects/query/mrquery.pdf
 |язык=en
 |издание=Department of Computer Science and Engineering
 |место=University of Washington, Seattle, Washington 98195
 |год=2006
 |ref=Jacobs,Finkelstein,Salesin
}}

*{{статья
 | автор         = Cutting, D., Pedersen, J.
 | заглавие      = Optimizations for dynamic inverted index maintenance
 | язык          = en
 | ответственный = Jean-Luc Vidick 
 | место         = NY, USA
 | издательство  = ACM New York
 | год           = 1990
 | страницы      = 405-411
 | isbn          = 0-89791-408-2
 | ref           = Cutting,Pedersen
}}

*{{книга
 | автор         = Eric W. Brown
 | заглавие      = Execution Performance Issues in Full-Text Information Retrieval
 | ссылка        = http://scholarworks.umass.edu/cgi/viewcontent.cgi?article=1088&context=cs_faculty_pubs
 | место         = University of Massachusetts Amherst
 | издательство  = Computer Science Department
 | год           = 1996
 | страниц       = 179
 | серия         = Technical Report 95-81
 | ref           = Brown
}}
*{{книга
 | автор = Dan Gusfield
 | заглавие = Algorithms on Strings, Trees and Sequences: Computer Science and Computational Biology 
 | ссылка = http://www.it-feel.com/Information%20Technologies/Programing/Algorithms%20on%20String%20Trees%20and%20Sequences.pdf
 | место = USA 
 | издательство = Cambridge University Press 
 | год = 1997 
 | страниц = 326
 | isbn = 0-521-58519-8
 | ref = Gusfield
}}
*{{статья
 |автор         = Caxton Croxford Foster
 |заглавие      = Information retrieval: information storage and retrieval using AVL trees
 |язык          = en
 |издание       = ACM '65 Proceedings of the 1965 20th national conference
 |место         = NY, USA
 |год           = 1965
 |страницы      = 192-205 
 |doi           = 10.1145/800197.806043
 |ref = Foster
}}
*{{статья
 |автор         = Landauer, W. I.
 |заглавие      = The balanced tree and its utilization in information retrieval
 |язык          = en
 |издание       = IEEE Trans. on Electronic Computers
 |место = USA
 |год           = 1963
 |номер         = 6
 |страницы      = 12
 |ref = Landauer
}}
*{{статья
 |автор         = Jeffrey Dean, Sanjay Ghemawat
 |заглавие      = MapReduce: Simplified Data Processing on Large Clusters
 |ссылка        = http://static.googleusercontent.com/external_content/untrusted_dlcp/research.google.com/ru//archive/mapreduce-osdi04.pdf
 |язык          = en
 |издательство  = Google, Inc
 |год           = 2004
 |ref           = Dean,Ghemawat
}}
*{{статья
 |автор         = Sergey Brin, Lawrence Page
 |заглавие      = The Anatomy of a Large-Scale Hypertextual Web Search Engine
 |ссылка        = http://infolab.stanford.edu/~backrub/google.html
 |язык          = en
 |место         = Stanford University, Stanford
 |издательство  = Computer Science Department
 |год= 2006
 |ref           = Brin,Page
}}
*{{статья
 |автор         = Grossman, Frieder, Goharian
 |заглавие      = IR Basics of Inverted Index
 |ссылка        = http://www.cs.clemson.edu/~juan/CPSC862/Concept-50/IR-Basics-of-Inverted-Index.pdf
 |язык          = en
 |год           = 2002
 |ref         = Grossman,Frieder,Goharian
}}
*{{статья
 |автор         = Tang Hunqiang, Sandhya Dwarkadas
 |заглавие      = Hybrid Global Local Indexing for Efficient Peer to Peer Information Retrieval
 |ссылка        = http://www.cs.rochester.edu/u/sandhya/papers/nsdi04.ps
 |язык          = en
 |место         = University of Rochester
 |издательство  = Computer Science Department
 |год           = 2004
 |ref           =Tang,Sandhya
}}
*{{статья
 |автор         = Anthony Tomasic
 |заглавие      = Incremental Updates of Inverted Lists for Text Document Retrieval
 |язык          = en
 |тип           = Conference Proceeding
 |место         = Stanford University
 |год           = 1994
 |ref           =Tomasic
}}
*{{статья
 |автор         = Robert W.P. Luk, Wai Lam
 |заглавие      = Efficient in-memory extensible inverted file
 |язык          = en
 |издание       = Information Systems
 |год           = 2007
 |номер         = 32 (5)
 |страницы      = 733-754
 |doi           = 10.1016/j.is.2006.06.001
 |ref           =Luk,Lam
}}
*{{статья
 |автор         = Radim Řehůřek, Milan Kolkus
 |заглавие      = Language Identification on the Web: Extending the Dictionary Method
 |ссылка        = http://folk.ntnu.no/sandsmar/langdetect.pdf
 |язык          = en
 |издание       = Lecture Notes in Computer Science Volume
 |место         = Mexico
 |год           = 2009
 |номер         = 5449
 |страницы      = 357-368
 |isbn          = 978-3-642-00382-0
 |ref           = Automated language recognition
}}
*{{книга
 | автор         = Scoping SIG, Tokenization Taskforce PCI Security Standards Council
 | заглавие      = Info Supplement:PCI DSS Tokenization Guidelines
 | ссылка        = https://www.pcisecuritystandards.org/documents/Tokenization_Guidelines_Info_Supplement.pdf
 | год           = 2011
 | страницы      = 23
 | ref           = Tokenization Guidelines
}}
*{{книга
 | автор         = Б. Лоусон, Р. Шарп
 | заглавие      = Изучаем HTML5
 | оригинал      = Introducing HTML5
 | издательство  = Питер
 | год           = 2011
 | страниц       = 272
 | серия         = Библиотека специалиста
 | isbn          = 978-5-459-00269-0, 978-0321687296
 | тираж         = 2000
 | ref           = html
}}
*{{статья
 |автор         = T. Berners-Lee
 |заглавие      = Hypertext Markup Language - 2.0
 |ссылка        = https://tools.ietf.org/html/rfc1866
 |язык          = en
 |издательство  = Network Working Group
 |год           = 1995
 |ref           = Lee Hypertext
}}

== Ссылки ==
*{{cite web
 |url         = http://www.technologyreview.com/news/406833/software-learns-to-tag-photos/
 |title       = Software Learns to Tag Photos
 |author      = James Lee
 |date        = November 09, 2006
 |work        = MIT Technology Review
 |pages       = 1-2
 |accessdate  = Dec 2006
 |lang        = en
 |ref=Lee
}}

*{{cite web |url=http://www.comparisonics.com/SearchingForSounds.html Searching for Sounds |title=Comparisonics Searching for Sounds|author=Stephen V. Rice, Stephen M. Bailey|date=May 2004|publisher=© 2013 Comparisonics Corporation|lang=en|ref=Rice,Bailey}}

*{{cite web|url=http://infolab.stanford.edu/~backrub/google.html|title=The Anatomy of a Large-Scale Hypertextual Web Search Engine|last=[[Брин, Сергей Михайлович|С. Брин]], [[Пейдж, Лэрри|Л. Пейдж]]|accessdate=2009-09-20|archiveurl=http://www.webcitation.org/66YJZq2dx|archivedate=2012-03-30}}

*{{cite web
 |url         = http://dev.mysql.com/doc/refman/5.1/en/partitioning-linear-hash.html
 |title       = MySQL 5.1 Reference Manual
 |subtitle    = 18.2.3.1 LINEAR HASH Partitioning
 |publisher      = © Oracle and/or its affiliates 1997, 2013
 |work        = mysql.com
 |accessdate  = 2013-10-24
 |lang        = en
 |ref = mysql
}}
*{{cite web
 |url         = http://www.nist.gov/dads/HTML/trie.html
 |title       = "trie" in Dictionary of Algorithms and Data Structures
 |author      = Vreda Pieterse and Paul E. Black
 |work        = http://www.nist.gov
 |date        = 22 February 2011
 |lang        = en
 |ref         = trie
}}
*{{cite web
 |url         = http://www.nist.gov/dads/HTML/invertedIndex.html
 |title       = "inverted index" in Dictionary of Algorithms and Data Structures
 |author      = Vreda Pieterse and Paul E. Black
 |work        = http://www.nist.gov U.S. National Institute of Standards and Technology
 |date        = 14 August 2008
 |lang        = en
 |ref         = inverted index
}}
*{{cite web
 |url         = http://catalog.ldc.upenn.edu/LDC2006T13
 |title       = Web 1T 5-gram Version 1
 |author      = Thorsten Brants, Alex Franz
 |work        = http://catalog.ldc.upenn.edu/
 |date        = Sep 19, 2006
 |lang        = en
 |ref         = 5-gram
}}
*{{cite web
 |url         = http://www.unicode.org/faq/basic_q.html#15
 |title       = The Unicode Standard - Frequently Asked Questions
 |date        = Dec 2006
 |lang        = en
 |ref=unicode
}}

[[Категория:Информационный поиск]]
[[Категория:Поисковые системы]]
[[Категория:Информационные системы]]
[[Категория:Алгоритмы интернет-поиска]]